# The metric vrops_hostsystem_runtime_maintenancestate indicates in the propkey label if a hypervisor is in maintenance.
# It can be used in two ways:
# 1.) use the value and a regex
#   vrops_hostsystem_runtime_maintenancestate == 0 indicates in maintenance
#   vrops_hostsystem_runtime_maintenancestate == 1 indicates not in maintenance
# 2.) use the label name:
#   vrops_hostsystem_runtime_maintenancestate{state="inMaintenance"} indicates in maintenance
#   vrops_hostsystem_runtime_maintenancestate{state="notInMaintenance"} indicates not in maintenance
# Since this metric is not providing constantly a value we have to use max_over_time. We take the average of 8m (5m scrape interval + 100-140s scrape duration + a buffer)

# Combining the redfish metrics with the vrops_hostsystem_runtime_maintenancestate metric needs a label_replace because the server_name label is not existing in vrops_hostsystem_runtime_maintenancestate metric but the hostsystem label.
# hostsystem label has the FQDN. So we only use the host part for the server_name label (node)
# label_replace(vrops_hostsystem_runtime_maintenancestate, "server_name", "$1", "hostsystem", "(.*).cc.*")

# Afterwards we can match using on(server_name) both metrics using the server_name label.

# To get all the labels needed for the alert we use group_left to use the ones from the left side which is the redfish metric.

# Available types in redfish-exporter: type=~"(memory|disk|chassis|fan|system|powersupply|storage|processor)"

groups:
- name: metal-redfish-esxi.alerts
  rules:      
  - alert: MetalESXiRedfishWarning
    expr: count(max_over_time(redfish_health{job="redfish-bb", type=~"(disk|storage)"}[30m]) == 1) by (server_name, type, exported_name, serial) * on(server_name) group_left count(label_replace(max_over_time(vrops_hostsystem_runtime_maintenancestate{state="notInMaintenance"}[15m]), "server_name", "$1", "hostsystem", "(.*).cc.*")) by (server_name)
    for: 10m
    labels:
      severity: warning
      tier: metal
      service: baremetal
      support_group: compute
      context: "{{ $labels.server_name }}"
      meta: "ESXi Host {{ $labels.server_name }} hardware error. Type: {{ $labels.type }} Name: {{ $labels.exported_name }} /  Serial: {{ $labels.serial }}, Host not in maintenance"
      playbook: docs/devops/alert/baremetal/vpod
    annotations:
      description: "ESXi Host {{ $labels.server_name }} hardware error. Type: {{ $labels.type }} / Name: {{ $labels.exported_name }} /  Serial: {{ $labels.serial }}, Host not in maintenance"
      summary: "Hardware error for server: {{ $labels.server_name }}"

  - alert: MetalESXiRedfishInfo
    expr: count(max_over_time(redfish_health{job="redfish-bb", type=~"(disk|storage)"}[30m]) == 1) by (server_name, type, exported_name, serial) * on(server_name) group_left count(label_replace(max_over_time(vrops_hostsystem_runtime_maintenancestate{state="InMaintenance"}[15m]), "server_name", "$1", "hostsystem", "(.*).cc.*")) by (server_name)
    for: 10m
    labels:
      severity: info
      tier: metal
      service: baremetal
      support_group: compute
      no_alert_on_absence: "true"
      context: "{{ $labels.server_name }}"
      meta: "ESXi Host {{ $labels.server_name }} hardware error. Type: {{ $labels.type }} Name: {{ $labels.exported_name }} /  Serial: {{ $labels.serial }}, Host in maintenance"
      playbook: docs/devops/alert/baremetal/vpod
    annotations:
      description: "ESXi Host {{ $labels.server_name }} hardware error. Type: {{ $labels.type }} / Name: {{ $labels.exported_name }} /  Serial: {{ $labels.serial }}, Host in maintenance"
      summary: "Hardware error for server: {{ $labels.server_name }}"
