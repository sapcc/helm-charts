userId:
  # -- run the MariaDB containers with that [user id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 101
  application:
  # -- run the MariaDB monitoring containers with that [user id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 3000
  monitoring:
  # -- run the ProxySQL containers with that [user id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 3100
  proxy:
groupId:
  # -- run the MariaDB containers with that [group id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 101
  application:
  # -- run the MariaDB monitoring containers with that [group id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 3000
  monitoring:
  # -- run the ProxySQL containers with that [group id](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container)
  # @default -- 3100
  proxy:

namePrefix:
  # -- name prefix used for the MariaDB pods, services etc.
  # @default mariadb-g
  application: false
  # -- name prefix used for the ProxySQL pods, services etc.
  # @default proxysql
  proxy: false
# -- only useful for benchmarking [www.kernel.org drop_caches](https://www.kernel.org/doc/html/latest/admin-guide/sysctl/vm.html?highlight=drop_caches#drop-caches)
cleanOsCacheAtStartup: false
scripts:
  # -- how many times should script functions retry before failing
  # @default -- 10
  maxRetries: 20
  # -- how long should script functions wait between retries
  # @default -- 6
  waitTimeBetweenRetriesInSeconds: 6
  # -- Log level of shell scripts used in the Helm chart.
  # Can be `info` or `debug`
  # @default -- info
  logLevel: debug
  # -- to multiply with `readinessProbe.timeoutSeconds.application` as the maximum allowed time difference between nodes for the last sequence number configmap update
  # @default -- 3
  maxAllowedTimeDifferenceFactor: 12
  # -- fail if time difference between nodes for the last sequence number configmap update is too big
  useTimeDifferenceForSeqnoCheck: false
mariadb:
  # -- run the default entrypoint.sh script or just sleep to be able to troubleshoot and debug
  autostart: true
  # -- will trigger a pod restart and remove all content from the data and log dir. This option will cause data loss and should only be used before triggering a [full database restore](#full-database-restore)
  # @default -- false
  wipeDataAndLog: false
  # -- if not defined the data dir will be used. Needs a log volume mount to be configured too
  binLogDir: log
  # -- `1` to enable [sync_binlog for ACID compliance](https://mariadb.com/kb/en/replication-and-binary-log-system-variables/#sync_binlog)
  # @default -- 0
  binLogSync: 1
  # -- `1` to enable [innodb_flush_log_at_trx_commit for ACID compliance](https://mariadb.com/kb/en/innodb-system-variables/#innodb_flush_log_at_trx_commit)
  # @default -- 0
  innodbFlushLogAtTrxCommit: 1
  # -- to enable the [Performance Schema](https://mariadb.com/kb/en/performance-schema-overview/)
  # @default -- false
  performance_schema: false
  # -- to define the [verbosity](https://mariadb.com/kb/en/error-log/#configuring-the-error-log-verbosity) of the MariaDB logs
  # @default -- 2
  errorLogWarningVerbosity: 1
  asyncReplication:
    # -- to enable the [asynchronous replication config](#asynchronous-replication-config). Should be done within custom instance configuration files
    # @default -- false
    enabled: false
    # -- reset the replica configuration. Use with care, because the currently used GTID binlog position value will be deleted. That can cause missing or duplicate data on the replica later
    resetConfig: false
    # -- start configured slave during database node startup [wsrep_restart_slave](https://mariadb.com/kb/en/galera-cluster-system-variables/#wsrep_restart_slave)
    # @default -- false
    autostart: false
    # -- #Hostname or IP of the replication source [master_host](https://mariadb.com/kb/en/change-master-to/#master_host)
    primaryHost: false
    # -- (int) how many [slave_parallel_threads](https://mariadb.com/kb/en/replication-and-binary-log-system-variables/#slave_parallel_threads) should be used for async replication
    # @default -- 1
    slaveReplicaThreads:
  galera:
    # -- [Galera debug](https://galeracluster.com/library/documentation/galera-parameters.html#debug)
    # @default -- false
    debug: false
    # -- (int) [pc.wait_prim_timeout](https://galeracluster.com/library/documentation/galera-parameters.html#pc.wait_prim_timeout)
    # @default -- 30
    waitForPrimaryTimeoutInSeconds: 60
    # -- (string) [wsrep_debug](https://mariadb.com/kb/en/galera-cluster-system-variables/#wsrep_debug)
    # @default -- info
    logLevel: info
    # -- [primary component recovery](https://galeracluster.com/library/documentation/pc-recovery.html)
    # @default -- false
    pcrecovery: false
    gcache:
      # -- `false` until [PR#624](https://github.com/codership/galera/issues/624) is fixed
      # @default -- false
      recover: false
    # -- `rsync` or `mariabackup` (also requires GALERA_SST_USER and GALERA_SST_PASSWORD)
    sst_method: rsync
    # -- (int) [wsrep-slave-threads](https://galeracluster.com/library/documentation/mysql-wsrep-options.html#wsrep-slave-threads)
    # @default -- 4
    slaveThreads: 16
    # -- (int) must be a positive integer [wsrep_gtid_domain_id](https://mariadb.com/kb/en/galera-cluster-system-variables/#wsrep_gtid_domain_id)
    # @default -- 1
    gtidDomainId: 1
    # -- (int) how many Galera cluster instances will be connected. Used for [asynchronous replication](#asynchronous-replication-config) setups. Maximum of `2` is supported
    # @default -- 1
    gtidDomainIdCount: 1
    # -- enable [gtid_strict_mode](https://mariadb.com/kb/en/gtid/#gtid_strict_mode)
    # @default -- false
    gtidStrictMode: false
    backup:
      # -- enable the [database backup](#database-backup). Should be done within custom instance configuration files
      enabled: false
      openstack:
        # -- (string) Openstack Keystone [url](https://docs.openstack.org/python-openstackclient/zed/cli/authentication.html)
        authurl: https://openstack.keystone.url:443/v3
        # -- (string) Openstack Keystone [region](https://docs.openstack.org/python-openstackclient/zed/cli/authentication.html)
        region:
        # -- (string) Openstack Keystone [project](https://docs.openstack.org/python-openstackclient/zed/cli/authentication.html)
        projectname:
        # -- (string) Openstack Keystone [tenant](https://docs.openstack.org/python-openstackclient/zed/cli/authentication.html)
        tenantname:
        # -- (string) Openstack [Swift](https://docs.openstack.org/swift/latest/) container
        container:
      restic:
        # --  (float) update interval for the console output [RESTIC_PROGRESS_FPS](https://restic.readthedocs.io/en/stable/040_backup.html?highlight=RESTIC_PROGRESS_FPS#environment-variables)
        # @default -- 0.01666
        progressFps:
        # -- (string) [compression](https://restic.readthedocs.io/en/stable/047_tuning_backup_parameters.html#compression)
        # @default -- auto
        compression:
        # -- (int) [pack-size](https://restic.readthedocs.io/en/stable/047_tuning_backup_parameters.html#pack-size) keep in mind the 5GB Swift object size limit and the potential object count quota limit
        # @default -- 16
        packsizeInMB:
        # -- [unlock repo](https://restic.readthedocs.io/en/stable/manual_rest.html?highlight=unlock)
        # @default -- false
        unlockRepo: false
        # -- [removing backup snapshots](https://restic.readthedocs.io/en/stable/060_forget.html?highlight=prune#removing-backup-snapshots)
        # @default -- false
        pruneBackups: false
        keep:
          # -- (int) [keep-last](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 2
          last: 2
          # -- (int) [keep-hourly](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 24
          hourly: 24
          # -- (int) [keep-daily](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 1
          daily: 1
          # -- (int) [keep-weekly](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 0
          weekly: 0
          # -- (int) [keep-monthly](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 0
          monthly: 0
          # -- (int) [keep-yearly](https://restic.readthedocs.io/en/stable/060_forget.html#removing-snapshots-according-to-a-policy)
          # @default -- 0
          yearly: 0
    restore:
      # -- enable the [full database restore](#full-database-restore). Should be done as described in the documentation with `--set` parameters
      enabled: false
      # -- define the backup timestamp that should be used for the restore. Only the `%Y-%m-%d %H:%M:%S` format is currently supported and the restic snapshot nearest before will be used
      beforeTimestamp:
      restic:
        # -- If set the beforeTimestamp option will be ignored and the configured id will be used
        snapshotId: false
        # --  (float) update interval for the console output [RESTIC_PROGRESS_FPS](https://restic.readthedocs.io/en/stable/040_backup.html?highlight=RESTIC_PROGRESS_FPS#environment-variables)
        # @default -- 0.01666
        progressFps: 0.5
monitoring:
  mysqld_exporter:
    # -- run the default entrypoint.sh script or just sleep to be able to troubleshoot and debug
    autostart: true
    # -- enable the [Prometheus MySQL exporter](https://github.com/prometheus/mysqld_exporter) as sidecar container
    # @default -- false
    enabled: false
    # -- (int) TCP port used by the exporter to listen for Prometheus connections
    # @default -- 9104
    metricsPort:
  prometheus:
    # -- (string) name of the Prometheus instance that should pull metrics
    # @default -- prometheus
    instance:
  elasticBeatsAutoDiscoveryAnnotations:
    # -- (not yet implemented) add annotations to allow [automatic configuration](https://www.elastic.co/guide/en/beats/metricbeat/current/configuration-autodiscover-hints.html) of Elastic Beats agents
    enabled: false
proxy:
  # -- use ProxySQL in front of the MariaDB Galera pods to reduce the service downtimes for the clients
  enabled: false
  restapi:
    # -- the [ProxySQL RestAPI](https://proxysql.com/documentation/REST-API/)
    enabled: true
  adminui:
    # -- the [ProxySQL Admin UI](https://proxysql.com/documentation/http-web-server/)
    enabled: true
    # -- the variable defines the [verbosity level](https://proxysql.com/documentation/global-variables/admin-variables/#admin-web_verbosity) of the web server
    verbosity: 0
  queryRules:
    genericReadWriteSplit:
      # -- check the "Generic Read/Write split using regex" section in the [howto](https://proxysql.com/documentation/proxysql-read-write-split-howto/) for details
      enabled: true

# Docker image
image:
  os:
    # -- hostname of the image registry used to pull the basic OS image that will be used for certain init steps
    registry: keppel.eu-nl-1.cloud.sap
    # -- project/tenant used in the image registry
    project: octobus
    # -- folder/container used in the image registry and also part of the image name
    applicationname: ubuntu
    # -- application part of the image version that should be pulled
    applicationversion: 20.04
    # -- image part of the image version that should be pulled
    imageversion: 0.3.74
    # -- (string) `Always` to enforce that the image will be pulled even if it is already available on the worker node
    # @default -- IfNotPresent
    pullPolicy:
    # -- name of the already defined Kubernetes secret that should be used for registry authentication
    pullSecret:
  application:
    # -- hostname of the image registry used to pull the application image that contains `MariaDB`, `Galera` and the two helpers `yq` and `restic`
    registry: keppel.eu-de-1.cloud.sap
    # -- project/tenant used in the image registry
    project: ccloud
    # -- folder/container used in the image registry and also part of the image name
    applicationname: mariadb-galera
    # -- application part of the image version that should be pulled
    applicationversion: 10.5.18
    # -- image part of the image version that should be pulled
    imageversion: 0.3.2
    # -- (string) `Always` to enforce that the image will be pulled even if it is already available on the worker node
    # @default -- IfNotPresent
    pullPolicy: Always
    # -- name of the already defined Kubernetes secret that should be used for registry authentication
    pullSecret:
  monitoring:
    # -- hostname of the image registry used to pull the monitoring image that currently contains the MySQL exporter for Prometheus
    registry: keppel.eu-de-1.cloud.sap
    # -- project/tenant used in the image registry
    project: ccloud
    # -- folder/container used in the image registry and also part of the image name
    applicationname: mysqld_exporter
    # -- application part of the image version that should be pulled
    applicationversion: 0.14.0
    # -- image part of the image version that should be pulled
    imageversion: 0.1.1
    # -- (string) `Always` to enforce that the image will be pulled even if it is already available on the worker node
    # @default -- IfNotPresent
    pullPolicy: Always
    # -- name of the already defined Kubernetes secret that should be used for registry authentication
    pullSecret:
  proxy:
    # -- hostname of the image registry used to pull the proxy image that contains the ProxySQL software to load balance MariaDB connections
    registry: keppel.eu-de-1.cloud.sap
    # -- project/tenant used in the image registry
    project: ccloud
    # -- folder/container used in the image registry and also part of the image name
    applicationname: proxysql
    # -- application part of the image version that should be pulled
    applicationversion: 2.4.5
    # -- image part of the image version that should be pulled
    imageversion: 0.1.3
    # -- (string) `Always` to enforce that the image will be pulled even if it is already available on the worker node
    # @default -- IfNotPresent
    pullPolicy: Always
    # -- name of the already defined Kubernetes secret that should be used for registry authentication
    pullSecret:

initContainers:
  increaseMapCount:
    securityContext:
      # -- (bool) required to configure `/proc/sys/vm/max_map_count` in the init phase
      # @default -- true
      privileged:
      # -- (int) required to configure `/proc/sys/vm/max_map_count` in the init phase
      # @default -- 0
      runAsUser:
  tcpKeepAlive:
    securityContext:
      # -- (bool) required to configure `net.ipv4.tcp_keepalive_time` in the init phase
      # @default -- true
      privileged:
      # -- (int) required to configure `net.ipv4.tcp_keepalive_time` in the init phase
      # @default -- 0
      runAsUser:
  cleanoscache:
    securityContext:
      # -- (bool) required to configure `/proc/sys/vm/drop_caches` in the init phase
      # @default -- true
      privileged:
      # -- (int) required to configure `/proc/sys/vm/drop_caches` in the init phase
      # @default -- 0
      runAsUser:

# network services
services:
  application:
    backend:
      # -- `ClusterIP` to configure a Kubernetes internal service or `LoadBalancer` to publish the service outside of the [Kubernetes cluster network](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types)
      type: ClusterIP
      # -- `false` or `true` if the IP adresses of the pods that are [endpoints for that service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) should be advertised. Required to let the client make it's own load balancing decisions
      headless: true
      ports:
        galera:
          # -- exposed Galera [replication port](https://mariadb.com/kb/en/configuring-mariadb-galera-cluster/#network-ports)
          port: 4567
          # -- Galera [replication port](https://mariadb.com/kb/en/configuring-mariadb-galera-cluster/#network-ports) configured in the container
          targetPort: 4567
          # -- Galera [replication port](https://mariadb.com/kb/en/configuring-mariadb-galera-cluster/#network-ports) protocol
          protocol: TCP
        ist:
          # -- exposed Galera [incremental state transfer port](http://galeracluster.com/library/documentation/galera-parameters.html#ist-recv-addr)
          port: 4568
          # -- Galera [incremental state transfer port](http://galeracluster.com/library/documentation/galera-parameters.html#ist-recv-addr) configured in the container
          targetPort: 4568
          # -- Galera [incremental state transfer port](http://galeracluster.com/library/documentation/galera-parameters.html#ist-recv-addr) protocol
          protocol: TCP
        sst:
          # -- exposed Galera [state snapshot transfer port](https://mariadb.com/kb/en/introduction-to-state-snapshot-transfers-ssts/)
          port: 4444
          # -- Galera [state snapshot transfer port](https://mariadb.com/kb/en/introduction-to-state-snapshot-transfers-ssts/) configured in the container
          targetPort: 4444
          # -- Galera [state snapshot transfer port](https://mariadb.com/kb/en/introduction-to-state-snapshot-transfers-ssts/) protocol
          protocol: TCP
      sessionAffinity:
        # -- `None` or `ClientIP` if connections from a single client should be [routed to the same endpoint](https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity) every time.
        type: None
    frontend:
      # -- `ClusterIP` to configure a Kubernetes internal service or `LoadBalancer` to publish the service outside of the [Kubernetes cluster network](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types)
      type: ClusterIP
      # -- `false` or `true` if the IP adresses of the pods that are [endpoints for that service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) should be advertised. Required to let the client make it's own load balancing decisions
      headless: false
      ports:
        mysql:
          # -- exposed MariaDB [SQL port](https://mariadb.com/kb/en/connecting-to-mariadb/#port)
          port: 3306
          # -- MariaDB [SQL port](https://mariadb.com/kb/en/connecting-to-mariadb/#port) configured in the container
          targetPort: 3306
          # -- MariaDB [SQL port](https://mariadb.com/kb/en/connecting-to-mariadb/#port) protocol
          protocol: TCP
      sessionAffinity:
        # -- `None` or `ClientIP` if connections from a single client should be [routed to the same endpoint](https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity) every time.
        type: ClientIP
        # -- [Session stickiness timeout](https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity) for the `sessionAffinity` option
        # @default -- 10800
        ClientIpTimeoutSeconds: 28800
  proxy:
    backend:
      # -- `ClusterIP` to configure a Kubernetes internal service or `LoadBalancer` to publish the service outside of the [Kubernetes cluster network](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types)
      type: ClusterIP
      # -- `false` or `true` if the IP adresses of the pods that are [endpoints for that service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) should be advertised. Required to let the client make it's own load balancing decisions
      headless: true
      ports:
        proxy:
          # -- exposed ProxySQL [Admin SQL port](https://proxysql.com/Documentation/global-variables/admin-variables/#admin-mysql_ifaces)
          port: 6032
          # -- ProxySQL [Admin SQL port](https://proxysql.com/Documentation/global-variables/admin-variables/#admin-mysql_ifaces) configured in the container
          targetPort: 6032
          # -- ProxySQL [Admin SQL port](https://proxysql.com/Documentation/global-variables/admin-variables/#admin-mysql_ifaces) protocol
          protocol: TCP
        restapi:
          # -- exposed ProxySQL [Rest API port](https://proxysql.com/documentation/REST-API/)
          port: 6070
          # -- ProxySQL [Rest API port](https://proxysql.com/documentation/REST-API/) configured in the container
          targetPort: 6070
          # -- ProxySQL [Rest API port](https://proxysql.com/documentation/REST-API/) protocol
          protocol: TCP
        adminui:
          # -- exposed ProxySQL [Admin UI port](https://proxysql.com/documentation/http-web-server/)
          port: 6080
          # -- ProxySQL [Admin UI port](https://proxysql.com/documentation/http-web-server/) configured in the container
          targetPort: 6080
          # -- ProxySQL [Admin UI port](https://proxysql.com/documentation/http-web-server/) protocol
          protocol: TCP
      sessionAffinity:
        # -- `None` or `ClientIP` if connections from a single client should be [routed to the same endpoint](https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity) every time.
        type: None
    frontend:
      # -- `ClusterIP` to configure a Kubernetes internal service or `LoadBalancer` to publish the service outside of the [Kubernetes cluster network](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types)
      type: ClusterIP
      # -- `false` or `true` if the IP adresses of the pods that are [endpoints for that service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) should be advertised. Required to let the client make it's own load balancing decisions
      headless: false
      ports:
        proxy:
          # -- exposed ProxySQL [SQL port](https://proxysql.com/Documentation/global-variables/mysql-variables/#mysql-interfaces)
          port: 3306
          # -- ProxySQL [SQL port](https://proxysql.com/Documentation/global-variables/mysql-variables/#mysql-interfaces) configured in the container
          targetPort: 6033
          # -- ProxySQL [SQL port](https://proxysql.com/Documentation/global-variables/mysql-variables/#mysql-interfaces) protocol
          protocol: TCP
      sessionAffinity:
        # -- `None` or `ClientIP` if connections from a single client should be [routed to the same endpoint](https://kubernetes.io/docs/reference/networking/virtual-ips/#session-affinity) every time.
        type: None

# Storage
volumeMounts:
  application:
    data:
      # -- name for the [persistent volume claim](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) requested for the MariaDB [data directory](https://mariadb.com/kb/en/server-system-variables/#datadir)
      claimName: mariadb
      # -- mount path of the persistent volume in the container used for the MariaDB data directory
      mountPath: /opt/mariadb/data
      # -- volume type [(persistent)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
      type: persistentVolume
    log:
      claimName: marialog
      # -- mount path of the persistent volume in the container used for the MariaDB log directory
      mountPath: /opt/mariadb/log
      # -- volume type [(persistent)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
      type: persistentVolume
    cert-wildcard:
      # -- if a `cert-wildcard` Kubernetes secret has been defined it will be mounted into that directory
      mountPath: /opt/mariadb/etc/certs
      # -- volume type [(secret)](https://kubernetes.io/docs/concepts/storage/volumes/#secret)
      type: secret
      # -- `true` to [mount the secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-files-from-a-pod) in read only mode
      readOnly: true
  proxy:
    data:
      # -- name for the [persistent volume claim](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) requested for the ProxySQL [data directory](https://proxysql.com/documentation/configuration-file/#general-variables)
      claimName: proxysql
      # -- mount path of the persistent volume in the container used for the for the ProxySQL data directory
      mountPath: /opt/proxysql/data
      # -- volume type [(persistent)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
      type: persistentVolume

volumeClaimTemplates:
  mariadb:
    # -- [access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) for the MariaDB data volume
    accessModes: [ReadWriteOnce]
    # -- capacity for the MariaDB data volume
    capacity: 10Gi
    # -- custom storageclass (currently `cinder` and `nfs` are supported) for the MariaDB data volume
    storageClassName: false
  marialog:
    # -- [access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) for the MariaDB log volume
    accessModes: [ReadWriteOnce]
    # -- capacity for the MariaDB log volume
    capacity: 30Gi
    # -- custom storageclass (currently `cinder` and `nfs` are supported) for the MariaDB log volume
    storageClassName: false
  proxysql:
    # -- [access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) for the ProxySQL data volume
    accessModes: [ReadWriteOnce]
    # -- capacity for the ProxySQL data volume
    capacity: 128Mi
    # -- custom storageclass (currently `cinder` and `nfs` are supported) for the ProxySQL data volume
    storageClassName: false

# Resource limits per container
resourceLimits:
  cpu:
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB containers
    # @default -- 0.5
    application: 2
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the Monitoring sidecar containers for MariaDB
    # @default -- 0.25
    monitoring: 0.5
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB configuration job
    # @default -- 0.25
    jobconfig: 0.5
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB restore job
    # @default -- 0.25
    jobrestore: 0.5
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB backup cronjob
    # @default -- 0.25
    cronjob: 2
    # -- CPU [resource reservation(request)](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the ProxySQL containers
    # @default -- 0.5
    proxy: 2
  memory:
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB containers
    # @default -- 64Mi
    application: 1024Mi
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the Monitoring sidecar containers for MariaDB
    # @default -- 32Mi
    monitoring: 48Mi
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB configuration job
    # @default -- 32Mi
    jobconfig: 48Mi
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB restore job
    # @default -- 128Mi
    jobrestore: 256Mi
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the MariaDB backup cronjob
    # @default -- 32Mi
    cronjob: 1024Mi
    # -- RAM [resource limit](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits) for the ProxySQL containers
    # @default -- 64Mi
    proxy: 256Mi

# Deployment rules
replicas:
  # -- amount of pods that will [scheduled](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment) for the MariaDB Galera cluster.
  # An uneven number will be enforced to avoid simple split brain situations. For a good balance between the write and read performance not more than 3 pods a suggested
  # @default -- 3
  application: 3
  # -- amount of pods that will [scheduled](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment) for the ProxySQL cluster.
  # An uneven number will be enforced to avoid simple split brain situations
  # @default -- 3
  proxy: 3
maxUnavailable:
  # -- number of MariaDB pods that can be [unavailable](https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget) during a rolling upgrade
  # @default -- 1
  application: 1
  # -- number of ProxySQL pods that can be [unavailable](https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget) during a rolling upgrade
  # @default -- 1
  proxy: 1

hpa:
  application:
    # -- enable [horizontal pod autoscaling](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) for the MariaDB Galera pods.
    # Currently not suggested because even replica numbers cannot be avoided
    # @default -- false
    enabled: false
    # -- minimum number of replicas allowed for the MariaDB Galera pods
    # @default -- 3
    minReplicas: 3
    # -- maximum number of replicas allowed for the MariaDB Galera pods
    # @default -- 5
    maxReplicas: 3
    # -- average CPU usage in percent across all MariaDB Galera pods that triggers the scaling process
    # @default -- 66
    maxCpuPercent: 50
  proxy:
    # -- enable [horizontal pod autoscaling](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/) for the ProxySQL cluster pods.
    # Currently not suggested because even replica numbers cannot be avoided
    # @default -- false
    enabled: false
    # -- minimum number of replicas allowed for the ProxySQL cluster pods
    # @default -- 3
    minReplicas: 3
    # -- maximum number of replicas allowed for the ProxySQL cluster pods
    # @default -- 5
    maxReplicas: 3
    # -- average CPU usage in percent across all ProxySQL cluster pods that triggers the scaling process
    # @default -- 66
    maxCpuPercent: 50

# -- [Update strategy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies) for the MariaDB Galera and ProxySQL cluster pods.
# @default -- RollingUpdate
updateStrategy: RollingUpdate
# -- [Pod Management Policy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies) for the MariaDB Galera and ProxySQL cluster pods.
# @default -- OrderedReady
podManagementPolicy: Parallel
# -- how many [versions](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#clean-up-policy) of the rolled out statefulsets for the MariaDB Galera and ProxySQL cluster pods should be kept
# @default -- 10
revisionHistoryLimit: 3
# -- how many seconds should [Kubernetes wait](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution) before forcefully stopping a MariaDB Galera and ProxySQL cluster pod.
# During the MariaDB [full database restore](#full-database-restore) process that value will be reduced to 15 seconds
# @default -- 86400
terminationGracePeriodSeconds: 600
# -- If enabled `topology.kubernetes.io/zone` infos will be added to the [podAntiAffinity rules](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/) for the MariaDB Galera and ProxySQL cluster.
# This is useful if the Kubernetes provider supports regional node pools to ensure a good pod distribution within that region
regional: false
job:
  mariadbconfig:
    # -- How many [retries](https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-backoff-failure-policy) before the MariaDB config job will be marked as failed
    # @default -- 6
    backoffLimit: 12
    # -- Maximum [allowed runtime](https://kubernetes.io/docs/concepts/workloads/controllers/job/#job-termination-and-cleanup) before the MariaDB config job will be stopped
    # @default -- 300
    activeDeadlineSeconds: 600
    # -- After how many seconds will a stopped MariaDB config job be [deleted from the Kubernetes cluster](https://kubernetes.io/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically)
    # @default -- 120
    ttlSecondsAfterFinished: 7200
    # -- Define how the MariaDB config job pod [will be restarted](https://kubernetes.io/docs/concepts/workloads/controllers/job/#handling-pod-and-container-failures) in case of an error.
    # It can be on the same worker node or another
    # @default -- OnFailure
    jobRestartPolicy: OnFailure
  mariadbbackup:
    # -- [Schedule](https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#schedule) for the MariaDB backup job based on that [syntax](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax)
    # @default -- 05 23 * * *
    schedule: "*/15 * * * *"
    # -- Define how the MariaDB backup job pod [will be restarted](https://kubernetes.io/docs/concepts/workloads/controllers/job/#handling-pod-and-container-failures) in case of an error.
    # It can be on the same worker node or another
    # @default -- OnFailure
    jobRestartPolicy: OnFailure
    # -- Define if and how MariaDB backup jobs can run in [parallel](https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#concurrency-policy)
    # @default -- Forbid
    concurrencyPolicy: Forbid
    # -- Define how how many completed MariaDB backup jobs [should be kept](https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#jobs-history-limits)
    # @default -- 1
    successfulJobsHistoryLimit: 1
    # -- Define how how many failed MariaDB backup jobs [should be kept](https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/#jobs-history-limits)
    # @default -- 1
    failedJobsHistoryLimit: 1
  mariadbrestore:
    # -- How many [retries](https://kubernetes.io/docs/concepts/workloads/controllers/job/#pod-backoff-failure-policy) before the MariaDB restore job will be marked as failed
    # @default -- 0
    backoffLimit: 0
    # -- Maximum [allowed runtime](https://kubernetes.io/docs/concepts/workloads/controllers/job/#job-termination-and-cleanup) before the MariaDB restore job will be stopped
    # @default -- 3600
    activeDeadlineSeconds: 7200
    # -- After how many seconds will a stopped MariaDB restore job be [deleted from the Kubernetes cluster](https://kubernetes.io/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically)
    # @default -- 43200
    ttlSecondsAfterFinished: 86400
    # -- Define how the MariaDB restore job pod [will be restarted](https://kubernetes.io/docs/concepts/workloads/controllers/job/#handling-pod-and-container-failures) in case of an error.
    # It can be on the same worker node or another
    # @default -- Never
    jobRestartPolicy: Never

#Container Health Checks
startupProbe:
  initialDelaySeconds:
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the startup probe for MariaDB Galera pods
    # @default -- 60
    application: 15
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the startup probe for ProxySQL cluster pods
    # @default -- 60
    proxy: 15
  periodSeconds:
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the startup probe for MariaDB Galera pods
    # @default -- 30
    application: 10
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the startup probe for ProxySQL cluster pods
    # @default -- 30
    proxy: 10
  failureThreshold:
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the startup probe for the MariaDB Galera pods is marked as failed
    # @default -- 4
    application: 12
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the startup probe for the ProxySQL cluster pods is marked as failed
    # @default -- 4
    proxy: 12
  timeoutSeconds:
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the startup probe for the MariaDB Galera pods
    # @default -- 20
    application: 20
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the startup probe for the ProxySQL cluster pods
    # @default -- 20
    proxy: 20
livenessProbe:
  initialDelaySeconds:
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for MariaDB Galera pods
    # @default -- 60
    application: 15
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for MariaDB monitoring sidecar container
    # @default -- 5
    monitoring: 5
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for ProxySQL cluster pods
    # @default -- 60
    proxy: 15
  periodSeconds:
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for MariaDB Galera pods
    # @default -- 30
    application: 30
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for MariaDB monitoring sidecar container
    # @default -- 30
    monitoring: 30
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the liveness probe for ProxySQL cluster pods
    # @default -- 30
    proxy: 30
  failureThreshold:
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the liveness probe for the MariaDB Galera pods is marked as failed
    # @default -- 4
    application: 4
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the liveness probe for the MariaDB monitoring sidecar container is marked as failed
    # @default -- 4
    monitoring: 4
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the liveness probe for the ProxySQL cluster pods is marked as failed
    # @default -- 4
    proxy: 4
  timeoutSeconds:
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the liveness probe for the MariaDB Galera pods
    # @default -- 20
    application: 20
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the liveness probe for the MariaDB monitoring sidecar container
    # @default -- 20
    monitoring: 20
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the liveness probe for the ProxySQL cluster pods
    # @default -- 20
    proxy: 20
readinessProbe:
  initialDelaySeconds:
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for MariaDB Galera pods
    # @default -- 90
    application: 30
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for MariaDB monitoring sidecar container
    # @default -- 10
    monitoring: 10
    # -- Define the [initial delay](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for ProxySQL cluster pods
    # @default -- 90
    proxy: 30
  periodSeconds:
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for MariaDB Galera pods
    # @default -- 20
    application: 20
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for MariaDB monitoring sidecar container
    # @default -- 20
    monitoring: 20
    # -- Define the [check interval](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) of the readiness probe for ProxySQL cluster pods
    # @default -- 20
    proxy: 20
  successThreshold:
    # -- After [how many](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) checks the readiness probe for the MariaDB Galera pods will be marked as successful
    # @default -- 1
    application: 1
    # -- After [how many](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) checks the readiness probe for the MariaDB monitoring sidecar container will be marked as successful
    # @default -- 1
    monitoring: 1
    # -- After [how many](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) checks the readiness probe for the ProxySQL cluster pods will be marked as successful
    # @default -- 1
    proxy: 1
  failureThreshold:
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the readiness probe for the MariaDB Galera pods is marked as failed
    # @default -- 2
    application: 3
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the readiness probe for the MariaDB monitoring sidecar container is marked as failed
    # @default -- 2
    monitoring: 3
    # -- How many [retries](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) are allowed before the readiness probe for the ProxySQL cluster pods is marked as failed
    # @default -- 2
    proxy: 3
  timeoutSeconds:
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the readiness probe for the MariaDB Galera pods
    # @default -- 10
    application: 10
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the readiness probe for the MariaDB monitoring sidecar container
    # @default -- 10
    monitoring: 10
    # -- How long should Kubernetes [wait](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) for the current check of the readiness probe for the ProxySQL cluster pods
    # @default -- 10
    proxy: 10

env:
  MARIADB_CLUSTER_NAME:
    # -- Name of the MariaDB Galera cluster defined with the [wsrep_cluster_name](https://mariadb.com/kb/en/galera-cluster-system-variables/#wsrep_cluster_name) option
    value: eu-de-1.nova
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - cronjob
  MARIADB_ROOT_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `MariaDB root user`
    secretName: db-full-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `MariaDB root user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - jobrestore
      - proxy
      - cronjob
  MARIADB_ROOT_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `MariaDB root user`
    secretName: db-full-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `MariaDB root user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - jobrestore
      - proxy
      - cronjob
  GALERA_SST_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `MariaDB Galera state snapshot transfer user`
    secretName: ga-sync-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `MariaDB Galera state snapshot transfer user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - proxy
  GALERA_SST_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `MariaDB Galera state snapshot transfer user`
    secretName: ga-sync-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `MariaDB Galera state snapshot transfer user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - proxy
  MARIADB_MONITORING_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `MariaDB monitoring user`
    secretName: db-mon-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `MariaDB monitoring user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - monitoring
      - jobconfig
  MARIADB_MONITORING_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `MariaDB monitoring user`
    secretName: db-mon-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `MariaDB monitoring user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - monitoring
      - jobconfig
  MARIADB_MONITORING_CONNECTION_LIMIT:
    # -- maximum number of allowed parallel connections for the `MariaDB monitoring user` defined within the [MAX_USER_CONNECTIONS](https://mariadb.com/kb/en/create-user/#resource-limit-options) option
    value: 6
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
  WEB_TELEMETRY_PATH:
    # -- The MySQL exporter monitoring sidecar container will expose the [Prometheus metrics](https://github.com/prometheus/mysqld_exporter#general-flags) under that path
    value: /metrics
    # -- for which containers this environment variable will be used
    containerType:
      - monitoring
  PROXYSQL_ADMIN_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `ProxySQL admin user`
    secretName: proxy-full-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `ProxySQL admin user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  PROXYSQL_ADMIN_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `ProxySQL admin user`
    secretName: proxy-full-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `ProxySQL admin user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  PROXYSQL_MONITOR_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `ProxySQL monitoring user for MariaDB`
    secretName: db-mon-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `ProxySQL monitoring user for MariaDB`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  PROXYSQL_MONITOR_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `ProxySQL monitoring user for MariaDB`
    secretName: db-mon-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `ProxySQL monitoring user for MariaDB`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  PROXYSQL_STATS_USER:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `ProxySQL statistics user`
    secretName: proxy-stats-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `ProxySQL statistics user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  PROXYSQL_STATS_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `ProxySQL statistics user`
    secretName: proxy-stats-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `ProxySQL statistics user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - proxy
  OPENSTACK_CITEST_USERNAME:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `Openstack oslo.db unit test user`
    secretName: db-oslodb-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `Openstack oslo.db unit test user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - jobconfig
      - proxy
  OPENSTACK_CITEST_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `Openstack oslo.db unit test user`
    secretName: db-oslodb-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `Openstack oslo.db unit test user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - jobconfig
      - proxy
  SYSBENCH_USERNAME:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `sysbench user`
    secretName: db-sysbench-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `sysbench user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - jobconfig
      - proxy
  SYSBENCH_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `sysbench user`
    secretName: db-sysbench-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `sysbench user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - jobconfig
      - proxy
  OS_USERNAME:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `Openstack swift user for restic`
    secretName: restic-swift-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `Openstack swift user for restic`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - cronjob
      - jobrestore
  OS_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `Openstack swift user for restic`
    secretName: restic-swift-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `Openstack swift user for restic`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - cronjob
      - jobrestore
  RESTIC_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `Restic repository encryption key`
    secretName: restic-repo-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `Restic repository encryption key`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - cronjob
      - jobrestore
  REPLICA_USERNAME:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `username` of the `MariaDB async replication user`
    secretName: replica-primary-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `username` for the `MariaDB async replication user`
    secretKey: username
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - proxy
  REPLICA_PASSWORD:
    # -- Name of the predefined [Kubernetes secret](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables) that contains the key for the `password` of the `MariaDB async replication user`
    secretName: replica-primary-auth
    # -- Name of the key of the predefined Kubernetes secret that contains the `password` for the `MariaDB async replication user`
    secretKey: password
    # -- for which containers this environment variable will be used
    containerType:
      - application
      - jobconfig
      - proxy
#command:
#   application:
#     - "sh"
#     - "-c"
#     - "/bin/sleep 3600"
#   monitoring:
#     - "sh"
#     - "-c"
#     - "/bin/sleep 3600"
#    jobconfig:
#     - "sh"
#     - "-c"
#     - "/bin/sleep 3600"
#    jobrestore:
#     - "sh"
#     - "-c"
#     - "/bin/sleep 3600"
#  cronjob:
#    - "sh"
#    - "-c"
#    - "/bin/sleep 3600"
#   proxy:
#     - "sh"
#     - "-c"
#     - "/bin/sleep 3600"
