# Default values for nova.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value
global:
  novaApiPortAdmin: '8774'
  novaApiPortInternal: '8774'
  novaApiPortPublic: '443'
  novaApiMetadataPortInternal: '8775'
  novaConsolePortPublic: '443'
  placementApiPortAdmin: '8778'
  placementApiPortInternal: '8778'
  placementApiPortPublic: '443'
  master_password: null

  dbUser: nova

  nova_service_user: nova
  placement_service_user: placement

  hypervisors: []
  enable_kvm: false
  # this being an empty list means autodetection by KosOperator
  hypervisors_kvm: []
  hypervisors_ironic: []
  osprofiler: {}
  pgbouncer:
    enabled: true

osprofiler: {}

auto_assign_aggregates: 'dry_run'

use_tls_acme: true

cell2:
  name: cell2
  enabled: false
  conductor:
    config_file: {}

defaults:
  default:
    graceful_shutdown_timeout: 60
  hypervisor:
    common:
      default:
        reserved_host_memory_mb: 512
        disk_allocation_ratio: "1.0"
        reserved_host_disk_mb: "0"
    ironic:
      default:
        reserved_host_memory_mb: "0"
        compute_driver: ironic.IronicDriver
        graceful_shutdown_timeout: 1800
      ironic:
        serial_console_state_timeout: 10
    kvm:
      default:
        compute_driver: libvirt.LibvirtDriver
        firewall_driver: nova.virt.firewall.NoopFirewallDriver
        resume_guests_state_on_host_boot: true

pod:
  replicas:
    api: 6
    metadata: 2
    console: 2
    consoleauth: 2
    conductor: 2
    scheduler: 1
    placement: 2
    vspc: 4
  lifecycle:
    upgrades:
      deployments:
        revision_history: 5
        podReplacementStrategy: RollingUpdate
        rollingUpdate:
          maxUnavailable: 0
          maxSurge: 1
  debug:
    api: false
  resources:
    api:
      requests:
        cpu: "4000m"
        memory: "6Gi"
    metadata:
      requests:
        cpu: "500m"
        memory: "3Gi"
    bigvm:
      requests:
        cpu: "100m"
        memory: "256m"
    conductor:
      requests:
        cpu: "1500m"
        memory: "7Gi"
    placement:
      requests:
        cpu: "400m"
        memory: "150Mi"
    scheduler:
      requests:
        cpu: "500m"
        memory: "4Gi"
    hv_ironic:
      requests:
        cpu: "150m"
        memory: "200Mi"
    hv_vmware:
      requests:
        cpu: "1000m"
        memory: "1Gi"
    hv_vmware_dvs:
      requests:
        cpu: "1000m"
        memory: "2Gi"
    vspc:
      requests:
        cpu: "200m"
        memory: "2Gi"
      limits:
        memory: "12Gi"

debug: "True"

dbName: nova
dbUser: nova
dbPassword: null

cell0dbName: nova_cell0
cell0dbUser: nova_cell0
cell0dbPassword: null

# cell2dbName should be the same as mariadb_cell2 backup_v2 DB name!
cell2dbName: nova_cell2
cell2dbUser: nova_cell2
cell2dbPassword: null

apidbName: nova_api
apidbUser: nova_api
apidbPassword: null

portMetrics: '9102'

loci:
  nova: false
  openvswitch: false
  # neutron images use loci by default

#TODO we need to move to global or find another way to share image versions
imageNameNeutron: loci-neutron
imageVersionNeutronServer: null
imageVersionNeutronOpenvswitchAgent: null

imageNameOpenvswitch: loci-neutron
imageVersionOpenvswitchVswitchd: null
imageVersionOpenvswitchDbServer: null

imageNameNova: loci-nova
imageVersionNova: null
imageVersionNovaApi: null
imageVersionNovaCompute: null
imageVersionNovaLibvirt: null
imageVersionNovaConductor: null
imageVersionNovaConsoleauth: null
imageVersionNovaNovncproxy: null
imageVersionNovaShellinaboxproxy: null
imageVersionNovaSpicehtml5proxy: null
imageVersionNovaScheduler: null
imageVersionNovaPlacementApi: null

vspc:
  enabled: false
  telnet:
    portInternal: 1333
    portExternal: 1333
  web:
    portInternal: 1334
    portExternal: 1334
  nodeIP: null
  url: vmware-vspc
  version: "20210111143046"
  pvc:
    existingClaim: null
    accessMode: ReadWriteMany
    size: 10Gi


# I would move all that to the neutron deployment
neutron: {}
neutron_dvs_agent_enabled: true

cross_az_attach: 'False'
# for a total of 11 tries with 0.5s sleep in between we could get away with < 5s of problems
cinder_http_retries: 10
neutron_http_retries: 10
neutron_timeout: 600

api:
  config_file:
    DEFAULT:
      api_paste_config: /etc/nova/api-paste.ini
      enabled_apis: osapi_compute
      use_forwarded_for: true
      osapi_compute_workers: 4

    api:
      list_records_by_skipping_down_cells: false
      use_forwarded_for: true

    wsgi:
      api_paste_config: /etc/nova/api-paste.ini

  use_uwsgi: false
  wsgi_processes: 8

api_metadata:
  config_file:
    DEFAULT:
      api_paste_config: /etc/nova/api-paste.ini
      enabled_apis: metadata
      use_forwarded_for: true
      metadata_workers: 4

    api:
      use_forwarded_for: true

    wsgi:
      api_paste_config: /etc/nova/api-paste.ini

consoles:
  novnc:
    enabled: false
    portInternal: '6080'
  serial:
    enabled: true
    portInternal: '6083'
  shellinabox:
    enabled: true
    portInternal: '6084'
  spice:
    enabled: false
  mks:
    enabled: true
    portInternal: '6090'
    args: '--web /usr/local/noVNC-mks --verbose'
    inject_nova_credentials: true

scheduler:
  driver: "filter_scheduler"
  scheduler_tracks_instance_changes: false
  scheduler_instance_sync_interval: 120
  default_filters: "AvailabilityZoneFilter, CpuInfoMigrationFilter, ShardFilter, AggregateMultiTenancyIsolation, RamFilter, DiskFilter, ComputeFilter, ComputeCapabilitiesFilter, BigVmFlavorHostSizeFilter, VmSizeThresholdFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter"
  vm_size_threshold_vm_size_mb: "8193"
  vm_size_threshold_hv_size_mb: "819200"
  ram_weight_multiplier: 1.0
  cpu_weight_multiplier: 1.0
  disk_weight_multiplier: 1.0
  io_ops_weight_multiplier: 0.0
  soft_affinity_weight_multiplier: 1.0
  # The following weighers are crutches, but we can't express it otherwise
  # currently. They should overpower the other weighers even in worst-case
  # (e.g. least ram available + worst disk weight), so we have to make it >=
  # len(other_weighers). At the same time, we, want a VM to not move on resize,
  # if it doesn't have to - even if it's in the wrong RAM class currently.
  prefer_same_host_resize_weight_multiplier: 1000.0
  hv_ram_class_weight_multiplier: 100.0

compute:
  defaults:
    host_username: m3novaapiuser
    default:
      max_concurrent_builds_per_project: 20
      max_concurrent_builds: 50
      ram_allocation_ratio: 1.0
      cpu_allocation_ratio: 4.0
      # this will set a 15 mins timeout for blockdevice mapping
      block_device_allocate_retries: 300
    vmware:
      insecure: true
      use_linked_clone: false
      pbm_enabled: false
      pbm_default_policy: "nova-ephemeral"
      smbios_asset_tag: "SAP CCloud VM"
      bigvm_deployment_free_host_hostgroup_name: "bigvm_free_host_antiaffinity_hostroup"
      clone_from_snapshot: false
      full_clone_snapshots: true
      # maximum of vSphere 6.5
      default_hw_version: vmx-13
      memory_reservation_cluster_hosts_max_fail: 2
      memory_reservation_max_ratio_fallback: 0.8

conductor:
  config_file:
    conductor:
      workers: 8

quota:
  # most default quotas are 0 to enforce usage of the Resource Management tool in Elektra
  cores: 0
  instances: 0
  ram: 0
  networks: 0

  server_group_members: 40  # this is set by limes now
  # we don't want to set unlimited because that has too much potential to break things
  key_pairs: 10000


placement:
  enabled: false
  wsgi_processes: 10

mysql_metrics:
  db_name: nova
  db_user: nova
  customMetrics:
    - help: Total Nova VM count
      labels:
      - "project_id"
      - "vm_state"
      - "nova_host"
      - "flavor_name"
      name: openstack_compute_instances_gauge
      query: |
        SELECT
          coalesce(instances.host,'N/A') AS nova_host,
          instances.project_id,
          COUNT(*) AS gauge,
          instances.vm_state,
          coalesce(instance_types.name,'N/A') AS flavor_name
        FROM instances
        JOIN instance_types ON instances.instance_type_id=instance_types.id
        GROUP BY instances.vm_state, instances.host, instances.project_id, instance_types.name;
      values:
      - "gauge"
    - help: Total Nova VM Stuck count
      labels:
      - "project_id"
      - "task_state"
      - "nova_host"
      - "uuid"
      - "availability_zone"
      name: openstack_compute_stuck_instances_count_gauge
      query: |
        SELECT coalesce(host, 'N/A') AS nova_host,
          project_id,
          uuid,
          availability_zone,
          task_state,
          SUM(IF(updated_at < DATE_SUB(now(), INTERVAL 15 MINUTE), 1, 0)) AS count_gauge,
          MAX((NOW() - updated_at)) AS max_duration_gauge
        FROM instances
        WHERE task_state IN ('scheduling','pausing','unpausing','suspending','resuming','rescuing','unrescuing','rebuilding','migrating','deleting','restoring','shelving','unshelving','building','deleting','stopping','starting','spawning','rebooting') AND deleted=0
        GROUP BY host, project_id, uuid, availability_zone, task_state UNION ALL SELECT 'dummy-row', 'None', 'None', 'None', 'None', 0, 0;
      values:
      - "count_gauge"
    - help: Total Nova VM Stuck count max duration
      labels:
      - "project_id"
      - "task_state"
      - "nova_host"
      - "uuid"
      - "availability_zone"
      name: openstack_compute_stuck_instances_max_duration_gauge
      query: |
        SELECT coalesce(host, 'N/A') AS nova_host,
          project_id,
          uuid,
          availability_zone,
          task_state,
          SUM(IF(updated_at < DATE_SUB(now(), INTERVAL 15 MINUTE), 1, 0)) AS count_gauge,
          MAX((NOW() - updated_at)) AS max_duration_gauge
        FROM instances
        WHERE task_state IN ('scheduling','pausing','unpausing','suspending','resuming','rescuing','unrescuing','rebuilding','migrating','deleting','restoring','shelving','unshelving','building','deleting','stopping','starting','spawning','rebooting') AND deleted=0
        GROUP BY host, project_id, uuid, availability_zone, task_state UNION ALL SELECT 'dummy-row', 'None', 'None', 'None', 'None', 0, 0;
      values:
      - "max_duration_gauge"
    - help: Instance launch time in the last 24 hours
      labels:
      - "nova_host"
      - "project_id"
      - "uuid"
      - "vm_state"
      name: openstack_compute_instance_launch_time_taken_gauge
      query: |
        SELECT coalesce(host, 'N/A') AS nova_host,
          project_id,
          uuid,
          vm_state,
          MAX(launched_at - created_at) AS time_taken_gauge
        FROM instances
        WHERE (launched_at IS NOT NULL AND launched_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND NOT host LIKE 'nova-compute-ironic%'
        GROUP BY host, project_id, uuid, vm_state;
      values:
      - "time_taken_gauge"
    - help: Instance termination time in the last 24 hours
      labels:
      - "nova_host"
      - "project_id"
      - "uuid"
      - "vm_state"
      name: openstack_compute_instance_termination_time_taken_gauge
      query: |
        SELECT coalesce(host, 'N/A') AS nova_host,
          project_id,
          uuid,
          vm_state,
          MAX(updated_at - terminated_at) AS time_taken_gauge
        FROM instances
        WHERE (terminated_at IS NOT NULL AND terminated_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND NOT host LIKE 'nova-compute-ironic%'
        GROUP BY host, project_id, uuid, vm_state;
      values:
      - "time_taken_gauge"
    - help: Instances created in the past 24 hours
      labels:
      - "nova_host"
      - "uuid"
      - "vm_state"
      name: openstack_compute_instance_created_in_24hrs_gauge
      query: |
        SELECT coalesce(host, 'N/A') AS nova_host,
          uuid,
          vm_state,
          COUNT(*) AS in_24hrs_gauge
        FROM instances
        WHERE (created_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND NOT host LIKE 'nova-compute-ironic%'
        AND deleted=0
        GROUP BY host, uuid, vm_state;
      values:
      - "in_24hrs_gauge"
    - help: Nodes Launch time in the past 24 hours
      labels:
      - "project_id"
      - "uuid"
      - "vm_state"
      - "hostname"
      - "node"
      name: openstack_ironic_instances_launch_time_taken_gauge
      query: |
        SELECT project_id,
          uuid,
          node AS node_id,
          hostname,
          vm_state,
          MAX(launched_at - created_at) AS time_taken_gauge
        FROM instances
        WHERE (launched_at IS NOT NULL AND launched_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND host LIKE 'nova-compute-ironic%'
        GROUP BY project_id, uuid, vm_state, hostname, node;
      values:
      - "time_taken_gauge"
    - help: Nodes termination time in past 24 hours
      labels:
      - "project_id"
      - "uuid"
      - "vm_state"
      - "hostname"
      - "node"
      name: openstack_ironic_instances_termination_time_taken_gauge
      query: |
        SELECT project_id,
          uuid,
          hostname,
          node AS node_id,
          vm_state,
          MAX(updated_at - terminated_at) AS time_taken_gauge
        FROM instances
        WHERE (terminated_at IS NOT NULL AND terminated_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND host LIKE 'nova-compute-ironic%'
        GROUP BY project_id, uuid, vm_state, hostname, node;
      values:
      - "time_taken_gauge"
    - help: Nodes created in past 24 hours
      labels:
      - "uuid"
      - "vm_state"
      - "hostname"
      - "node"
      name: openstack_ironic_instances_created_in_24hrs
      query: |
        SELECT uuid,
          hostname,
          node AS node_id,
          vm_state,
          COUNT(*) AS in_24hrs
        FROM instances
        WHERE (created_at >= DATE_SUB(now(), INTERVAL 24 HOUR))
        AND host LIKE 'nova-compute-ironic%'
        GROUP BY uuid, vm_state, hostname, node
        UNION SELECT 'none' AS uuid, 'none' AS hostname, 'none' AS node_id, 'none' AS vm_state, 0 AS in_24hrs;
      values:
      - "in_24hrs"
    - help: Total Node count
      labels:
      - "vm_state"
      - "project_id"
      - "flavor_name"
      - "uuid"
      - "hostname"
      - "node_id"
      name: openstack_ironic_instances_gauge
      query: |
        SELECT
          instances.uuid,
          instances.node AS node_id,
          instances.project_id,
          instances.hostname,
          instances.vm_state,
          coalesce(instance_types.name,'N/A') AS flavor_name,
          COUNT(*) AS gauge
        FROM instances
        JOIN instance_types ON instances.instance_type_id=instance_types.id where host LIKE 'nova-compute-ironic%'
        GROUP BY instances.vm_state, instances.project_id, instance_types.name, instances.uuid, instances.hostname, instances.node;
      values:
      - "gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_free_disk_gb_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.free_disk_gb, 0) AS free_disk_gb_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "free_disk_gb_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_local_gb_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.local_gb, 0) AS local_gb_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "local_gb_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_local_gb_used_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.local_gb_used, 0) AS local_gb_used_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "local_gb_used_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_free_ram_mb_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.free_ram_mb, 0) AS free_ram_mb_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "free_ram_mb_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_memory_mb_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.memory_mb, 0) AS memory_mb_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "memory_mb_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_memory_mb_used_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.memory_mb_used, 0) AS memory_mb_used_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "memory_mb_used_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_vcpus_used_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.vcpus_used, 0) AS vcpus_used_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "vcpus_used_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_vcpus_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.vcpus, 0) AS vcpus_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "vcpus_gauge"
    - help: Stats on compute nodes
      labels:
      - "nova_host"
      - "uuid"
      - "hypervisor_type"
      name: openstack_compute_nodes_running_vms_gauge
      query: |
        SELECT
          COALESCE(compute_nodes.host, 'N/A') AS nova_host, compute_nodes.uuid, compute_nodes.hypervisor_type,
          COALESCE(compute_nodes.running_vms, 0) AS running_vms_gauge
        FROM compute_nodes
        WHERE compute_nodes.deleted=0;
      values:
      - "running_vms_gauge"
    - help: Version of the service running
      labels:
      - "id"
      - "nova_host"
      - "binary"
      name: openstack_compute_service_version
      query: |
        SELECT
          id, coalesce(host, 'N/A') AS nova_host, `binary`, version
        FROM services
        WHERE deleted_at is NULL;
      values:
      - "version"

postgresql:
  enabled: false

postgresql_cell2:
  enabled: false

db_name: nova
max_pool_size: 10
max_overflow: 5

mariadb:
  enabled: false
  max_connections: 2048
  buffer_pool_size: "4096M"
  log_file_size: "1024M"
  name: nova
  custom_initdb_configmap: nova-mysql-db-init
  persistence_claim:
    name: db-nova-pvc
    size: "50Gi"
  backup:
    enabled: false
  backup_v2:
    enabled: true
    databases:
      - nova
      - nova_cell0
    verify_tables:
      - nova.services
      - nova.instance_metadata
      - nova_cell0.instance_metadata
    oauth:
      client_id: "nova"

mariadb_api:
  enabled: false
  buffer_pool_size: "4096M"
  log_file_size: "1024M"
  name: nova-api
  custom_initdb_configmap: nova-api-db-init
  persistence_claim:
    name: db-nova-api-pvc
    size: "50Gi"
  backup:
    enabled: false
  backup_v2:
    enabled: true
    databases:
      - nova_api
    verify_tables:
      - nova_api.flavors
      - nova_api.key_pairs
    oauth:
      client_id: "nova-api"

mariadb_cell2:
  enabled: false
  buffer_pool_size: "4096M"
  log_file_size: "1024M"
  custom_initdb_configmap: nova-cell2-db-init
  persistence_claim:
    name: db-nova-cell2-pvc
    size: "50Gi"
  backup:
    enabled: false
  backup_v2:
    enabled: true
    oauth:
      client_id: "nova-cell2"

rabbitmq_cell2:
  name: nova-cell2
  persistence:
    enabled: false

  alerts:
    # unacked/ready messages in rabbitmq
    rabbit_queue_length: 50
    unacknowledged_total_wait_for: 10m
    ready_total_wait_for: 10m

audit:
  enabled: false
  # how many messages to buffer before dumping to log (when rabbit is down or too slow)
  mem_queue_size: 1000
  record_payloads: false
  metrics_enabled: true

rabbitmq:
  name: nova
  users:
    default:
      password: null
    admin:
      password: null
  persistence:
    enabled: false
  metrics:
    password: null

  resources:
    requests:
      memory: 2Gi
      cpu: 1000m

  alerts:
    # unacked/ready messages in rabbitmq
    rabbit_queue_length: 50
    unacknowledged_total_wait_for: 10m
    ready_total_wait_for: 10m

rabbitmq_notifications:
  name: nova
  persistence:
    enabled: false

logging:
  formatters:
    context:
      class: oslo_log.formatters.ContextFormatter
    default:
      format: "%(message)s"
  handlers:
    stdout:
      class: StreamHandler
      args: "(sys.stdout,)"
      formatter: context
    "null":
      class: logging.NullHandler
      args: "()"
      formatter: default
    sentry:
      class: raven.handlers.logging.SentryHandler
      level: ERROR
      args: "()"
  loggers:
    root:
      handlers: stdout, sentry
      level: WARNING
    migrate:
      handlers: stdout, sentry
      level: INFO
    nova:
      handlers: stdout, sentry
      level: INFO
    nova.scheduler:
      handlers: stdout, sentry
      level: DEBUG
    nova.scheduler.host_manager: # You might get problems with unicodedecode errors if you decrease that
      handlers: stdout, sentry
      level: INFO
    nova.virt.vmwareapi:
      handlers: stdout, sentry
      level: DEBUG
    eventlet.wsgi.server:
      handlers: stdout, sentry
      level: INFO
    oslo.privsep:
      handlers: stdout, sentry
      level: INFO
    suds:
      handlers: "null"
      level: ERROR
    oslo_vmware.common.loopingcall:
      handlers: "null"
      level: ERROR

# openstack-watcher-middleware
watcher:
  enabled: true

# Deploy Sentry Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which metrics should be exported
  prometheus: openstack

sentry:
  enabled: true

nova_bigvm_enabled: true
