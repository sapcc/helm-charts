# Default values for nova.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value
global:
  novaApiPortAdmin: '8774'
  novaApiPortInternal: '8774'
  novaApiPortPublic: '443'
  novaApiMetadataPortInternal: '8775'
  novaConsolePortPublic: '443'
  placementApiPortAdmin: '8778'
  placementApiPortInternal: '8778'
  placementApiPortPublic: '443'
  master_password: null

  dbUser: nova

  nova_service_user: nova
  placement_service_user: placement

  hypervisors: []
  hypervisors_kvm: []
  hypervisors_ironic: []
  osprofiler: {}
  pgbouncer:
    enabled: true
  novaApi:
    executable: nova-api

osprofiler: {}

auto_assign_aggregates: 'dry_run'

cell2:
  name: cell2
  enabled: false
  conductor: {}

defaults:
  default:
    graceful_shutdown_timeout: 60
  hypervisor:
    common:
      default:
        reserved_host_memory_mb: 512
        disk_allocation_ratio: "1.0"
        reserved_host_disk_mb: 0
    ironic:
      default:
        reserved_host_memory_mb: 0
        compute_driver: ironic.IronicDriver
        graceful_shutdown_timeout: 1800
      ironic:
        serial_console_state_timeout: 10
    kvm:
      default:
        compute_driver: libvirt.LibvirtDriver
        firewall_driver: nova.virt.firewall.NoopFirewallDriver
        resume_guests_state_on_host_boot: true

pod:
  replicas:
    api: 2
    metadata: 2
    console: 2
    consoleauth: 2
    conductor: 2
    scheduler: 1
    placement: 1
  lifecycle:
    upgrades:
      deployments:
        revision_history: 5
        podReplacementStrategy: RollingUpdate
        rollingUpdate:
          maxUnavailable: 0
          maxSurge: 1
  debug:
    api: false
  resources:
    api:
      requests:
        cpu: "12000m"
        memory: "13Gi"
    metadata:
      requests:
        cpu: "500m"
        memory: "3Gi"
    bigvm:
      requests:
        cpu: "100m"
        memory: "256m"
    conductor:
      requests:
        cpu: "1500m"
        memory: "7Gi"
    placement:
      requests:
        cpu: "400m"
        memory: "150Mi"
    scheduler:
      requests:
        cpu: "500m"
        memory: "4Gi"
    hv_ironic:
      requests:
        cpu: "150m"
        memory: "200Mi"
    hv_vmware:
      requests:
        cpu: "1000m"
        memory: "1Gi"
    hv_vmware_dvs:
      requests:
        cpu: "1000m"
        memory: "2Gi"

debug: "True"

dbName: nova
dbUser: nova
dbPassword: null

cell0dbName: nova_cell0
cell0dbUser: nova_cell0
cell0dbPassword: null

cell2dbName: nova_cell2
cell2dbUser: nova_cell2
cell2dbPassword: null

apidbName: nova_api
apidbUser: nova_api
apidbPassword: null

portMetrics: '9102'

sentry_dsn: DEFINE_IN_REGION_CHART

loci:
  nova: false
  openvswitch: false
  # neutron images use loci by default

#TODO we need to move to global or find another way to share image versions
imageNameNeutron: loci-neutron
imageVersionNeutronServer: null
imageVersionNeutronOpenvswitchAgent: null

imageNameOpenvswitch: loci-neutron
imageVersionOpenvswitchVswitchd: null
imageVersionOpenvswitchDbServer: null

imageNameNova: loci-nova
imageVersionNova: null
imageVersionNovaApi: null
imageVersionNovaCompute: null
imageVersionNovaLibvirt: null
imageVersionNovaConductor: null
imageVersionNovaConsoleauth: null
imageVersionNovaNovncproxy: null
imageVersionNovaShellinaboxproxy: null
imageVersionNovaSpicehtml5proxy: null
imageVersionNovaScheduler: null
imageVersionNovaPlacementApi: null

vspc:
  enabled: false
  telnet:
    portInternal: 1333
    portExternal: 1333
  web:
    portInternal: 1334
    portExternal: 1334
  nodeIP: null
  url: vmware-vspc
  version: "20181123173748"
  pvc:
    existingClaim: null
    accessMode: ReadWriteMany
    size: 10Gi


# I would move all that to the neutron deployment
neutron: {}
neutron_dvs_agent_enabled: true

cross_az_attach: 'False'

api:
  DEFAULT:
    api_paste_config: /etc/nova/api-paste.ini
    enabled_apis: osapi_compute
    use_forwarded_for: true

  api:
    list_records_by_skipping_down_cells: false

api_metadata:
  DEFAULT:
    api_paste_config: /etc/nova/api-paste.ini
    enabled_apis: metadata
    use_forwarded_for: true

consoles:
  novnc:
    portInternal: '6080'
  serial:
    portInternal: '6083'
  shellinabox:
    portInternal: '6084'
  mks:
    portInternal: '6090'
    args: '--web /usr/local/noVNC-mks --verbose'
    inject_nova_credentials: true

scheduler:
  driver: "filter_scheduler"
  scheduler_tracks_instance_changes: false
  scheduler_instance_sync_interval: 120
  default_filters: "AvailabilityZoneFilter, ShardFilter, AggregateMultiTenancyIsolation, RamFilter, DiskFilter, ComputeFilter, ComputeCapabilitiesFilter, BigVmFlavorHostSizeFilter, ImagePropertiesFilter, ServerGroupAntiAffinityFilter, ServerGroupAffinityFilter, BaremetalExactRamFilter, BaremetalExactCoreFilter, BaremetalExactDiskFilter"
  ram_weight_multiplier: 1.0
  disk_weight_multiplier: 1.0
  io_ops_weight_multiplier: 0.0
  soft_affinity_weight_multiplier: 1.0
  # the prefer-same-host weigher should be able to overpower a worst-case combination of other weighers
  # (e.g. least ram available + slightly bad disk weight), so make it >= len(other_weighers)
  prefer_same_host_resize_weight_multiplier: 5.0

compute:
  defaults:
    host_username: m3novaapiuser
    default:
      max_concurrent_builds_per_project: 20
      max_concurrent_builds: 50
      ram_allocation_ratio: 1.0
      cpu_allocation_ratio: 8.0
      # this will set a 15 mins timeout for blockdevice mapping
      block_device_allocate_retries: 300
    vmware:
      insecure: true
      use_linked_clone: false
      pbm_enabled: false
      pbm_default_policy: "nova-ephemeral"
      smbios_asset_tag: "SAP CCloud VM"
      bigvm_deployment_free_host_hostgroup_name: "bigvm_free_host_antiaffinity_hostroup"
      clone_from_snapshot: true
      full_clone_snapshots: true

conductor: {}

quota:
  # most default quotas are 0 to enforce usage of the Resource Management tool in Elektra
  cores: 0
  instances: 0
  ram: 0
  fixed_ips: 0
  floating_ips: 0
  networks: 0
  security_group_rules: 0
  security_groups: 0

  server_group_members: 40  # this is set by limes now
  # we don't want to set unlimited because that has too much potential to break things
  key_pairs: 10000


placement:
  enabled: false
  wsgi_processes: 10

pgmetrics:
  name: nova
  customMetrics:
    openstack_compute_instances:
      query: "SELECT coalesce(instances.host,'N/A') AS host, instances.project_id, COUNT(*) AS gauge, instances.vm_state, coalesce(instance_types.name,'N/A') AS flavor_name FROM instances JOIN instance_types ON instances.instance_type_id=instance_types.id GROUP BY instances.vm_state, instances.host, instances.project_id, instance_types.name"
      metrics:
        - project_id:
            usage: "LABEL"
            description: "Project ID"
        - vm_state:
            usage: "LABEL"
            description: "State of the VM"
        - host:
            usage: "LABEL"
            description: "Host Name"
        - flavor_name:
            usage: "LABEL"
            description: "Flavor Name of Instance"
        - gauge:
            usage: "GAUGE"
            description: "VM Count"
    openstack_compute_stuck_instances:
      query: "SELECT coalesce(host, 'N/A') AS host, project_id, uuid, availability_zone, vm_state, COUNT(*) FILTER (WHERE updated_at < now() - interval '15 minutes') AS count_gauge, MAX(EXTRACT(epoch FROM now() - updated_at)) AS max_duration_gauge FROM instances WHERE vm_state IN ('scheduling','pausing','unpausing','suspending','resuming','rescuing','unrescuing','rebuilding','migrating','deleting','restoring','shelving','unshelving','building','deleting','stopping','starting','spawning','rebooting') AND deleted=0 GROUP BY host, project_id, uuid, availability_zone, vm_state"
      metrics:
        - project_id:
            usage: "LABEL"
            description: "Project ID"
        - vm_state:
            usage: "LABEL"
            description: "State of the VM"
        - host:
            usage: "LABEL"
            description: "Host Name"
        - uuid:
            usage: "LABEL"
            description: "Instance ID"
        - availability_zone:
            usage: "LABEL"
            description: "AZ Name"
        - count_gauge:
            usage: "GAUGE"
            description: "VM Count"
        - max_duration_gauge:
            usage: "GAUGE"
            description: "Maximum duration of state"
    openstack_compute_instance_launch:
      query: "SELECT coalesce(host, 'N/A') AS host, project_id, uuid, vm_state, MAX(EXTRACT(epoch FROM launched_at - created_at)) AS time_taken_gauge FROM instances WHERE (launched_at IS NOT NULL AND launched_at >= now() - interval '24 hours') AND NOT host LIKE 'nova-compute-ironic%' GROUP BY host, project_id, uuid, vm_state"
      metrics:
        - host:
            usage: "LABEL"
            description: "Name of host"
        - project_id:
            usage: "LABEL"
            description: "Project ID of the instance"
        - uuid:
            usage: "LABEL"
            description: "Instance UUID"
        - vm_state:
            usage: "LABEL"
            description: "instance current state"
        - time_taken_gauge:
            usage: "GAUGE"
            description: "Instances termination time in past 24hrs"
    openstack_compute_instance_termination:
      query: "SELECT coalesce(host, 'N/A') AS host, project_id, uuid, vm_state, MAX(EXTRACT(epoch FROM updated_at - terminated_at)) AS time_taken_gauge FROM instances WHERE (terminated_at IS NOT NULL AND terminated_at >= now() - interval '24 hours') AND NOT host LIKE 'nova-compute-ironic%' GROUP BY host, project_id, uuid, vm_state"
      metrics:
        - host:
            usage: "LABEL"
            description: "Name of host"
        - project_id:
            usage: "LABEL"
            description: "Project ID of the instance"
        - uuid:
            usage: "LABEL"
            description: "Instance UUID"
        - vm_state:
            usage: "LABEL"
            description: "instance current state"
        - time_taken_gauge:
            usage: "GAUGE"
            description: "Instances termination time in past 24hrs"
    openstack_compute_instance_created:
      query: "SELECT coalesce(host, 'N/A') AS host, uuid, vm_state, COUNT(*) AS in_24hrs_gauge FROM instances WHERE (created_at >= now() - interval '24 hours') AND NOT host LIKE 'nova-compute-ironic%' AND deleted=0 GROUP BY host, uuid, vm_state"
      metrics:
        - host:
            usage: "LABEL"
            description: "Name of host"
        - vm_state:
            usage: "LABEL"
            description: "instance current state"
        - uuid:
            usage: "LABEL"
            description: "Instance UUID"
        - in_24hrs_gauge:
            usage: "GAUGE"
            description: "Instances created past 24hrs"
    openstack_ironic_instances_launch:
      query: "SELECT project_id, uuid, node AS node_id, hostname, vm_state, MAX(EXTRACT(epoch FROM launched_at - created_at)) AS time_taken_gauge FROM instances WHERE (launched_at IS NOT NULL AND launched_at >= now() - interval '24 hours') AND host LIKE 'nova-compute-ironic%' GROUP BY project_id, uuid, vm_state, hostname, node"
      metrics:
        - project_id:
            usage: "LABEL"
            description: "Project ID of the Node"
        - uuid:
            usage: "LABEL"
            description: "Node UUID"
        - vm_state:
            usage: "LABEL"
            description: "Node current state"
        - node_id:
            usage: "LABEL"
            description: "Node ID"
        - hostname:
            usage: "LABEL"
            description: "Node Name"
        - time_taken_gauge:
            usage: "GAUGE"
            description: "Nodes Launch time in past 24hrs"
    openstack_ironic_instances_termination:
      query: "SELECT project_id, uuid, hostname, node AS node_id, vm_state, MAX(EXTRACT(epoch FROM updated_at - terminated_at)) AS time_taken_gauge FROM instances WHERE (terminated_at IS NOT NULL AND terminated_at >= now() - interval '24 hours') AND host LIKE 'nova-compute-ironic%' GROUP BY project_id, uuid, vm_state, hostname, node"
      metrics:
        - project_id:
            usage: "LABEL"
            description: "Project ID of the Node"
        - uuid:
            usage: "LABEL"
            description: "Node UUID"
        - vm_state:
            usage: "LABEL"
            description: "Node current state"
        - hostname:
            usage: "LABEL"
            description: "Node Name"
        - node_id:
            usage: "LABEL"
            description: "Node ID"
        - time_taken_gauge:
            usage: "GAUGE"
            description: "Nodes termination time in past 24hrs"
    openstack_ironic_instances_created:
      query: "SELECT uuid, hostname, node AS node_id, vm_state, COUNT(*) AS in_24hrs FROM instances WHERE (created_at >= now() - interval '24 hours') AND host LIKE 'nova-compute-ironic%' GROUP BY uuid, vm_state, hostname, node"
      metrics:
        - vm_state:
            usage: "LABEL"
            description: "Node current state"
        - uuid:
            usage: "LABEL"
            description: "Node UUID"
        - node_id:
            usage: "LABEL"
            description: "Node ID"
        - hostname:
            usage: "LABEL"
            description: "Node Name"
        - in_24hrs_gauge:
            usage: "GAUGE"
            description: "Nodes created past 24hrs"
    openstack_ironic_instances:
      query: "SELECT instances.uuid, instances.node AS node_id, instances.project_id, instances.hostname, instances.node AS node_id, instances.vm_state, coalesce(instance_types.name,'N/A') AS flavor_name, COUNT(*) AS gauge FROM instances JOIN instance_types ON instances.instance_type_id=instance_types.id where host LIKE 'nova-compute-ironic%' GROUP BY instances.vm_state, instances.project_id, instance_types.name, instances.uuid, instances.hostname, instances.node"
      metrics:
        - uuid:
            usage: "LABEL"
            description: "Node UUID"
        - project_id:
            usage: "LABEL"
            description: "Project ID of the Node"
        - vm_state:
            usage: "LABEL"
            description: "Node current state"
        - flavor_name:
            usage: "LABEL"
            description: "Node flavor Name"
        - node_id:
            usage: "LABEL"
            description: "Node Name"
        - hostname:
            usage: "LABEL"
            description: "Node Name"
        - gauge:
            usage: "GAUGE"
            description: "Node Count"
    openstack_compute_nodes:
      query: "SELECT compute_nodes.host, compute_nodes.uuid, aggregate_metadata.value AS availability_zone, compute_nodes.hypervisor_type, compute_nodes.free_disk_gb AS free_disk_gb_gauge, compute_nodes.local_gb AS local_gb_gauge, compute_nodes.local_gb_used AS local_gb_used_gauge, compute_nodes.free_ram_mb AS free_ram_mb_gauge, compute_nodes.memory_mb AS memory_mb_gauge, compute_nodes.memory_mb_used AS memory_mb_used_gauge, compute_nodes.vcpus_used AS vcpus_used_gauge, compute_nodes.vcpus AS vcpus_gauge, compute_nodes.running_vms AS running_vms_gauge from compute_nodes join aggregate_hosts on compute_nodes.host=aggregate_hosts.host join aggregate_metadata on aggregate_hosts.aggregate_id=aggregate_metadata.aggregate_id WHERE compute_nodes.deleted = 0 AND aggregate_hosts.deleted=0 AND aggregate_metadata.deleted=0 AND aggregate_metadata.key='availability_zone'"
      metrics:
        - availability_zone:
            usage: "LABEL"
            description: "Availability Zone details from aggregate_metadata table"
        - uuid:
            usage: "LABEL"
            description: "Compute Node UUID"
        - host:
            usage: "LABEL"
            description: "Name of the host"
        - hypervisor_type:
            usage: "LABEL"
            description: "Type of the hypervisor"
        - free_disk_gb_gauge:
            usage: "GAUGE"
            description: "Total Free disk size in GB"
        - local_gb_gauge:
            usage: "GAUGE"
            description: "Total local disk size in GB"
        - local_gb_used_gauge:
            usage: "GAUGE"
            description: "Total used local disk size in GB"
        - free_ram_mb_gauge:
            usage: "GAUGE"
            description: "Free RAM in MiB"
        - memory_mb_gauge:
            usage: "GAUGE"
            description: "Total RAM in MiB"
        - memory_mb_used_gauge:
            usage: "GAUGE"
            description: "Total Used RAM in MiB"
        - vcpus_used_gauge:
            usage: "GAUGE"
            description: "vCPUs used"
        - vcpus_gauge:
            usage: "GAUGE"
            description: "Total vCPUs"
        - running_vms_gauge:
            usage: "GAUGE"
            description: "Number of VMs running"
    openstack_compute_service:
      query: 'select id, host, "binary", version from services where deleted_at is null'
      metrics:
      - id:
          usage: "LABEL"
          description: "ID of the service"
      - host:
          usage: "LABEL"
          description: "Name of the host"
      - binary:
          usage: "LABEL"
          description: "Name of the executable"
      - version:
          usage: "GAUGE"
          description: "Version of the service running"
    openstack_compute_node_last_action_interval_seconds:
      query: 'select i.host AS host, EXTRACT(EPOCH FROM (now() - max(ia.created_at)))::int AS "interval" from instance_actions AS ia JOIN instances AS i ON i.uuid = ia.instance_uuid group by i.host;'
      metrics:
      - host:
          usage: "LABEL"
          description: "name of the nova-compute service"
      - interval:
          usage: "GAUGE"
          description: "Seconds since the latest instance_action was created."
    openstack_compute_node_actions_without_events:
      query: "SELECT i.host AS host, COUNT(*) - COUNT(iae.start_time) AS \"actions\" FROM instance_actions AS ia JOIN instances AS i ON i.uuid = ia.instance_uuid LEFT OUTER JOIN instance_actions_events AS iae ON iae.action_id = ia.id WHERE ia.deleted = 0 AND ia.created_at > (NOW() - interval '1 week') GROUP by i.host;"
      metrics:
      - host:
          usage: "LABEL"
          description: "name of the nova-compute service"
      - actions:
          usage: "GAUGE"
          description: "instance_actions entries without instance instance_action_events entries"


postgresql:
  enabled: true
  imageTag: '9.4.14'
  postgresDatabase: nova
  dbInit: nova-db-init
  dbMaintain: nova-db-maintain
  name: nova
  users:
    nova: {}
    nova_api: {}
  persistence:
    enabled: true
    existingClaim: db-nova-pvclaim
  backup:
    enabled: true
    metrics: true
    os_password: null

  resources:
    requests:
      cpu: "1000m" # 1 cpu
      memory: "7Gi" # 6.3Gi high recorded

  max_connections: 500
  shared_buffers: '4GB'
  temp_buffers: '32MB'
  work_mem: '64MB'
  maintenance_work_mem: '256MB'
  max_stack_depth: '4MB'
  effective_cache_size: '16GB'
  autovacuum_analyze_scale_factor: '0.02'
  autovacuum_vacuum_scale_factor: '0.01'
  random_page_cost: '1.1'
  shared_preload_libraries: pg_stat_statements
  track_activity_query_size: 2048
  pgbouncer:
    enabled: true
    config:
      max_db_connections: 83
      default_pool_size: 50
      reserve_pool_size: 100
      idle_transaction_timeout: 60

postgresql_cell2:
  custom_repository: true
  imageTag: "9.5.10"
  name: nova-cell2
  postgresDatabase: nova-cell2
  dbInit: nova-db-init
  dbMaintain: nova-cell2-db-maintain
  persistence:
    enabled: true
    existingClaim: db-nova-cell2-pvclaim
  backup:
    enabled: true
    metrics: true
    os_password: null

  max_connections: 500
  shared_buffers: '4GB'
  temp_buffers: '32MB'
  work_mem: '64MB'
  maintenance_work_mem: '256MB'
  max_stack_depth: '4MB'
  effective_cache_size: '16GB'
  autovacuum_analyze_scale_factor: '0.02'
  autovacuum_vacuum_scale_factor: '0.01'
  random_page_cost: '1.1'
  shared_preload_libraries: pg_stat_statements
  track_activity_query_size: 2048
  pgbouncer:
    enabled: true
    config:
      max_db_connections: 83
      default_pool_size: 50
      reserve_pool_size: 100
      idle_transaction_timeout: 60

rabbitmq_cell2:
  name: nova-cell2
  persistence:
    enabled: false

  alerts:
    # unacked/ready messages in rabbitmq
    rabbit_queue_length: 50
    unacknowledged_total_wait_for: 10m
    ready_total_wait_for: 10m

audit:
  enabled: false
  # how many messages to buffer before dumping to log (when rabbit is down or too slow)
  mem_queue_size: 1000
  record_payloads: false
  metrics_enabled: true

rabbitmq:
  users:
    default:
      password: null
    admin:
      password: null
  persistence:
    enabled: false
  metrics:
    password: null

  resources:
    enabled: true

    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      cpu: 2000m

  alerts:
    # unacked/ready messages in rabbitmq
    rabbit_queue_length: 50
    unacknowledged_total_wait_for: 10m
    ready_total_wait_for: 10m

rabbitmq_notifications:
  name: nova
  persistence:
    enabled: false

logging:
  formatters:
    context:
      class: oslo_log.formatters.ContextFormatter
    default:
      format: "%(message)s"
  handlers:
    stdout:
      class: StreamHandler
      args: "(sys.stdout,)"
      formatter: context
    "null":
      class: logging.NullHandler
      args: "()"
      formatter: default
    sentry:
      class: raven.handlers.logging.SentryHandler
      level: ERROR
      args: "()"
  loggers:
    root:
      handlers: stdout, sentry
      level: WARNING
    migrate:
      handlers: stdout, sentry
      level: INFO
    nova:
      handlers: stdout, sentry
      level: INFO
    nova.scheduler:
      handlers: stdout, sentry
      level: DEBUG
    nova.scheduler.host_manager: # You might get problems with unicodedecode errors if you decrease that
      handlers: stdout, sentry
      level: INFO
    nova.virt.vmwareapi:
      handlers: stdout, sentry
      level: DEBUG
    eventlet.wsgi.server:
      handlers: stdout, sentry
      level: INFO
    oslo.privsep:
      handlers: stdout, sentry
      level: INFO
    suds:
      handlers: "null"
      level: ERROR
    oslo_vmware.common.loopingcall:
      handlers: "null"
      level: ERROR

# openstack-watcher-middleware
watcher:
  enabled: true

# Deploy Sentry Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which the alerts should be assigned to.
  prometheus: openstack
