global:
  registry: DEFINED_IN_VALUES_FILE

castellum:
  image_tag: latest
  image_pull_policy: Always

  service_user:
    password: DEFINED_IN_VALUES_FILE

  # Set to non-empty values to enable audit logging to Hermes.
  rabbitmq:
    queue_name: ""
    username: ""
    password: ""
    hostname: ""

  # # Whether to apply resource requests/limits to containers.
  # resources:
  #   enabled: false

postgresql:
  log_min_duration_statement: 250
  # less than the postgresql chart's default; I want to know early when connections start getting out of hand
  max_connections: 64

# Deploy Castellum Prometheus alerts.
alerts:
  enabled: true
  # Names of the Prometheus to which the alerts should be assigned to.
  # Keys = directory names in alerts/ and aggregations/
  prometheus:
    openstack: openstack
    kubernetes: kubernetes

pgmetrics:
  db_name: castellum

  customMetrics:
    castellum_asset_count:
      query: >
        SELECT r.asset_type AS asset, COUNT(a.id) AS gauge
          FROM resources r
          LEFT OUTER JOIN assets a ON a.resource_id = r.id
         GROUP BY r.asset_type
      metrics:
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - gauge:
            usage: "GAUGE"
            description: "Total number of assets that are managed by Castellum"
    castellum_resource_count:
      query: >
        SELECT asset_type AS asset, COUNT(id) AS gauge
          FROM resources
         GROUP BY asset_type
      metrics:
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - gauge:
            usage: "GAUGE"
            description: "Total number of resources where autoscaling is enabled"

    # The final UNION SELECT adds a dummy row that always exists even when no
    # pending operations exist. This allows us to have our cake and eat it (we
    # don't insert unnecessary timeseries, but the absence alert generated by
    # the absent-metrics-operator is still useful).
    castellum_min_greenlit_at:
      query: >
        SELECT r.scope_uuid AS project_id, r.asset_type AS asset, EXTRACT(epoch FROM MIN(o.greenlit_at)) AS gauge
          FROM resources r
          JOIN assets a ON a.resource_id = r.id
          JOIN pending_operations o ON o.asset_id = a.id
         WHERE o.greenlit_at IS NOT NULL
         GROUP BY r.scope_uuid, r.asset_type
         UNION SELECT 'none' AS project_id, 'none' AS asset, EXTRACT(epoch FROM NOW()) AS gauge
      metrics:
        - project_id:
            usage: "LABEL"
            description: "UUID of project"
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - gauge:
            usage: "GAUGE"
            description: "Lowest greenlit_at timestamp of any pending operation in this project resource"
    castellum_resource:
      query: >
        SELECT asset_type AS asset, MIN(checked_at) AS min_checked_at
          FROM resources
         GROUP BY asset_type
      metrics:
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - min_checked_at:
            usage: "GAUGE"
            description: "Lowest checked_at timestamp of any project resource with this asset type"
    castellum_asset:
      query: >
        SELECT r.asset_type AS asset, MIN(a.checked_at) AS min_checked_at
          FROM resources r
          JOIN assets a ON a.resource_id = r.id
          GROUP BY r.asset_type
      metrics:
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - min_checked_at:
            usage: "GAUGE"
            description: "Lowest checked_at timestamp of any asset with this type"

    castellum_resource_scrape_errors:
      query: >
        SELECT COUNT(id) as gauge
          FROM resources
         WHERE scrape_error_message != ''
      metrics:
        - gauge:
            usage: "GAUGE"
            description: "Total number of resources that failed their last scrape"

    castellum_existing_asset_scrape_errors:
      query: >
        SELECT COUNT(id) as gauge
          FROM assets
         WHERE scrape_error_message != '' AND scraped_at IS NOT NULL
      metrics:
        - gauge:
            usage: "GAUGE"
            description: "Total number of assets that failed their last scrape (only counting those assets that had at least one successful scrape ever)"

    castellum_fresh_asset_scrape_errors:
      query: >
        SELECT COUNT(id) as gauge
          FROM assets
         WHERE scrape_error_message != '' AND scraped_at IS NULL
      metrics:
        - gauge:
            usage: "GAUGE"
            description: "Total number of assets that failed their last scrape (only counting those assets that never had a successful scrape)"

    castellum_asset_resize_errors:
      query: >
        WITH latest_finished_operations AS (
          SELECT DISTINCT ON (asset_id) o.* FROM finished_operations o
            JOIN assets a ON a.id = o.asset_id
          ORDER BY o.asset_id, o.finished_at DESC
        )
        SELECT COUNT(asset_id) as gauge
          FROM latest_finished_operations
         WHERE outcome = 'errored'
      metrics:
        - gauge:
            usage: "GAUGE"
            description: "Total number of assets that failed their last resize"

    # There is a lot to unpack in this query. Reading from the inside out:
    # 1. We want to be alerted when an asset is at a critical usage level, but
    #    Castellum is not doing anything about it. That's what the WHERE describes.
    #    (This used to just be something along the lines of `WHERE
    #    usage_percent > critical_threshold_percent`, but since multi-usage
    #    resources, Castellum has started evaluating this condition for us and
    #    reporting into the `critical_usages` column.)
    # 2. To quantify the "not doing anything" part, the metric value is the
    #    time since the last critical upsize was performed on that asset. We
    #    RIGHT OUTER JOIN instead of a simple JOIN since there may not be a
    #    finished operation for that asset at all.
    # 3. The inner SELECT query would be enough to power the alert. But if we
    #    do just that, we would be creating a ton of useless timeseries that live
    #    for only a few minutes. The timeseries appears when the asset is scraped
    #    and usage is critical, and it disappears in the next scrape after the
    #    size was adjusted. Since scrapes occur every 5 minutes, we only create
    #    the timeseries at the 6 minute mark, so most of them will be avoided.
    # 4. The final UNION SELECT adds a dummy row that always exists even when no
    #    critical assets are inactive. This allows us to have our cake and eat
    #    it (we don't insert unnecessary timeseries, but the absence alert
    #    generated by the absent-metrics-operator is still useful).
    castellum_critical_inactivity:
      query: >
        WITH currently_critical_assets AS (
          SELECT a.uuid AS asset_id, r.asset_type AS asset, COALESCE(EXTRACT(epoch FROM MAX(fo.finished_at)), 0) AS started_at
            FROM assets a
            JOIN resources r ON a.resource_id = r.id
           RIGHT OUTER JOIN finished_operations fo ON fo.asset_id = a.id AND fo.reason = 'critical'
           WHERE a.critical_usages != ''
           GROUP BY a.uuid, r.asset_type
        )
        SELECT * FROM currently_critical_assets WHERE started_at < EXTRACT(epoch FROM (NOW() - interval '6 minute'))
        UNION SELECT 'none' AS asset_id, 'none' AS asset, EXTRACT(epoch FROM NOW()) AS started_at
      metrics:
        - asset:
            usage: "LABEL"
            description: "Asset type"
        - asset_id:
            usage: "LABEL"
            description: "ID of affected asset"
        - started_at:
            usage: "GAUGE"
            description: "UNIX timestamp of last finished resize operation on this asset (presence of metric indicates that asset usage is critical for at least 1 minute)"
