NAME: keystone
LAST DEPLOYED: Wed Oct 11 10:50:24 2023
NAMESPACE: monsoon3
STATUS: pending-install
REVISION: 1
TEST SUITE: None
HOOKS:
---
# Source: keystone/charts/owner-info/templates/configmap.yaml
kind: ConfigMap
apiVersion: v1

metadata:
  # We need this configmap to be present early because it is used by a mutating webhook when the
  # other objects in this Helm release are written into the Kubernetes DB.
  name: early-owner-of-keystone
  labels:
    # This can be used to validate via policy that everyone uses a reasonably up-to-date version of this chart.
    owner-info-version: "0.2.0"
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-100"
    "helm.sh/hook-delete-policy": before-hook-creation

data:
  support-group: "identity"
MANIFEST:
---
# Source: keystone/charts/mariadb-galera/templates/poddisruptionbudget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  namespace: monsoon3
  name: keystone-database
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      component: "database"
---
# Source: keystone/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: keystone-api
spec:
  minAvailable: 1
  selector:
    matchLabels:
      name: keystone-api
      system: openstack
      component: keystone
      type: api
---
# Source: keystone/charts/mariadb-galera/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: monsoon3
  name: keystone
automountServiceAccountToken: false
---
# Source: keystone/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: keystone
  namespace: monsoon3
---
# Source: keystone/templates/ingress-api.yaml
kind: Secret
apiVersion: v1

metadata:
  name: keystone-x509-ca
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    component: keystone
    type: x509-ca
data:
  ca.crt: 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
---
# Source: keystone/templates/secret-credential-keys.yaml
apiVersion: v1
kind: Secret
metadata:
  name: keystone-credential-keys
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    component: keystone
    type: config
  #annotations:
    # only create once and never touch again, since it should be rotated via cli
    #"helm.sh/hook": pre-install, post-upgrade
data:
    0: dummypass
    1: dummypass
---
# Source: keystone/templates/secret-fernet.yaml
apiVersion: v1
kind: Secret
metadata:
  name: keystone-fernet
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    component: keystone
    type: config
  annotations:
    max_active_keys: "3"
    # only create once and never touch again, since it should be rotated via cli
    #"helm.sh/hook": pre-install, post-upgrade
data:
    0: dummypass
    1: dummypass
    2: dummypass
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb-job.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: monsoon3
  name: keystone-mariadb-config-job-entrypoint-sh
  labels:
    app: keystone
data:
  entrypoint-job-config.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    waitfordatabase
    loginfo "null" "configuration job started"
    setuprole 'fullaccess' 'ALL PRIVILEGES' '*.*' "WITH GRANT OPTION"
    setuprole 'monitor' 'SHOW DATABASES, SLAVE MONITOR, BINLOG MONITOR, PROCESS, REPLICA MONITOR, SELECT' '*.*' ""
    setupuser "${MARIADB_ROOT_USERNAME}" "${MARIADB_ROOT_PASSWORD}" 'fullaccess' 0 '%' 'ed25519' "WITH ADMIN OPTION"
    setdefaultrole 'fullaccess' 'root' '%'
    setupuser "${MARIADB_ROOT_USERNAME}" "${MARIADB_ROOT_PASSWORD}" 'fullaccess' 0 '::1' 'ed25519' "WITH ADMIN OPTION"
    setdefaultrole 'fullaccess' 'root' '::1'

    listdbandusers
    stopasyncreplication

    loginfo "null" "configuration job finished"
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb-my.cnf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-mariadb-my-cnf
  namespace: monsoon3
data:
  my.cnf.keystone-mariadb-g-0.tpl: |-
    [mysqld]
    performance_schema=OFF
    skip-name-resolve=1
    max_connect_errors=4294967295 #to avoid failed connections because of loadbalancer health checks https://mariadb.com/kb/en/server-system-variables/#max_connect_errors
    log_warnings=1

    [mariadb]
    wsrep-provider=/usr/lib/libgalera_smm.so
    plugin_load_add = wsrep_info #https://mariadb.com/kb/en/wsrep_info-plugin/
    binlog_format=ROW
    max_binlog_size=104857600
    log-bin=/opt/${SOFTWARE_NAME}/log/keystone_binlog
    expire_logs_days=1
    sync_binlog=1
    default_storage_engine=InnoDB
    innodb_autoinc_lock_mode=2
    innodb_flush_log_at_trx_commit=1
    gtid-strict-mode=0
    wsrep_gtid_mode=on
    wsrep_gtid_domain_id=10815
    gtid_domain_id=10816
    expire_logs_days=1
    wsrep-cluster-name="keystone"
    wsrep_cluster_address=gcomm://keystone-mariadb-g-0.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-1.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-2.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-backend.monsoon3.svc.cluster.local:4567
    wsrep_provider_options=cert.log_conflicts=ON;debug=NO;gcache.recover=no;ist.recv_addr=${CONTAINER_IP}:0;pc.recovery=FALSE;pc.wait_prim_timeout=PT60S;pc.weight=${PC_WEIGHT_0}
    wsrep_node_address=${CONTAINER_IP}
    wsrep_node_name=keystone-mariadb-g-0
    wsrep-on=1
    wsrep_log_conflicts=ON
    wsrep_slave_threads=16
    wsrep_auto_increment_control=0
    auto_increment_increment=3
    auto_increment_offset=1

    # async replication with MariaDB instances outside of the Galera cluster
    relay_log=/opt/${SOFTWARE_NAME}/log/keystone_relaylog
    server_id=1
    log_slave_updates=on
    wsrep_restart_slave=off
    report-host=keystone-mariadb-g-0
    slave-parallel-threads=1
    binlog-commit-wait-count=0
  my.cnf.keystone-mariadb-g-1.tpl: |-
    [mysqld]
    performance_schema=OFF
    skip-name-resolve=1
    max_connect_errors=4294967295 #to avoid failed connections because of loadbalancer health checks https://mariadb.com/kb/en/server-system-variables/#max_connect_errors
    log_warnings=1

    [mariadb]
    wsrep-provider=/usr/lib/libgalera_smm.so
    plugin_load_add = wsrep_info #https://mariadb.com/kb/en/wsrep_info-plugin/
    binlog_format=ROW
    max_binlog_size=104857600
    log-bin=/opt/${SOFTWARE_NAME}/log/keystone_binlog
    expire_logs_days=1
    sync_binlog=1
    default_storage_engine=InnoDB
    innodb_autoinc_lock_mode=2
    innodb_flush_log_at_trx_commit=1
    gtid-strict-mode=0
    wsrep_gtid_mode=on
    wsrep_gtid_domain_id=10815
    gtid_domain_id=11816
    expire_logs_days=1
    wsrep-cluster-name="keystone"
    wsrep_cluster_address=gcomm://keystone-mariadb-g-0.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-1.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-2.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-backend.monsoon3.svc.cluster.local:4567
    wsrep_provider_options=cert.log_conflicts=ON;debug=NO;gcache.recover=no;ist.recv_addr=${CONTAINER_IP}:0;pc.recovery=FALSE;pc.wait_prim_timeout=PT60S;pc.weight=${PC_WEIGHT_1}
    wsrep_node_address=${CONTAINER_IP}
    wsrep_node_name=keystone-mariadb-g-1
    wsrep-on=1
    wsrep_log_conflicts=ON
    wsrep_slave_threads=16
    wsrep_auto_increment_control=0
    auto_increment_increment=3
    auto_increment_offset=2

    # async replication with MariaDB instances outside of the Galera cluster
    relay_log=/opt/${SOFTWARE_NAME}/log/keystone_relaylog
    server_id=1
    log_slave_updates=on
    wsrep_restart_slave=off
    report-host=keystone-mariadb-g-1
    slave-parallel-threads=1
    binlog-commit-wait-count=0
  my.cnf.keystone-mariadb-g-2.tpl: |-
    [mysqld]
    performance_schema=OFF
    skip-name-resolve=1
    max_connect_errors=4294967295 #to avoid failed connections because of loadbalancer health checks https://mariadb.com/kb/en/server-system-variables/#max_connect_errors
    log_warnings=1

    [mariadb]
    wsrep-provider=/usr/lib/libgalera_smm.so
    plugin_load_add = wsrep_info #https://mariadb.com/kb/en/wsrep_info-plugin/
    binlog_format=ROW
    max_binlog_size=104857600
    log-bin=/opt/${SOFTWARE_NAME}/log/keystone_binlog
    expire_logs_days=1
    sync_binlog=1
    default_storage_engine=InnoDB
    innodb_autoinc_lock_mode=2
    innodb_flush_log_at_trx_commit=1
    gtid-strict-mode=0
    wsrep_gtid_mode=on
    wsrep_gtid_domain_id=10815
    gtid_domain_id=12816
    expire_logs_days=1
    wsrep-cluster-name="keystone"
    wsrep_cluster_address=gcomm://keystone-mariadb-g-0.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-1.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-2.monsoon3.svc.cluster.local:4567,keystone-mariadb-g-backend.monsoon3.svc.cluster.local:4567
    wsrep_provider_options=cert.log_conflicts=ON;debug=NO;gcache.recover=no;ist.recv_addr=${CONTAINER_IP}:0;pc.recovery=FALSE;pc.wait_prim_timeout=PT60S;pc.weight=${PC_WEIGHT_2}
    wsrep_node_address=${CONTAINER_IP}
    wsrep_node_name=keystone-mariadb-g-2
    wsrep-on=1
    wsrep_log_conflicts=ON
    wsrep_slave_threads=16
    wsrep_auto_increment_control=0
    auto_increment_increment=3
    auto_increment_offset=3

    # async replication with MariaDB instances outside of the Galera cluster
    relay_log=/opt/${SOFTWARE_NAME}/log/keystone_relaylog
    server_id=1
    log_slave_updates=on
    wsrep_restart_slave=off
    report-host=keystone-mariadb-g-2
    slave-parallel-threads=1
    binlog-commit-wait-count=0
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: monsoon3
  name: keystone-mariadb-entrypoint-sh
  labels:
    app: keystone
data:
  entrypoint-galera.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    function bootstrapgalera {
      loginfo "${FUNCNAME[0]}" "init Galera cluster"
      if [ -f "${BASE}/etc/wipedata.flag" ]; then
        exec mariadbd --defaults-file=${BASE}/etc/my.cnf --basedir=/usr --wsrep-new-cluster --wsrep_on=OFF --expire-logs-days=0
      else
        exec mariadbd --defaults-file=${BASE}/etc/my.cnf --basedir=/usr --wsrep-new-cluster
      fi

    }

    function fetchseqnofromgrastate {
      IFS=": " SEQNO=($(grep 'seqno:' ${DATADIR}/grastate.dat))
      IFS="${oldIFS}"
      echo ${SEQNO[1]}
    }

    function recovergalera {
      loginfo "${FUNCNAME[0]}" "recover mariadbd galera if required"
      if [ ${PC_RECOVERY} == "true" ] && [ -f ${DATADIR}/gvwstate.dat ] && [ -s ${DATADIR}/gvwstate.dat ]; then

        loginfo "${FUNCNAME[0]}" "primary component recovery possible"
        startgalera
      else
        IFS=": " SAFE_TO_BOOTSTRAP=($(grep 'safe_to_bootstrap:' ${DATADIR}/grastate.dat))
        IFS="${oldIFS}"
        SEQNO=$(fetchseqnofromgrastate)

        if [ ${SAFE_TO_BOOTSTRAP[1]} -eq 1 ] && [ ${SEQNO} -ne -1 ]; then
          loginfo "${FUNCNAME[0]}" 'positive sequence number found'
          setconfigmap "seqno" "${SEQNO}" "Update"
          selectbootstrapnode
          if [ "${NODENAME[0]}" == "${POD_NAME}" ]; then
            bootstrapgalera
          else
            startgalera
          fi
        else
          loginfo "${FUNCNAME[0]}" "start 'mariadbd --wsrep-recover' to find last sequence number"
          MARIADBD_RESPONSE=$(mariadbd --defaults-file=${BASE}/etc/my.cnf --basedir=/usr --skip-log-error --wsrep-recover 2>&1)
          # '2023-06-29 15:33:06 0 [Note] WSREP: Recovered position: d1211d51-168e-11ee-bb72-d392a3952878:70,0-10-62'
          # grep will match: 70
          SEQNO=$(echo ${MARIADBD_RESPONSE} | grep --only-matching --perl-regexp --regexp='\[Note\] WSREP: Recovered position: .+:\K([0-9]+)')
          # '2023-06-29 15:33:06 0 [Note] WSREP: Recovered position: d1211d51-168e-11ee-bb72-d392a3952878:70,0-10-62'
          # grep will match: d1211d51-168e-11ee-bb72-d392a3952878
          UUID=$(echo ${MARIADBD_RESPONSE} | grep --only-matching --perl-regexp --regexp='\[Note\] WSREP: Recovered position: \K([0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12})')
          if [ $? -ne 0 ]; then
            logerror "${FUNCNAME[0]}" "mariadbd --wsrep-recover failed with '${MARIADBD_RESPONSE}'"
            exit 1
          fi

          if [ ${SEQNO} -ge 0 ]; then
            loginfo "${FUNCNAME[0]}" "sequence number ${SEQNO} and historic UUID ${UUID} found"
            sed --in-place "s,^seqno:\s*-1,seqno:   ${SEQNO}," ${DATADIR}/grastate.dat
            if [ $? -ne 0 ]; then
              logerror "${FUNCNAME[0]}" "sequence number update failed"
              exit 1
            fi
            sed --in-place "s,^uuid:\s*00000000-0000-0000-0000-000000000000,uuid:   ${UUID}," ${DATADIR}/grastate.dat
            if [ $? -ne 0 ]; then
              logerror "${FUNCNAME[0]}" "uuid update failed"
              exit 1
            fi
             loginfo "${FUNCNAME[0]}" "grastate.dat file updated"

            setconfigmap "seqno" "${SEQNO}" "Update"
            selectbootstrapnode
            if [ "${NODENAME[0]}" == "${POD_NAME}" ]; then
              sed --in-place "s,^safe_to_bootstrap:\s*0,safe_to_bootstrap: 1," ${DATADIR}/grastate.dat
              if [ $? -ne 0 ]; then
                logerror "${FUNCNAME[0]}" "safe_to_bootstrap update failed"
                exit 1
              fi
              bootstrapgalera
            else
              startgalera
            fi
          else
            logerror "${FUNCNAME[0]}" "The value '${SEQNO}' is not a valid sequence number"
            exit 1
          fi
        fi
      fi
    }

    function startgalera {
      loginfo "${FUNCNAME[0]}" "starting mariadbd galera process"
      exec mariadbd --defaults-file=${BASE}/etc/my.cnf --basedir=/usr --skip-log-error
    }

    function initgalera {
      if [ -f "${BASE}/etc/wipedata.flag" ]; then
        if [ ${HOSTNAME} == "keystone-mariadb-g-0" ]; then
          bootstrapgalera
        else
          loginfo "${FUNCNAME[0]}" "start sleep mode because wipedata flag has been set"
          sleep 86400
        fi
      else
        if [ -f ${DATADIR}/grastate.dat ] && [ -s ${DATADIR}/grastate.dat ]; then
            loginfo "${FUNCNAME[0]}" "init Galera cluster configuration already done"
            recovergalera
          else
            if [ ${HOSTNAME} == "keystone-mariadb-g-0" ]; then
              bootstrapgalera
            else
              loginfo "${FUNCNAME[0]}" "will join the Galera cluster during the initial bootstrap triggered on the first node"
              startgalera
            fi
        fi
      fi
    }

    initgalera
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: monsoon3
  name: keystone-mariadb-common-functions-extended-sh
  labels:
    app: keystone
data:
  common-functions-extended.sh: |
    MAX_RETRIES=20
    WAIT_SECONDS=6
    if [ "$0" != "/opt/mariadb/bin/entrypoint-backup.sh" ]; then
      MYSQL_SVC_CONNECT="mysql --protocol=tcp --user=${MARIADB_ROOT_USERNAME} --password=${MARIADB_ROOT_PASSWORD} --host=keystone-mariadb-g-frontend-direct.database.svc.cluster.local --port=${MYSQL_PORT} --wait --connect-timeout=${WAIT_SECONDS} --reconnect --batch"
    fi
    declare -a NODENAME=()

    #entrypoint-galera
    # updateconfigmap "scope[seqno|running|primary]" "value[sequence number|true|false]" "output[Update|Reset]"
    function setconfigmap {
      local int
      local SCOPE=$1
      local VALUE=$2
      local OUTPUT=$3
      declare -l OUTPUT_LOWERCASE=${OUTPUT}
      if [ ${OUTPUT} == "Reset" ]; then
        local CONTENT="${VALUE}\ntimestamp:\n"
      else
        local CONTENT="${VALUE}\ntimestamp:$(date +%s)\n"
      fi
      local CONFIGMAP_NAME=keystone-galerastatus
      local KUBE_TOKEN=$(</var/run/secrets/kubernetes.io/serviceaccount/token)

      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        loginfo "${FUNCNAME[0]}" "${OUTPUT} configmap '${CONFIGMAP_NAME}' (${int} retries left)"
        CURL_RESPONSE=$(curl --max-time ${WAIT_SECONDS} --retry ${MAX_RETRIES} --silent \
                        --write-out '\n{"curl":{"http_code":"%{http_code}","response_code":"%{response_code}","url":"%{url_effective}"}}\n' \
                        --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt \
                        --header "Authorization: Bearer ${KUBE_TOKEN}" --header "Accept: database/json" --header "Content-Type: database/strategic-merge-patch+json" \
                        --data "{\"kind\":\"ConfigMap\",\"apiVersion\":\"v1\",\"data\":{\"${POD_NAME}.${SCOPE}\":\"${POD_NAME}:${CONTENT}\"}}" \
                        --request PATCH https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_PORT_443_TCP_PORT}/api/v1/namespaces/monsoon3/configmaps/${CONFIGMAP_NAME})
        CURL_STATUS=$?
        HTTP_STATUS=$(echo ${CURL_RESPONSE} | jq -r '. | select( .curl ) | .curl.http_code')
        CURL_OUTPUT=$(echo ${CURL_RESPONSE} | jq -c '. | select( .curl ) | .curl')
        HTTP_OUTPUT=$(echo ${CURL_RESPONSE} | jq '. | select( .kind )')
        if [ ${CURL_STATUS} -ne 0 ]; then
           logerror "${FUNCNAME[0]}" "configmap '${CONFIGMAP_NAME}' ${OUTPUT_LOWERCASE} has been failed because of ${CURL_OUTPUT}"
          sleep ${WAIT_SECONDS}
        else
          break
        fi
      done
      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "configmap '${CONFIGMAP_NAME}' ${OUTPUT_LOWERCASE} has been finally failed"
        exit 1
      fi
       loginfo "${FUNCNAME[0]}" "configmap '${CONFIGMAP_NAME}' ${OUTPUT_LOWERCASE} done with http status code '${HTTP_STATUS}'"
    }

    function fetchcurrentseqno {
      local int
      local SEQNOARRAY

      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        IFS=$'\t' SEQNOARRAY=($(mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_last_committed';" --batch --skip-column-names | grep 'wsrep_last_committed'))
        if [ $? -ne 0 ]; then
          sleep ${WAIT_SECONDS}
        else
          break
        fi
      done
      if [ ${int} -eq 0 ]; then
        exit 1
      fi
      IFS="${oldIFS}"
      echo ${SEQNOARRAY[1]}
    }

    function checkdblogon {
      mysql --protocol=socket --user=root --database=mysql --wait --connect-timeout=${WAIT_SECONDS} --reconnect --execute="STATUS;" | grep 'Server version:' | grep --silent "${SOFTWARE_VERSION}"
      if [ $? -eq 0 ]; then
        echo 'MariaDB MySQL API usable'
      else
        echo 'MariaDB MySQL API not usable'
        exit 1
      fi
    }

    function checkdbk8sservicelogon {
      local ONLY_RETURN_STATUS=${1-false}

      ${MYSQL_SVC_CONNECT} --execute="STATUS;" | grep 'Server version:' | grep --silent "${SOFTWARE_VERSION}"
      if [ $? -eq 0 ]; then
        if [ "${ONLY_RETURN_STATUS}" == "true" ]; then
          return 0
        else
          echo 'MariaDB MySQL API Kubernetes service usable'
        fi
      else
        if [ "${ONLY_RETURN_STATUS}" == "true" ]; then
          return 1
        else
          echo 'MariaDB MySQL API Kubernetes service not usable'
          exit 1
        fi
      fi
    }

    function waitfordatabase {
      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        checkdbk8sservicelogon "true"
        if [ $? -eq 0 ]; then
          break
        else
          loginfo "${FUNCNAME[0]}" "database not yet usable. Will wait ${WAIT_SECONDS}s before retry"
          sleep ${WAIT_SECONDS}
        fi
      done
    }

    # setupdatabase dbname comment collation charset enabled createOrReplace deleteIfDisabled
    # setupdatabase "sb_oltp_ro" "for the sysbench oltp readonly benchmark" "utf8_general_ci" "utf8" true true true
    function setupdatabase {
      if [ -n "${7}" ]; then
        local int
        export DB_NAME=${1}
        export DB_COMMENT=${2}
        export DB_COLLATION=${3}
        export DB_CHARSET=${4}
        export DB_ENABLED=${5}
        export DB_REPLACE=${6}
        export DB_DELETE=${7}

        if [ "${DB_REPLACE}" == "true" ]; then
          export DB_CREATE="CREATE OR REPLACE DATABASE"
        else
          export DB_CREATE="CREATE DATABASE IF NOT EXISTS"
        fi

        loginfo "${FUNCNAME[0]}" "setup '${DB_NAME}' database"
        for (( int=${MAX_RETRIES}; int >=1; int-=1));
          do
          if [ "${DB_ENABLED}" == "true" ]; then
            if [ "$0" == "/opt/mariadb/bin/entrypoint-job-config.sh" ]; then
              ${MYSQL_SVC_CONNECT} --execute="${DB_CREATE} ${DB_NAME} CHARACTER SET = ${DB_CHARSET} COLLATE = ${DB_COLLATION} COMMENT '${DB_COMMENT}';"
            else
              mysql --protocol=socket --user=root --batch --execute="${DB_CREATE} ${DB_NAME} CHARACTER SET = ${DB_CHARSET} COLLATE = ${DB_COLLATION} COMMENT '${DB_COMMENT}';"
            fi
            if [ $? -ne 0 ]; then
              logerror "${FUNCNAME[0]}" "'${DB_NAME}' database creation has been failed(${int} retries left)"
              sleep ${WAIT_SECONDS}
            else
              loginfo "${FUNCNAME[0]}" "'${DB_NAME}' database creation done"
              break
            fi
          else
            if [ "${DB_DELETE}" == "true" ]; then
              if [ "$0" == "/opt/mariadb/bin/entrypoint-job-config.sh" ]; then
                ${MYSQL_SVC_CONNECT} --execute="DROP DATABASE IF EXISTS ${DB_NAME};"
              else
                mysql --protocol=socket --user=root --batch --execute="DROP DATABASE IF EXISTS ${DB_NAME};"
              fi
              if [ $? -ne 0 ]; then
                logerror "${FUNCNAME[0]}" "'${DB_NAME}' database delete has been failed(${int} retries left)"
                sleep ${WAIT_SECONDS}
              else
                loginfo "${FUNCNAME[0]}" "'${DB_NAME}' database deletion done"
                break
              fi
            else
              loginfo "${FUNCNAME[0]}" "'${DB_NAME}' database deletion not allowed because deleteIfDisabled option is not enabled"
              break
            fi
          fi
        done

        if [ ${int} -eq 0 ]; then
          logerror "${FUNCNAME[0]}" "database setup has been finally failed"
          exit 1
        fi
        export -n DB_NAME
        export -n DB_COMMENT
        export -n DB_COLLATION
        export -n DB_CHARSET
        export -n DB_ENABLED
        export -n DB_REPLACE
        export -n DB_DELETE
        export -n DB_CREATE
      else
        loginfo "${FUNCNAME[0]}" "database setup skipped because of missing parameters"
      fi
    }

    function selectbootstrapnode {
      local int
      local SEQNO=$(fetchseqnofromgrastate)
      local SEQNO_FILES="${BASE}/etc/galerastatus/keystone-mariadb-g-*.seqno"
      local SEQNO_OLDEST_TIMESTAMP
      local SEQNO_OLDEST_TIMESTAMP_WITH_BUFFER
      local CURRENT_EPOCH

      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        loginfo "${FUNCNAME[0]}" "Find Galera node with highest sequence number (${int} retries left)"
        SEQNO_FILE_COUNT=$(grep -c 'keystone-mariadb-g-*' ${SEQNO_FILES} | grep -c -e ${BASE}/etc/galerastatus/keystone-mariadb-g-.*.seqno:1)
        if [ ${SEQNO_FILE_COUNT} -ge 0 ]; then
          IFS=":" SEQNO_OLDEST_TIMESTAMP=($(grep --no-filename --perl-regex --regexp='^timestamp:\d+$' ${SEQNO_FILES} | sort --key=2 --numeric-sort --field-separator=: | head --lines=1))
          IFS="${oldIFS}"
          if ! [ -z ${SEQNO_OLDEST_TIMESTAMP[1]+x} ]; then
            SEQNO_OLDEST_TIMESTAMP_WITH_BUFFER=$(( ${SEQNO_OLDEST_TIMESTAMP[1]} + (10 * 12) ))
            CURRENT_EPOCH=$(date +%s)
            # time difference check disabled
              IFS=": " NODENAME=($(grep --no-filename 'keystone-mariadb-g-*' ${SEQNO_FILES} | sort --key=2 --reverse --numeric-sort --field-separator=: | head -1))
              IFS="${oldIFS}"
              if [[ "${NODENAME[0]}" =~ ^keystone-mariadb-g-.* ]]; then
                loginfo "${FUNCNAME[0]}" "Galera nodename '${NODENAME[0]}' with the sequence number '${NODENAME[1]}' selected"
                break
              else
                logerror "${FUNCNAME[0]}" "nodename '${NODENAME[0]}' not valid"
                exit 1
              fi
          else
            loginfo "${FUNCNAME[0]}" "Sequence numbers not yet found in configmap. Retry after $(( ${WAIT_SECONDS} * (${MAX_RETRIES} - ${int} + 1) ))s"
            sleep  $(( ${WAIT_SECONDS} * (${MAX_RETRIES} - ${int} + 1) ))
          fi
        else
          loginfo "${FUNCNAME[0]}" "${SEQNO_FILE_COUNT} of 0 sequence numbers found. Will wait $(( ${WAIT_SECONDS} * (${MAX_RETRIES} - ${int} + 1) ))s"
          sleep  $(( ${WAIT_SECONDS} * (${MAX_RETRIES} - ${int} + 1) ))
        fi
        setconfigmap "seqno" "${SEQNO}" "Update"
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "Sequence number search finally incomplete(${SEQNO_FILE_COUNT}/0)"
        exit 1
      fi
      loginfo "${FUNCNAME[0]}" "Sequence number search done"
    }

    function setupasyncreplication {
      local int
      local primaryhost="false"
      local gtidbinlogposition
      local gtidlist

      loginfo "${FUNCNAME[0]}" "setup async replication from '${primaryhost}'"
      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        # use only the wsrep_gtid_domain_id values like '10815-10-2809143'
        IFS=$'\n' gtidlist=($(mysql --protocol=tcp --host=${primaryhost} --user=${REPLICA_USERNAME} --password=${REPLICA_PASSWORD} --execute="select @@gtid_binlog_pos;" --batch --skip-column-names | grep --only-matching --perl-regexp --regexp='(?<=)\d{1}0815-\d{2}-\d+'))
        IFS="${oldIFS}"
        if [ $? -ne 0 ]; then
          logerror "${FUNCNAME[0]}" "'gtid_binlog_pos query failed(${int} retries left)"
          sleep ${WAIT_SECONDS}
        else
          # join array values to something like '10815-10-2809143,20815-20-442922'
          gtidbinlogposition=$(IFS=','; echo "${gtidlist[*]}")
          IFS="${oldIFS}"

          break
        fi
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "async replication setup has been finally failed"
        exit 1
      fi

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "async replication setup has been finally failed"
        exit 1
      fi

      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        mysql --protocol=tcp --host=keystone-mariadb-g-0 --user=${MARIADB_ROOT_USERNAME} --password=${MARIADB_ROOT_PASSWORD} --execute="CHANGE MASTER TO MASTER_HOST=\"${primaryhost}\", MASTER_PORT=${MYSQL_PORT}, MASTER_USERNAME=\"${REPLICA_USERNAME}\", MASTER_PASSWORD=\"${REPLICA_PASSWORD}\", MASTER_USE_GTID=slave_pos, DO_DOMAIN_IDS=(10815,20815), IGNORE_SERVER_IDS=(10,11,12);" --batch
        if [ $? -ne 0 ]; then
          logerror "${FUNCNAME[0]}" "'change master config failed(${int} retries left)"
          sleep ${WAIT_SECONDS}
        else

          break
        fi
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "async replication setup has been finally failed"
        exit 1
      fi
    }

    function stopasyncreplication {
      local int

      loginfo "${FUNCNAME[0]}" "stop async replication"
      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        mysql --protocol=tcp --host=keystone-mariadb-g-0 --user=${MARIADB_ROOT_USERNAME} --password=${MARIADB_ROOT_PASSWORD} --execute="STOP ALL SLAVES;" --batch
        if [ $? -ne 0 ]; then
          logerror "${FUNCNAME[0]}" "'replica stop failed(${int} retries left)"
          sleep ${WAIT_SECONDS}
        else
          loginfo "${FUNCNAME[0]}" "replica stop successful"
          break
        fi
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "async replication stop has been finally failed"
        exit 1
      fi
    }

    function startasyncreplication {
      local int

      loginfo "${FUNCNAME[0]}" "start async replication"
      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        mysql --protocol=tcp --host=keystone-mariadb-g-0 --user=${MARIADB_ROOT_USERNAME} --password=${MARIADB_ROOT_PASSWORD} --execute="START ALL SLAVES;" --batch
        if [ $? -ne 0 ]; then
          logerror "${FUNCNAME[0]}" "'replica start failed(${int} retries left)"
          sleep ${WAIT_SECONDS}
        else
          loginfo "${FUNCNAME[0]}" "replica start successful"
          break
        fi
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "async replication start has been finally failed"
        exit 1
      fi
    }

    function checkasyncreplication {
      local int
      local SLAVEIO_STATUS
      local SLAVEIO_ERRNR
      local SLAVEIO_ERRTXT
      local SLAVESQL_STATUS
      local SLAVESQL_ERRNR
      local SLAVESQL_ERRTXT

      loginfo "${FUNCNAME[0]}" "check async replication status"
      for (( int=${MAX_RETRIES}; int >=1; int-=1));
        do
        MYSQL_RESPONSE=$(mysql --protocol=tcp --host=keystone-mariadb-g-0 --user=${MARIADB_ROOT_USERNAME} --password=${MARIADB_ROOT_PASSWORD} --execute="SHOW ALL SLAVES STATUS\G;" --batch)
        if [ $? -ne 0 ]; then
          logerror "${FUNCNAME[0]}" "replica status check failed(${int} retries left)"
          sleep ${WAIT_SECONDS}
        else
          SLAVEIO_STATUS=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Slave_IO_Running: )(No|Yes|Connecting)')
          if [ "${SLAVEIO_STATUS}" != "Connecting" ]; then

            break
          else
            logerror "${FUNCNAME[0]}" "replica still trying to connect to the primary(${int} retries left)"
            sleep ${WAIT_SECONDS}
          fi
        fi
      done

      if [ ${int} -eq 0 ]; then
        logerror "${FUNCNAME[0]}" "replica status check has been finally failed"
        exit 1
      fi

      IFS=""
      SLAVEIO_ERRNR=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Last_IO_Errno: )[0-9]+$')
      SLAVEIO_ERRTXT=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Last_IO_Error: ).*$')
      SLAVESQL_STATUS=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Slave_SQL_Running: )(No|Yes)')
      SLAVESQL_ERRNR=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Last_SQL_Errno: )[0-9]+$')
      SLAVESQL_ERRTXT=$(echo ${MYSQL_RESPONSE} | grep --only-matching --perl-regexp --regexp='(?<=Last_SQL_Error: ).*$')
      IFS="${oldIFS}"

      if [ "${SLAVEIO_STATUS}" == "No" ]; then
        logerror "${FUNCNAME[0]}" "replica i/o is currently stopped and the error number '${SLAVEIO_ERRNR}' has been reported"
        logerror "${FUNCNAME[0]}" "replica i/o error message: '${SLAVEIO_ERRTXT}'"
      fi

      if [ "${SLAVESQL_STATUS}" == "No" ]; then
        logerror "${FUNCNAME[0]}" "replica sql is currently stopped and the error number '${SLAVESQL_ERRNR}' has been reported"
        logerror "${FUNCNAME[0]}" "replica sql error message: '${SLAVESQL_ERRTXT}'"
      fi

      if [ ${SLAVEIO_STATUS} == "Yes" ] && [ ${SLAVESQL_STATUS} == "Yes" ]; then
        loginfo "${FUNCNAME[0]}" "async replication active"
      else
        loginfo "${FUNCNAME[0]}" "async replication not active"
      fi
    }
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-mariadb-probes-sh
  namespace: monsoon3
data:
  startup.sh: |+
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    mysql --protocol=socket --user=root --batch --connect-timeout=20 --execute="SHOW DATABASES;" | grep --silent 'mysql'
    if [ $? -eq 0 ]; then
      echo 'MariaDB MySQL API reachable'
    else
      echo 'MariaDB MySQL API not reachable'
      exit 1
    fi

    timeout 20 bash -c "</dev/tcp/${CONTAINER_IP}/${GALERA_PORT}"
    if [ $? -eq 0 ]; then
      echo 'MariaDB Galera API reachable'
    else
      echo 'MariaDB Galera API not reachable'
      exit 1
    fi

  liveness.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    function checkdblogon {
      mysql --protocol=socket --user=root --batch --connect-timeout=20 --execute="SHOW DATABASES;" | grep --silent 'mysql'
      if [ $? -eq 0 ]; then
        echo 'MariaDB MySQL API reachable'
      else
        echo 'MariaDB MySQL API not reachable'
        exit 1
      fi
    }

    function checkgaleraport {
      timeout 20 bash -c "</dev/tcp/${CONTAINER_IP}/${GALERA_PORT}"
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera API reachable'
      else
        echo 'MariaDB Galera API not reachable'
        exit 1
      fi
    }

    checkdblogon
    checkgaleraport
    setconfigmap "running" "true" "Update"
  readiness.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    function checkgaleraclusterstatus {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_cluster_status';" --batch --skip-column-names | grep --silent 'Primary'
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera node reports a working cluster status'
      else
        echo 'MariaDB Galera node reports a not working cluster status'
        exit 1
      fi
    }

    function checkgaleranodejoinstatus {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_local_state_comment';" --batch --skip-column-names | grep --silent 'Synced'
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera node is in sync with the cluster'
      else
        echo 'MariaDB Galera node not in sync with the cluster'
        exit 1
      fi
    }

    function checkgaleranodeconnectstatus {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_connected';" --batch --skip-column-names | grep --silent 'ON'
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera node connected to other cluster nodes'
      else
        echo 'MariaDB Galera node not connected to other cluster nodes'
        exit 1
      fi
    }

    function checkgaleraready {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_ready';" --batch --skip-column-names | grep --silent 'ON'
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera ready for queries'
      else
        echo 'MariaDB Galera not ready for queries'
        exit 1
      fi
    }

    function checknoderejectsconnections {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=10 --execute="SHOW VARIABLES LIKE 'wsrep_reject_queries';" --batch --skip-column-names | grep --silent 'NONE'
      if [ $? -eq 0 ]; then
        echo 'MariaDB Galera node does accept new client connections'
      else
        echo 'MariaDB Galera node does not accept new client connections'
        exit 1
      fi
    }

    checkdblogon
    checkgaleraclusterstatus
    checkgaleranodejoinstatus
    checkgaleranodeconnectstatus
    checkgaleraready
    checknoderejectsconnections
    setconfigmap "seqno" $(fetchcurrentseqno) "Update"
    setconfigmap "primary" "true" "Update"
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: monsoon3
  name: keystone-mariadb-hooks-sh
  labels:
    app: keystone
data:
  pre-stop-hook.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    function checkgaleralocalstate {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=20 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_local_state_comment';" --batch --skip-column-names | grep --silent 'Synced'
      if [ $? -eq 0 ]; then
        loginfo "${FUNCNAME[0]}" 'MariaDB Galera node in sync with the cluster'
      else
        logerror "${FUNCNAME[0]}" 'MariaDB Galera node not synced with the cluster'
        exit 1
      fi
    }

    function checkgaleraclusterstate {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=20 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_cluster_status';" --batch --skip-column-names | grep --silent 'Primary'
      if [ $? -eq 0 ]; then
        loginfo "${FUNCNAME[0]}" 'MariaDB Galera node reports a working cluster status'
      else
        logerror "${FUNCNAME[0]}" 'MariaDB Galera node reports a not working cluster status'
        exit 1
      fi
    }

    function checkgaleranodeconnected {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=20 --execute="SHOW GLOBAL STATUS LIKE 'wsrep_connected';" --batch --skip-column-names | grep --silent 'ON'
      if [ $? -eq 0 ]; then
        loginfo "${FUNCNAME[0]}" 'MariaDB Galera node connected to other cluster nodes'
      else
        logerror "${FUNCNAME[0]}" 'MariaDB Galera node not connected to other cluster nodes'
        exit 1
      fi
    }

    function shutdowngaleranode {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=20 --execute="SHUTDOWN WAIT FOR ALL SLAVES;"
      if [ $? -eq 0 ]; then
        loginfo "${FUNCNAME[0]}" 'MariaDB Galera node shutdown successful'
      else
        logerror "${FUNCNAME[0]}" 'MariaDB Galera node shutdown failed'
        exit 1
      fi
    }

    function rejectnewconnectionstogaleranode {
      mysql --protocol=socket --user=root --database=mysql --connect-timeout=20 --execute="SET GLOBAL wsrep_reject_queries=ALL;"
      if [ $? -eq 0 ]; then
        loginfo "${FUNCNAME[0]}" 'MariaDB Galera node successfully configured to reject new connections'
      else
        logerror "${FUNCNAME[0]}" 'MariaDB Galera node configuration failed to reject new connections'
        exit 1
      fi
    }

    loginfo "null" "preStop hook started"
    checkgaleraclusterstate
    checkgaleranodeconnected
    checkgaleralocalstate
    rejectnewconnectionstogaleranode
    setconfigmap "seqno" "" "Reset"
    setconfigmap "primary" "" "Reset"
    setconfigmap "running" "" "Reset"
    loginfo "null" "preStop hook done"
  post-start-hook.sh: |
    #!/usr/bin/env bash
    set +e
    set -u
    set -o pipefail

    source /opt/${SOFTWARE_NAME}/bin/common-functions.sh

    loginfo "null" "postStart hook started"
    loginfo "null" "postStart hook done"
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-galerastatus
  namespace: monsoon3
data:
---
# Source: keystone/charts/mariadb-galera/templates/configmap-mariadb.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-mariadb-wipedata
  namespace: monsoon3
data:
  wipedata.flag: |-
    true
---
# Source: keystone/charts/owner-info/templates/configmap.yaml
kind: ConfigMap
apiVersion: v1

metadata:
  name: owner-of-keystone
  labels:
    # This can be used to validate via policy that everyone uses a reasonably up-to-date version of this chart.
    owner-info-version: "0.2.0"

data:
  helm-chart-url: "https://github.com/sapcc/helm-charts/tree/master/openstack/keystone"
  maintainers: "Boris Bobrov, Rajiv Mucheli"

  support-group: "identity"
---
# Source: keystone/templates/configmap-bin.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-bin
  labels:
    app: keystone-keystone
    release: "keystone"
    heritage: "Helm"
    component: keystone
    type: config
data:
  bootstrap: |
    #!/usr/bin/env bash
    set -ex
    trap "" EXIT
    # seed just enough to have a functional v3 api
    keystone-manage --config-file=/etc/keystone/keystone.conf bootstrap \
        --bootstrap-username admin \
        --bootstrap-password dummypass-ADMIN \
        --bootstrap-project-name admin \
        --bootstrap-admin-url https://identity-3.qa-de-1.cloud.sap/v3 \
        --bootstrap-public-url https://identity-3.qa-de-1.cloud.sap/v3 \
        --bootstrap-internal-url http://keystone.monsoon3.svc.kubernetes.qa-de-1.cloud.sap:5000/v3 \
        --bootstrap-region-id qa-de-1

  cron: |
    #!/usr/bin/env bash

    export STDOUT=${STDOUT:-/proc/1/fd/1}
    export STDERR=${STDERR:-/proc/1/fd/2}

    cat <(crontab -l) <(echo "0 * * * * PATH=${PATH}; . /scripts/repair_assignments > ${STDOUT} 2> ${STDERR}") | crontab -

    exec cron -f

  db-sync: |
    #!/usr/bin/env bash
    trap "" EXIT

    echo "Status before migration:"
    keystone-status --config-file=/etc/keystone/keystone.conf upgrade check

    echo "DB Version before migration:"
    keystone-manage --config-file=/etc/keystone/keystone.conf db_version

    keystone-manage --config-file=/etc/keystone/keystone.conf db_sync --check
    case $? in
        0)
            echo "No migration required. Database is up-2-date."
            ;;
        1)
            echo "Uhoh, Houston we have a problem."
            ;;
        2)
            echo "Database update available - starting migrations"
            # expand the database schema
            keystone-manage --config-file=/etc/keystone/keystone.conf db_sync --expand
            ;&
        3)
            echo "Database expanded"
            # run migrate
            keystone-manage --config-file=/etc/keystone/keystone.conf db_sync --migrate
            ;&
        4)
            echo "Database migrated"
            # run contraction
            keystone-manage --config-file=/etc/keystone/keystone.conf db_sync --contract
            ;;
        *)
            echo "Duno what state the database is in. grrrr"
            ;;
    esac

    echo "DB Version after migration:"
    keystone-manage --config-file=/etc/keystone/keystone.conf db_version

    echo "Keystone doctor:"
    keystone-manage --config-file=/etc/keystone/keystone.conf doctor

    # don't let the doctor break stuff (as usual not qualified enough and you allways need another opinion :P )
    exit 0

  repair_assignments: |
    #!/usr/bin/env bash
    trap "" EXIT
    export STDOUT=${STDOUT:-/proc/1/fd/1}
    export STDERR=${STDERR:-/proc/1/fd/2}

    # repair any role-assignments that point to orphaned objects (usually from users that have been deactivated by CAM)
    keystone-manage-extension --config-file=/etc/keystone/keystone.conf repair_assignments  > ${STDOUT} 2> ${STDERR}

  keystone-api.sh: |
    #!/bin/bash

    # Copyright 2017 The Openstack-Helm Authors.
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    set -ex

    COMMAND="${@:-start}"

    function start () {

      for KEYSTONE_WSGI_SCRIPT in keystone-wsgi-public; do
        cp -a $(type -p ${KEYSTONE_WSGI_SCRIPT}) /var/www/cgi-bin/keystone/
      done

      if [ -f /etc/apache2/envvars ]; then
         # Loading Apache2 ENV variables
         source /etc/apache2/envvars
      fi

      if [ ! -d "$APACHE_RUN_DIR" ]; then
        # create a apache2 runtime directory
        mkdir "$APACHE_RUN_DIR"
      fi

      if [ -f "$APACHE_PID_FILE" ]; then
        # Remove the stale pid for debian/ubuntu images
        rm -f "$APACHE_PID_FILE"
      fi

      # Start Apache2
      exec apache2 -DFOREGROUND
    }

    function stop () {
      sleep 10
      apachectl -k graceful-stop
    }

    $COMMAND

  region-check.py: |
---
# Source: keystone/templates/configmap-etc.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: keystone-etc
  labels:
    app: keystone-keystone
    release: "keystone"
    heritage: "Helm"
    component: keystone
    type: config
data:
  keystone.conf: |
    [DEFAULT]
    debug = true
    insecure_debug = false
    verbose = true

    max_token_size = 268

    log_config_append = /etc/keystone/logging.conf
    logging_context_format_string = %(process)d %(levelname)s %(name)s [%(request_id)s g%(global_request_id)s %(user_identity)s] %(instance)s%(message)s
    logging_default_format_string = %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s
    logging_exception_prefix = %(process)d ERROR %(name)s %(instance)s
    logging_user_identity_format = usr %(user)s prj %(tenant)s dom %(domain)s usr-dom %(user_domain)s prj-dom %(project_domain)s

    notification_format = "cadf"

    notification_opt_out = identity.authenticate.pending

    default_tag = vc-a-0

    default_tag = vc-b-0

    default_tag = vc-d-0

    [auth]
    methods = password,token,totp,external,oauth1,application_credential
    external = cc_x509
    password = cc_password
    totp = cc_radius
    [cc_password]
    url = https://accounts.sap.com/service/users/password

    [cc_x509]
    trusted_issuer = CN=SSO_CA,O=SAP-AG,C=DE
    trusted_issuer = CN=SAP SSO CA G2,O=SAP SE,L=Walldorf,C=DE
    user_domain_id_header: HTTP_X_USER_DOMAIN_ID
    user_domain_name_header: HTTP_X_USER_DOMAIN_NAME




    [cc_radius]
    host = jump01.cc.qa-de-1.cloud.sap
    port = 16451
    secret = dummypass



    [oauth1]
    request_token_duration = 28800
    access_token_duration = 0

    [cache]
    backend = dogpile.cache.memcached
    memcache_servers = keystone-memcached.monsoon3.svc.kubernetes.qa-de-1.cloud.sap:11211
    config_prefix = cache.keystone
    expiration_time = 600
    enabled = true

    # Directory containing Fernet keys used to encrypt and decrypt credentials
    # stored in the credential backend. Fernet keys used to encrypt credentials
    # have no relationship to Fernet keys used to encrypt Fernet tokens. Both sets
    # of keys should be managed separately and require different rotation policies.
    # Do not share this repository with the repository used to manage keys for
    # Fernet tokens. (string value)
    [credential]
    key_repository = /credential-keys

    [token]
    provider = fernet
    expiration = 28800
    allow_expired_window = 28800
    cache_on_issue = true
    cache_time = 1800

    [revoke]
    expiration_buffer = 3600

    [fernet_tokens]
    key_repository = /fernet-keys
    max_active_keys = 3

    [fernet_receipts]
    key_repository = /fernet-keys
    max_active_keys = 3

    [access_rules_config]
    rules_file = /etc/keystone/access_rules.json
    permissive = true

    [database]
    # Database connection string - MariaDB for regional setup
    # and Percona Cluster for inter-regional setup:

    connection = mysql+pymysql://keystone:dummypass@keystone-mariadb/keystone?charset=utf8

    [assignment]
    driver = sql

    [identity]
    list_limit = 1500
    default_domain_id = default
    domain_specific_drivers_enabled = true
    domain_configurations_from_database = true

    [trust]
    allow_redelegation = true

    [resource]
    admin_project_domain_name = ccadmin
    admin_project_name = cloud_admin
    bootstrap_project_domain_name = Default
    bootstrap_project_name = admin
    project_name_url_safe = new
    domain_name_url_safe = new

    [security_compliance]
    lockout_failure_attempts = 5
    lockout_duration = 300
    unique_last_password_count = 5
    disable_user_account_days_inactive = 36500

    [oslo_messaging_notifications]
    driver = messaging
    transport_url = rabbit://rabbitmq:dummypass@hermes-rabbitmq-notifications.hermes:5672/

    [oslo_messaging_rabbit]
    rabbit_retry_interval = 1
    kombu_reconnect_delay = 0.1
    rabbit_interval_max = 1
    rabbit_retry_backoff = 0
    heartbeat_timeout_threshold = 0


    [oslo_middleware]
    enable_proxy_headers_parsing = true

    [oslo_policy]
    # This option controls whether or not to enforce scope when evaluating
    # policies. If ``True``, the scope of the token used in the request is compared
    # to the ``scope_types`` of the policy being enforced. If the scopes do not
    # match, an ``InvalidScope`` exception will be raised. If ``False``, a message
    # will be logged informing operators that policies are being invoked with
    # mismatching scope. (boolean value)
    enforce_scope = false
    policy_file = /etc/keystone/policy.yaml

    [lifesaver]
    enabled = false
    memcached = keystone-memcached.monsoon3.svc.kubernetes.qa-de-1.cloud.sap:11211
    # deprecated
    domain_whitelist = Default, tempest
    # deprecated
    user_whitelist = admin, keystone, nova, neutron, cinder, glance, designate, barbican, dashboard, manila, swift

    domain_allowlist = Default, tempest
    user_allowlist = admin, keystone, nova, neutron, cinder, glance, designate, barbican, dashboard, manila, swift
    user_blocklist =
    # initial user credit
    initial_credit = 500
    # how often do we refill credit
    refill_seconds = 60
    # and with what amount
    refill_amount = 5
    # cost of each status
    status_cost = default:1,401:10,403:5,404:0,429:0
    [cors]
    allowed_origin = *
    allow_credentials = true
    expose_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Auth-Token,X-Openstack-Request-Id,X-Subject-Token
    allow_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Auth-Token,X-Openstack-Request-Id,X-Subject-Token,X-Project-Id,X-Project-Name,X-Project-Domain-Id,X-Project-Domain-Name,X-Domain-Id,X-Domain-Name,X-User-Id,X-User-Name,X-User-Domain-name

  logging.conf: |
    [loggers]
    keys = root

    [handlers]
    keys = stderr, stdout, null

    [formatters]
    keys = context, default

    [logger_root]
    level = DEBUG
    handlers = stdout


    [logger_keystone]
    level = DEBUG
    handlers = null
    qualname = keystone

    [logger_cc]
    level = DEBUG
    handlers = null
    qualname = cc

    [logger_radius]
    level = DEBUG
    handlers = null
    qualname = radius

    [logger_keystonemiddleware]
    level = DEBUG
    handlers = null
    qualname = keystonemiddleware

    [logger_keystoneauth]
    level = DEBUG
    handlers = null
    qualname = keystoneauth1

    [logger_oslo_messaging]
    level = DEBUG
    handlers = null
    qualname = oslo.messaging

    [logger_oslo_policy]
    level = DEBUG
    handlers = null
    qualname = oslo_policy

    [logger_ldap]
    level = DEBUG
    handlers = null
    qualname = keystone.common.ldap.core

    [logger_ldappool]
    level = DEBUG
    handlers = null
    qualname = ldappool

    [logger_amqp]
    level = DEBUG
    handlers = null
    qualname = amqp

    [logger_amqplib]
    level = DEBUG
    handlers = null
    qualname = amqplib

    [logger_sqlalchemy]
    level = INFO
    handlers = null
    qualname = sqlalchemy
    # "level = INFO" logs SQL queries.
    # "level = DEBUG" logs SQL queries and results.
    # "level = WARNING" logs neither.  (Recommended for production systems.)

    [logger_warnings]
    level = INFO
    handlers = null
    qualname = py.warnings

    [handler_stderr]
    class = StreamHandler
    args = (sys.stderr,)
    formatter = context

    [handler_stdout]
    class = StreamHandler
    args = (sys.stdout,)
    formatter = context

    [handler_null]
    class = logging.NullHandler
    formatter = default
    args = ()



    [formatter_context]
    class = oslo_log.formatters.ContextFormatter

    [formatter_default]
    format = %(message)s


  mpm_event.conf: |
    # Copyright 2017 The Openstack-Helm Authors.
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    <IfModule mpm_event_module>
      ServerLimit         1024
      StartServers        32
      MinSpareThreads     32
      MaxSpareThreads     256
      ThreadsPerChild     25
      ThreadLimit         720
    </IfModule>

  policy.yaml: |
    #"admin_required": "role:admin"
    "admin_required": "role:admin"

    #"service_role": "role:service"
    "service_role": "role:service"

    #"service_or_admin": "rule:admin_required or rule:service_role"
    "service_or_admin": "rule:admin_required or rule:service_role"

    #"owner": "user_id:%(user_id)s"
    "owner": "user_id:%(user_id)s"

    #"admin_or_owner": "rule:admin_required or rule:owner"

    #"token_subject": "user_id:%(target.token.user_id)s"
    "token_subject": "user_id:%(target.token.user_id)s"

    #"admin_or_token_subject": "rule:admin_required or rule:token_subject"

    #"service_admin_or_token_subject": "rule:service_or_admin or rule:token_subject"

    # ccloud: added these to allow a smooth transitioning from old cloud-admin to new system scopes
    "cloud_admin": "(role:admin and system_scope:all) or
      (role:admin and ((is_admin_project:True or domain_id:default)))"

    "cloud_reader": "(role:reader and system_scope:all) or
      role:cloud_identity_viewer or
      rule:service_role or
      rule:cloud_admin"

    "blocklist_roles": "'resource_service':%(target.role.name)s or
      'cloud_registry_admin':%(target.role.name)s or
      'cloud_registry_viewer':%(target.role.name)s or
      'cloud_dns_resource_admin':%(target.role.name)s or
      'cloud_resource_admin':%(target.role.name)s or
      'cloud_resource_viewer':%(target.role.name)s or
      'cloud_baremetal_admin':%(target.role.name)s or
      'cloud_network_admin':%(target.role.name)s or
      'cloud_dns_admin':%(target.role.name)s or
      'cloud_dns_viewer':%(target.role.name)s or
      'dns_admin':%(target.role.name)s or
      'cloud_image_admin':%(target.role.name)s or
      'cloud_compute_admin':%(target.role.name)s or
      'cloud_keymanager_admin':%(target.role.name)s or
      'cloud_volume_admin':%(target.role.name)s or
      'cloud_sharedfilesystem_admin':%(target.role.name)s or
      'cloud_sharedfilesystem_editor':%(target.role.name)s or
      'cloud_sharedfilesystem_viewer':%(target.role.name)s or
      'cloud_objectstore_admin':%(target.role.name)s or
      'cloud_objectstore_viewer':%(target.role.name)s or
      'service':%(target.role.name)s or
      'cloud_identity_viewer':%(target.role.name)s or
      'cloud_support_tools_viewer':%(target.role.name)s or
      'cloud_email_admin':%(target.role.name)s or
      'cloud_inventory_viewer':%(target.role.name)s"

    "blocklist_projects": "'9e2ae21cd643430f8efe9005a758c4e7':%(target.project.id)s"

    # Show access rule details.
    # GET  /v3/users/{user_id}/access_rules/{access_rule_id}
    # HEAD  /v3/users/{user_id}/access_rules/{access_rule_id}
    # Intended scope(s): system, project
    #"identity:get_access_rule": "(role:reader and system_scope:all) or user_id:%(target.user.id)s"
    "identity:get_access_rule": "rule:cloud_reader or user_id:%(target.user.id)s"

    # List access rules for a user.
    # GET  /v3/users/{user_id}/access_rules
    # HEAD  /v3/users/{user_id}/access_rules
    # Intended scope(s): system, project
    #"identity:list_access_rules": "(role:reader and system_scope:all) or user_id:%(target.user.id)s"
    "identity:list_access_rules": "rule:cloud_reader or user_id:%(target.user.id)s"

    # Delete an access_rule.
    # DELETE  /v3/users/{user_id}/access_rules/{access_rule_id}
    # Intended scope(s): system, project
    #"identity:delete_access_rule": "(role:admin and system_scope:all) or user_id:%(target.user.id)s"
    "identity:delete_access_rule": "rule:cloud_admin or user_id:%(target.user.id)s"

    # Authorize OAUTH1 request token.
    # PUT  /v3/OS-OAUTH1/authorize/{request_token_id}
    # Intended scope(s): project
    #"identity:authorize_request_token": "rule:admin_required"
    "identity:authorize_request_token": "rule:cloud_admin"

    # Get OAUTH1 access token for user by access token ID.
    # GET  /v3/users/{user_id}/OS-OAUTH1/access_tokens/{access_token_id}
    # Intended scope(s): project
    #"identity:get_access_token": "rule:admin_required"
    "identity:get_access_token": "rule:cloud_admin"

    # Get role for user OAUTH1 access token.
    # GET  /v3/users/{user_id}/OS-OAUTH1/access_tokens/{access_token_id}/roles/{role_id}
    # Intended scope(s): project
    #"identity:get_access_token_role": "rule:admin_required"
    "identity:get_access_token_role": "rule:cloud_admin"

    # List OAUTH1 access tokens for user.
    # GET  /v3/users/{user_id}/OS-OAUTH1/access_tokens
    # Intended scope(s): project
    #"identity:list_access_tokens": "rule:admin_required"
    "identity:list_access_tokens": "rule:cloud_admin"

    # List OAUTH1 access token roles.
    # GET  /v3/users/{user_id}/OS-OAUTH1/access_tokens/{access_token_id}/roles
    # Intended scope(s): project
    #"identity:list_access_token_roles": "rule:admin_required"
    "identity:list_access_token_roles": "rule:cloud_admin"

    # Delete OAUTH1 access token.
    # DELETE  /v3/users/{user_id}/OS-OAUTH1/access_tokens/{access_token_id}
    # Intended scope(s): project
    #"identity:delete_access_token": "rule:admin_required"
    "identity:delete_access_token": "rule:cloud_admin"

    # Show application credential details.
    # GET  /v3/users/{user_id}/application_credentials/{application_credential_id}
    # HEAD  /v3/users/{user_id}/application_credentials/{application_credential_id}
    # Intended scope(s): system, project
    #"identity:get_application_credential": "(role:reader and system_scope:all) or rule:owner"
    "identity:get_application_credential": "rule:cloud_reader or rule:owner"

    "identity:get_application_credentials": "rule:identity:get_application_credential"
    # List application credentials for a user.
    # GET  /v3/users/{user_id}/application_credentials
    # HEAD  /v3/users/{user_id}/application_credentials
    # Intended scope(s): system, project
    #"identity:list_application_credentials": "(role:reader and system_scope:all) or rule:owner"
    "identity:list_application_credentials": "rule:cloud_reader or rule:owner"

    # Create an application credential.
    # POST  /v3/users/{user_id}/application_credentials
    # Intended scope(s): project
    #"identity:create_application_credential": "user_id:%(user_id)s"

    # Delete an application credential.
    # DELETE  /v3/users/{user_id}/application_credentials/{application_credential_id}
    # Intended scope(s): system, project
    #"identity:delete_application_credential": "(role:admin and system_scope:all) or rule:owner"
    "identity:delete_application_credential": "rule:cloud_admin or rule:owner"

    "identity:delete_application_credentials": "rule:identity:delete_application_credential"
    # Get service catalog.
    # GET  /v3/auth/catalog
    # HEAD  /v3/auth/catalog
    #"identity:get_auth_catalog": ""

    # List all projects a user has access to via role assignments.
    # GET  /v3/auth/projects
    # HEAD  /v3/auth/projects
    #"identity:get_auth_projects": ""

    # List all domains a user has access to via role assignments.
    # GET  /v3/auth/domains
    # HEAD  /v3/auth/domains
    #"identity:get_auth_domains": ""

    # List systems a user has access to via role assignments.
    # GET  /v3/auth/system
    # HEAD  /v3/auth/system
    #"identity:get_auth_system": ""

    # Show OAUTH1 consumer details.
    # GET  /v3/OS-OAUTH1/consumers/{consumer_id}
    # Intended scope(s): system
    #"identity:get_consumer": "role:reader and system_scope:all"
    "identity:get_consumer": "rule:cloud_reader"

    # List OAUTH1 consumers.
    # GET  /v3/OS-OAUTH1/consumers
    # Intended scope(s): system
    #"identity:list_consumers": "role:reader and system_scope:all"
    "identity:list_consumers": "rule:cloud_reader"

    # Create OAUTH1 consumer.
    # POST  /v3/OS-OAUTH1/consumers
    # Intended scope(s): system
    #"identity:create_consumer": "role:admin and system_scope:all"
    "identity:create_consumer": "rule:cloud_admin"

    # Update OAUTH1 consumer.
    # PATCH  /v3/OS-OAUTH1/consumers/{consumer_id}
    # Intended scope(s): system
    #"identity:update_consumer": "role:admin and system_scope:all"
    "identity:update_consumer": "rule:cloud_admin"

    # Delete OAUTH1 consumer.
    # DELETE  /v3/OS-OAUTH1/consumers/{consumer_id}
    # Intended scope(s): system
    #"identity:delete_consumer": "role:admin and system_scope:all"
    "identity:delete_consumer": "rule:cloud_admin"

    # Show credentials details.
    # GET  /v3/credentials/{credential_id}
    # Intended scope(s): system, project
    #"identity:get_credential": "(role:reader and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:get_credential": "rule:cloud_reader or user_id:%(target.credential.user_id)s"

    # List credentials.
    # GET  /v3/credentials
    # Intended scope(s): system, project
    #"identity:list_credentials": "(role:reader and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:list_credentials": "rule:cloud_reader or user_id:%(target.credential.user_id)s"

    # Create credential.
    # POST  /v3/credentials
    # Intended scope(s): system, project
    #"identity:create_credential": "(role:admin and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:create_credential": "rule:cloud_admin or (user_id:%(target.credential.user_id)s and project_id:%(target.credential.project_id)s)"

    # Update credential.
    # PATCH  /v3/credentials/{credential_id}
    # Intended scope(s): system, project
    #"identity:update_credential": "(role:admin and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:update_credential": "rule:cloud_admin"

    # Delete credential.
    # DELETE  /v3/credentials/{credential_id}
    # Intended scope(s): system, project
    #"identity:delete_credential": "(role:admin and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:delete_credential": "rule:cloud_admin or user_id:%(target.credential.user_id)s"

    # Show domain details.
    # GET  /v3/domains/{domain_id}
    # Intended scope(s): system, domain, project
    #"identity:get_domain": "(role:reader and system_scope:all) or token.domain.id:%(target.domain.id)s or token.project.domain.id:%(target.domain.id)s"
    "identity:get_domain": "rule:cloud_reader or
      token.domain.id:%(target.domain.id)s or
      token.project.domain.id:%(target.domain.id)s or
      role:role_viewer"

    # List domains.
    # GET  /v3/domains
    # Intended scope(s): system
    #"identity:list_domains": "role:reader and system_scope:all"
    "identity:list_domains": "rule:cloud_reader or role:role_viewer"

    # Create domain.
    # POST  /v3/domains
    # Intended scope(s): system
    #"identity:create_domain": "role:admin and system_scope:all"
    "identity:create_domain": "rule:cloud_admin"

    # Update domain.
    # PATCH  /v3/domains/{domain_id}
    # Intended scope(s): system
    #"identity:update_domain": "role:admin and system_scope:all"
    "identity:update_domain": "rule:cloud_admin"

    # Delete domain.
    # DELETE  /v3/domains/{domain_id}
    # Intended scope(s): system
    #"identity:delete_domain": "role:admin and system_scope:all"
    "identity:delete_domain": "rule:cloud_admin"

    # Create domain configuration.
    # PUT  /v3/domains/{domain_id}/config
    # Intended scope(s): system
    #"identity:create_domain_config": "role:admin and system_scope:all"
    "identity:create_domain_config": "rule:cloud_admin"

    # Get the entire domain configuration for a domain, an option group
    # within a domain, or a specific configuration option within a group
    # for a domain.
    # GET  /v3/domains/{domain_id}/config
    # HEAD  /v3/domains/{domain_id}/config
    # GET  /v3/domains/{domain_id}/config/{group}
    # HEAD  /v3/domains/{domain_id}/config/{group}
    # GET  /v3/domains/{domain_id}/config/{group}/{option}
    # HEAD  /v3/domains/{domain_id}/config/{group}/{option}
    # Intended scope(s): system
    #"identity:get_domain_config": "role:reader and system_scope:all"
    "identity:get_domain_config": "rule:cloud_reader"

    # Get security compliance domain configuration for either a domain or
    # a specific option in a domain.
    # GET  /v3/domains/{domain_id}/config/security_compliance
    # HEAD  /v3/domains/{domain_id}/config/security_compliance
    # GET  v3/domains/{domain_id}/config/security_compliance/{option}
    # HEAD  v3/domains/{domain_id}/config/security_compliance/{option}
    # Intended scope(s): system, domain, project
    #"identity:get_security_compliance_domain_config": ""

    # Update domain configuration for either a domain, specific group or a
    # specific option in a group.
    # PATCH  /v3/domains/{domain_id}/config
    # PATCH  /v3/domains/{domain_id}/config/{group}
    # PATCH  /v3/domains/{domain_id}/config/{group}/{option}
    # Intended scope(s): system
    #"identity:update_domain_config": "role:admin and system_scope:all"
    "identity:update_domain_config": "rule:cloud_admin"

    # Delete domain configuration for either a domain, specific group or a
    # specific option in a group.
    # DELETE  /v3/domains/{domain_id}/config
    # DELETE  /v3/domains/{domain_id}/config/{group}
    # DELETE  /v3/domains/{domain_id}/config/{group}/{option}
    # Intended scope(s): system
    #"identity:delete_domain_config": "role:admin and system_scope:all"
    "identity:delete_domain_config": "rule:cloud_admin"

    # Get domain configuration default for either a domain, specific group
    # or a specific option in a group.
    # GET  /v3/domains/config/default
    # HEAD  /v3/domains/config/default
    # GET  /v3/domains/config/{group}/default
    # HEAD  /v3/domains/config/{group}/default
    # GET  /v3/domains/config/{group}/{option}/default
    # HEAD  /v3/domains/config/{group}/{option}/default
    # Intended scope(s): system
    #"identity:get_domain_config_default": "role:reader and system_scope:all"
    "identity:get_domain_config_default": "rule:cloud_reader"

    # Show ec2 credential details.
    # GET  /v3/users/{user_id}/credentials/OS-EC2/{credential_id}
    # Intended scope(s): system, project
    #"identity:ec2_get_credential": "(role:reader and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:ec2_get_credential": "rule:cloud_reader or user_id:%(target.credential.user_id)s"

    # List ec2 credentials.
    # GET  /v3/users/{user_id}/credentials/OS-EC2
    # Intended scope(s): system, project
    #"identity:ec2_list_credentials": "(role:reader and system_scope:all) or rule:owner"
    "identity:ec2_list_credentials": "rule:cloud_reader or rule:owner"

    # Create ec2 credential.
    # POST  /v3/users/{user_id}/credentials/OS-EC2
    # Intended scope(s): system, project
    #"identity:ec2_create_credential": "(role:admin and system_scope:all) or rule:owner"
    "identity:ec2_create_credential": "rule:cloud_admin or (user_id:%(target.credential.user_id)s and project_id:%(target.credential.project_id)s)"

    "identity:ec2_create_credentials": "rule:identity:ec2_create_credential"
    # Delete ec2 credential.
    # DELETE  /v3/users/{user_id}/credentials/OS-EC2/{credential_id}
    # Intended scope(s): system, project
    #"identity:ec2_delete_credential": "(role:admin and system_scope:all) or user_id:%(target.credential.user_id)s"
    "identity:ec2_delete_credential": "rule:cloud_admin or user_id:%(target.credential.user_id)s"

    "identity:ec2_delete_credentials": "rule:identity:ec2_delete_credential"
    # Show endpoint details.
    # GET  /v3/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:get_endpoint": "role:reader and system_scope:all"
    "identity:get_endpoint": "rule:cloud_reader"

    # List endpoints.
    # GET  /v3/endpoints
    # Intended scope(s): system
    #"identity:list_endpoints": "role:reader and system_scope:all"
    "identity:list_endpoints": "rule:cloud_reader"

    # Create endpoint.
    # POST  /v3/endpoints
    # Intended scope(s): system
    #"identity:create_endpoint": "role:admin and system_scope:all"
    "identity:create_endpoint": "rule:cloud_admin"

    # Update endpoint.
    # PATCH  /v3/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:update_endpoint": "role:admin and system_scope:all"
    "identity:update_endpoint": "rule:cloud_admin"

    # Delete endpoint.
    # DELETE  /v3/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:delete_endpoint": "role:admin and system_scope:all"
    "identity:delete_endpoint": "rule:cloud_admin"

    # Create endpoint group.
    # POST  /v3/OS-EP-FILTER/endpoint_groups
    # Intended scope(s): system
    #"identity:create_endpoint_group": "role:admin and system_scope:all"
    "identity:create_endpoint_group": "rule:cloud_admin"

    # List endpoint groups.
    # GET  /v3/OS-EP-FILTER/endpoint_groups
    # Intended scope(s): system
    #"identity:list_endpoint_groups": "role:reader and system_scope:all"
    "identity:list_endpoint_groups": "rule:cloud_reader"

    # Get endpoint group.
    # GET  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}
    # HEAD  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}
    # Intended scope(s): system
    #"identity:get_endpoint_group": "role:reader and system_scope:all"
    "identity:get_endpoint_group": "rule:cloud_reader"

    # Update endpoint group.
    # PATCH  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}
    # Intended scope(s): system
    #"identity:update_endpoint_group": "role:admin and system_scope:all"
    "identity:update_endpoint_group": "rule:cloud_admin"

    # Delete endpoint group.
    # DELETE  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}
    # Intended scope(s): system
    #"identity:delete_endpoint_group": "role:admin and system_scope:all"
    "identity:delete_endpoint_group": "rule:cloud_admin"

    # List all projects associated with a specific endpoint group.
    # GET  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/projects
    # Intended scope(s): system
    #"identity:list_projects_associated_with_endpoint_group": "role:reader and system_scope:all"
    "identity:list_projects_associated_with_endpoint_group": "rule:cloud_reader"

    # List all endpoints associated with an endpoint group.
    # GET  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/endpoints
    # Intended scope(s): system
    #"identity:list_endpoints_associated_with_endpoint_group": "role:reader and system_scope:all"
    "identity:list_endpoints_associated_with_endpoint_group": "rule:cloud_reader"

    # Check if an endpoint group is associated with a project.
    # GET  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/projects/{project_id}
    # HEAD  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/projects/{project_id}
    # Intended scope(s): system
    #"identity:get_endpoint_group_in_project": "role:reader and system_scope:all"
    "identity:get_endpoint_group_in_project": "rule:cloud_reader"

    # List endpoint groups associated with a specific project.
    # GET  /v3/OS-EP-FILTER/projects/{project_id}/endpoint_groups
    # Intended scope(s): system
    #"identity:list_endpoint_groups_for_project": "role:reader and system_scope:all"
    "identity:list_endpoint_groups_for_project": "rule:cloud_reader"

    # Allow a project to access an endpoint group.
    # PUT  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/projects/{project_id}
    # Intended scope(s): system
    #"identity:add_endpoint_group_to_project": "role:admin and system_scope:all"
    "identity:add_endpoint_group_to_project": "rule:cloud_admin"

    # Remove endpoint group from project.
    # DELETE  /v3/OS-EP-FILTER/endpoint_groups/{endpoint_group_id}/projects/{project_id}
    # Intended scope(s): system
    #"identity:remove_endpoint_group_from_project": "role:admin and system_scope:all"
    "identity:remove_endpoint_group_from_project": "rule:cloud_admin"

    # grant-specific rules
    "domain_admin_for_grants": "(rule:domain_admin_for_global_role_grants or rule:domain_admin_for_domain_role_grants) and not rule:blocklist_roles and not rule:blocklist_projects"
    "domain_admin_for_global_role_grants": "rule:admin_required and None:%(target.role.domain_id)s and rule:domain_admin_grant_match"
    "domain_admin_for_domain_role_grants": "rule:admin_required and domain_id:%(target.role.domain_id)s and rule:domain_admin_grant_match"
    "domain_admin_grant_match": "domain_id:%(domain_id)s or domain_id:%(target.project.domain_id)s"
    "project_admin_for_grants": "(rule:project_admin_for_global_role_grants or rule:project_admin_for_domain_role_grants) and not rule:blocklist_roles and not rule:blocklist_projects"
    "project_admin_for_global_role_grants": "(rule:admin_required or role:role_admin) and None:%(target.role.domain_id)s and project_id:%(project_id)s"
    "project_admin_for_domain_role_grants": "(rule:admin_required or role:role_admin) and project_domain_id:%(target.role.domain_id)s and project_id:%(project_id)s"
    "domain_admin_for_list_grants": "rule:admin_required and rule:domain_admin_grant_match"
    "project_admin_for_list_grants": "(rule:admin_required or role:role_admin or role:role_viewer) and project_id:%(project_id)s"

    # Check a role grant between a target and an actor. A target can be
    # either a domain or a project. An actor can be either a user or a
    # group. These terms also apply to the OS-INHERIT APIs, where grants
    # on the target are inherited to all projects in the subtree, if
    # applicable.
    # HEAD  /v3/projects/{project_id}/users/{user_id}/roles/{role_id}
    # GET  /v3/projects/{project_id}/users/{user_id}/roles/{role_id}
    # HEAD  /v3/projects/{project_id}/groups/{group_id}/roles/{role_id}
    # GET  /v3/projects/{project_id}/groups/{group_id}/roles/{role_id}
    # HEAD  /v3/domains/{domain_id}/users/{user_id}/roles/{role_id}
    # GET  /v3/domains/{domain_id}/users/{user_id}/roles/{role_id}
    # HEAD  /v3/domains/{domain_id}/groups/{group_id}/roles/{role_id}
    # GET  /v3/domains/{domain_id}/groups/{group_id}/roles/{role_id}
    # HEAD  /v3/OS-INHERIT/projects/{project_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # GET  /v3/OS-INHERIT/projects/{project_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # HEAD  /v3/OS-INHERIT/projects/{project_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # GET  /v3/OS-INHERIT/projects/{project_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # HEAD  /v3/OS-INHERIT/domains/{domain_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # GET  /v3/OS-INHERIT/domains/{domain_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # HEAD  /v3/OS-INHERIT/domains/{domain_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # GET  /v3/OS-INHERIT/domains/{domain_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # Intended scope(s): system, domain
    #"identity:check_grant": "(role:reader and system_scope:all) or ((role:reader and domain_id:%(target.user.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:reader and domain_id:%(target.user.domain_id)s and domain_id:%(target.domain.id)s) or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.domain.id)s)) and (domain_id:%(target.role.domain_id)s or None:%(target.role.domain_id)s)"
    "identity:check_grant": "rule:cloud_admin or rule:domain_admin_for_grants or rule:project_admin_for_grants"

    # List roles granted to an actor on a target. A target can be either a
    # domain or a project. An actor can be either a user or a group. For
    # the OS-INHERIT APIs, it is possible to list inherited role grants
    # for actors on domains, where grants are inherited to all projects in
    # the specified domain.
    # GET  /v3/projects/{project_id}/users/{user_id}/roles
    # HEAD  /v3/projects/{project_id}/users/{user_id}/roles
    # GET  /v3/projects/{project_id}/groups/{group_id}/roles
    # HEAD  /v3/projects/{project_id}/groups/{group_id}/roles
    # GET  /v3/domains/{domain_id}/users/{user_id}/roles
    # HEAD  /v3/domains/{domain_id}/users/{user_id}/roles
    # GET  /v3/domains/{domain_id}/groups/{group_id}/roles
    # HEAD  /v3/domains/{domain_id}/groups/{group_id}/roles
    # GET  /v3/OS-INHERIT/domains/{domain_id}/groups/{group_id}/roles/inherited_to_projects
    # GET  /v3/OS-INHERIT/domains/{domain_id}/users/{user_id}/roles/inherited_to_projects
    # Intended scope(s): system, domain
    #"identity:list_grants": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.user.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:reader and domain_id:%(target.user.domain_id)s and domain_id:%(target.domain.id)s) or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.domain.id)s)"
    "identity:list_grants": "rule:cloud_admin or rule:domain_admin_for_list_grants or rule:project_admin_for_list_grants"

    # Create a role grant between a target and an actor. A target can be
    # either a domain or a project. An actor can be either a user or a
    # group. These terms also apply to the OS-INHERIT APIs, where grants
    # on the target are inherited to all projects in the subtree, if
    # applicable.
    # PUT  /v3/projects/{project_id}/users/{user_id}/roles/{role_id}
    # PUT  /v3/projects/{project_id}/groups/{group_id}/roles/{role_id}
    # PUT  /v3/domains/{domain_id}/users/{user_id}/roles/{role_id}
    # PUT  /v3/domains/{domain_id}/groups/{group_id}/roles/{role_id}
    # PUT  /v3/OS-INHERIT/projects/{project_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # PUT  /v3/OS-INHERIT/projects/{project_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # PUT  /v3/OS-INHERIT/domains/{domain_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # PUT  /v3/OS-INHERIT/domains/{domain_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # Intended scope(s): system, domain
    #"identity:create_grant": "(role:admin and system_scope:all) or ((role:admin and domain_id:%(target.user.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:admin and domain_id:%(target.user.domain_id)s and domain_id:%(target.domain.id)s) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.domain.id)s)) and (domain_id:%(target.role.domain_id)s or None:%(target.role.domain_id)s)"
    "identity:create_grant": "rule:cloud_admin or rule:domain_admin_for_grants or rule:project_admin_for_grants"

    # Revoke a role grant between a target and an actor. A target can be
    # either a domain or a project. An actor can be either a user or a
    # group. These terms also apply to the OS-INHERIT APIs, where grants
    # on the target are inherited to all projects in the subtree, if
    # applicable. In that case, revoking the role grant in the target
    # would remove the logical effect of inheriting it to the target's
    # projects subtree.
    # DELETE  /v3/projects/{project_id}/users/{user_id}/roles/{role_id}
    # DELETE  /v3/projects/{project_id}/groups/{group_id}/roles/{role_id}
    # DELETE  /v3/domains/{domain_id}/users/{user_id}/roles/{role_id}
    # DELETE  /v3/domains/{domain_id}/groups/{group_id}/roles/{role_id}
    # DELETE  /v3/OS-INHERIT/projects/{project_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # DELETE  /v3/OS-INHERIT/projects/{project_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # DELETE  /v3/OS-INHERIT/domains/{domain_id}/users/{user_id}/roles/{role_id}/inherited_to_projects
    # DELETE  /v3/OS-INHERIT/domains/{domain_id}/groups/{group_id}/roles/{role_id}/inherited_to_projects
    # Intended scope(s): system, domain
    #"identity:revoke_grant": "(role:admin and system_scope:all) or ((role:admin and domain_id:%(target.user.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:admin and domain_id:%(target.user.domain_id)s and domain_id:%(target.domain.id)s) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.project.domain_id)s) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.domain.id)s)) and (domain_id:%(target.role.domain_id)s or None:%(target.role.domain_id)s)"
    "identity:revoke_grant": "rule:cloud_admin or rule:domain_admin_for_grants or rule:project_admin_for_grants"

    # List all grants a specific user has on the system.
    # ['HEAD', 'GET']  /v3/system/users/{user_id}/roles
    # Intended scope(s): system
    #"identity:list_system_grants_for_user": "role:reader and system_scope:all"
    "identity:list_system_grants_for_user": "rule:cloud_reader"

    # Check if a user has a role on the system.
    # ['HEAD', 'GET']  /v3/system/users/{user_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:check_system_grant_for_user": "role:reader and system_scope:all"
    "identity:check_system_grant_for_user": "rule:cloud_reader"

    # Grant a user a role on the system.
    # ['PUT']  /v3/system/users/{user_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:create_system_grant_for_user": "role:admin and system_scope:all"
    "identity:create_system_grant_for_user": "rule:cloud_admin"

    # Remove a role from a user on the system.
    # ['DELETE']  /v3/system/users/{user_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:revoke_system_grant_for_user": "role:admin and system_scope:all"
    "identity:revoke_system_grant_for_user": "rule:cloud_admin"

    # List all grants a specific group has on the system.
    # ['HEAD', 'GET']  /v3/system/groups/{group_id}/roles
    # Intended scope(s): system
    #"identity:list_system_grants_for_group": "role:reader and system_scope:all"
    "identity:list_system_grants_for_group": "rule:cloud_reader"

    # Check if a group has a role on the system.
    # ['HEAD', 'GET']  /v3/system/groups/{group_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:check_system_grant_for_group": "role:reader and system_scope:all"
    "identity:check_system_grant_for_group": "rule:cloud_reader"

    # Grant a group a role on the system.
    # ['PUT']  /v3/system/groups/{group_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:create_system_grant_for_group": "role:admin and system_scope:all"
    "identity:create_system_grant_for_group": "rule:cloud_admin"

    # Remove a role from a group on the system.
    # ['DELETE']  /v3/system/groups/{group_id}/roles/{role_id}
    # Intended scope(s): system
    #"identity:revoke_system_grant_for_group": "role:admin and system_scope:all"
    "identity:revoke_system_grant_for_group": "rule:cloud_admin"

    # Show group details.
    # GET  /v3/groups/{group_id}
    # HEAD  /v3/groups/{group_id}
    # Intended scope(s): system, domain
    #"identity:get_group": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.group.domain_id)s)"
    "identity:get_group": "rule:cloud_reader or
      (role:reader and domain_id:%(target.group.domain_id)s) or
      role:role_viewer"

    # List groups.
    # GET  /v3/groups
    # HEAD  /v3/groups
    # Intended scope(s): system, domain
    #"identity:list_groups": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.group.domain_id)s)"
    "identity:list_groups": "rule:cloud_reader or
      (role:reader and (domain_id:%(target.group.domain_id)s or domain_id:%(domain_id)s)) or
      (role:role_viewer and (project_domain_id:%(domain_id)s) or project_domain_id:%(target.group.domain_id)s)"

    # List groups to which a user belongs.
    # GET  /v3/users/{user_id}/groups
    # HEAD  /v3/users/{user_id}/groups
    # Intended scope(s): system, domain, project
    #"identity:list_groups_for_user": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.user.domain_id)s) or user_id:%(user_id)s"
    "identity:list_groups_for_user": "rule:cloud_reader or
      (role:reader and domain_id:%(target.user.domain_id)s) or
      user_id:%(user_id)s"

    # Create group.
    # POST  /v3/groups
    # Intended scope(s): system, domain
    #"identity:create_group": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.group.domain_id)s)"
    "identity:create_group": "rule:cloud_admin or (role:admin and domain_id:%(target.group.domain_id)s)"

    # Update group.
    # PATCH  /v3/groups/{group_id}
    # Intended scope(s): system, domain
    #"identity:update_group": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.group.domain_id)s)"
    "identity:update_group": "rule:cloud_admin or (role:admin and domain_id:%(target.group.domain_id)s)"

    # Delete group.
    # DELETE  /v3/groups/{group_id}
    # Intended scope(s): system, domain
    #"identity:delete_group": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.group.domain_id)s)"
    "identity:delete_group": "rule:cloud_admin"

    # List members of a specific group.
    # GET  /v3/groups/{group_id}/users
    # HEAD  /v3/groups/{group_id}/users
    # Intended scope(s): system, domain
    #"identity:list_users_in_group": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.group.domain_id)s)"
    "identity:list_users_in_group": "rule:cloud_reader or (role:reader and domain_id:%(target.group.domain_id)s)"

    # Remove user from group.
    # DELETE  /v3/groups/{group_id}/users/{user_id}
    # Intended scope(s): system, domain
    #"identity:remove_user_from_group": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"
    "identity:remove_user_from_group": "rule:cloud_admin or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"

    # Check whether a user is a member of a group.
    # HEAD  /v3/groups/{group_id}/users/{user_id}
    # GET  /v3/groups/{group_id}/users/{user_id}
    # Intended scope(s): system, domain
    #"identity:check_user_in_group": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"
    "identity:check_user_in_group": "rule:cloud_reader or (role:reader and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"

    # Add user to group.
    # PUT  /v3/groups/{group_id}/users/{user_id}
    # Intended scope(s): system, domain
    #"identity:add_user_to_group": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"
    "identity:add_user_to_group": "rule:cloud_admin or (role:admin and domain_id:%(target.group.domain_id)s and domain_id:%(target.user.domain_id)s)"

    # Create identity provider.
    # PUT  /v3/OS-FEDERATION/identity_providers/{idp_id}
    # Intended scope(s): system
    #"identity:create_identity_provider": "role:admin and system_scope:all"
    "identity:create_identity_provider": "rule:cloud_admin"

    "identity:create_identity_providers": "rule:identity:create_identity_provider"
    # List identity providers.
    # GET  /v3/OS-FEDERATION/identity_providers
    # HEAD  /v3/OS-FEDERATION/identity_providers
    # Intended scope(s): system
    #"identity:list_identity_providers": "role:reader and system_scope:all"
    "identity:list_identity_providers": "rule:cloud_reader"

    # Get identity provider.
    # GET  /v3/OS-FEDERATION/identity_providers/{idp_id}
    # HEAD  /v3/OS-FEDERATION/identity_providers/{idp_id}
    # Intended scope(s): system
    #"identity:get_identity_provider": "role:reader and system_scope:all"
    "identity:get_identity_provider": "rule:cloud_reader"

    "identity:get_identity_providers": "rule:identity:get_identity_provider"
    # Update identity provider.
    # PATCH  /v3/OS-FEDERATION/identity_providers/{idp_id}
    # Intended scope(s): system
    #"identity:update_identity_provider": "role:admin and system_scope:all"
    "identity:update_identity_provider": "rule:cloud_admin"

    "identity:update_identity_providers": "rule:identity:update_identity_provider"
    # Delete identity provider.
    # DELETE  /v3/OS-FEDERATION/identity_providers/{idp_id}
    # Intended scope(s): system
    #"identity:delete_identity_provider": "role:admin and system_scope:all"
    "identity:delete_identity_provider": "rule:cloud_admin"

    "identity:delete_identity_providers": "rule:identity:delete_identity_provider"
    # Get information about an association between two roles. When a
    # relationship exists between a prior role and an implied role and the
    # prior role is assigned to a user, the user also assumes the implied
    # role.
    # GET  /v3/roles/{prior_role_id}/implies/{implied_role_id}
    # Intended scope(s): system
    #"identity:get_implied_role": "role:reader and system_scope:all"
    "identity:get_implied_role": "rule:cloud_reader"

    # List associations between two roles. When a relationship exists
    # between a prior role and an implied role and the prior role is
    # assigned to a user, the user also assumes the implied role. This
    # will return all the implied roles that would be assumed by the user
    # who gets the specified prior role.
    # GET  /v3/roles/{prior_role_id}/implies
    # HEAD  /v3/roles/{prior_role_id}/implies
    # Intended scope(s): system
    #"identity:list_implied_roles": "role:reader and system_scope:all"
    "identity:list_implied_roles": "rule:cloud_reader"

    # Create an association between two roles. When a relationship exists
    # between a prior role and an implied role and the prior role is
    # assigned to a user, the user also assumes the implied role.
    # PUT  /v3/roles/{prior_role_id}/implies/{implied_role_id}
    # Intended scope(s): system
    #"identity:create_implied_role": "role:admin and system_scope:all"
    "identity:create_implied_role": "rule:cloud_admin"

    # Delete the association between two roles. When a relationship exists
    # between a prior role and an implied role and the prior role is
    # assigned to a user, the user also assumes the implied role. Removing
    # the association will cause that effect to be eliminated.
    # DELETE  /v3/roles/{prior_role_id}/implies/{implied_role_id}
    # Intended scope(s): system
    #"identity:delete_implied_role": "role:admin and system_scope:all"
    "identity:delete_implied_role": "rule:cloud_admin"

    # List all associations between two roles in the system. When a
    # relationship exists between a prior role and an implied role and the
    # prior role is assigned to a user, the user also assumes the implied
    # role.
    # GET  /v3/role_inferences
    # HEAD  /v3/role_inferences
    # Intended scope(s): system
    #"identity:list_role_inference_rules": "role:reader and system_scope:all"
    "identity:list_role_inference_rules": "rule:cloud_reader or role:role_viewer"

    # Check an association between two roles. When a relationship exists
    # between a prior role and an implied role and the prior role is
    # assigned to a user, the user also assumes the implied role.
    # HEAD  /v3/roles/{prior_role_id}/implies/{implied_role_id}
    # Intended scope(s): system
    #"identity:check_implied_role": "role:reader and system_scope:all"
    "identity:check_implied_role": "rule:cloud_reader or role:role_viewer"

    # Get limit enforcement model.
    # GET  /v3/limits/model
    # HEAD  /v3/limits/model
    # Intended scope(s): system, domain, project
    #"identity:get_limit_model": ""

    # Show limit details.
    # GET  /v3/limits/{limit_id}
    # HEAD  /v3/limits/{limit_id}
    # Intended scope(s): system, domain, project
    #"identity:get_limit": "(role:reader and system_scope:all) or (domain_id:%(target.limit.domain.id)s or domain_id:%(target.limit.project.domain_id)s) or (project_id:%(target.limit.project_id)s and not None:%(target.limit.project_id)s)"
    "identity:get_limit": "rule:cloud_reader or
      (domain_id:%(target.limit.domain.id)s or domain_id:%(target.limit.project.domain_id)s) or
      (project_id:%(target.limit.project_id)s and not None:%(target.limit.project_id)s)"

    # List limits.
    # GET  /v3/limits
    # HEAD  /v3/limits
    # Intended scope(s): system, domain, project
    #"identity:list_limits": ""

    # Create limits.
    # POST  /v3/limits
    # Intended scope(s): system
    #"identity:create_limits": "role:admin and system_scope:all"
    "identity:create_limits": "rule:cloud_admin"

    # Update limit.
    # PATCH  /v3/limits/{limit_id}
    # Intended scope(s): system
    #"identity:update_limit": "role:admin and system_scope:all"
    "identity:update_limit": "rule:cloud_admin"

    # Delete limit.
    # DELETE  /v3/limits/{limit_id}
    # Intended scope(s): system
    #"identity:delete_limit": "role:admin and system_scope:all"
    "identity:delete_limit": "rule:cloud_admin"

    # Create a new federated mapping containing one or more sets of rules.
    # PUT  /v3/OS-FEDERATION/mappings/{mapping_id}
    # Intended scope(s): system
    #"identity:create_mapping": "role:admin and system_scope:all"
    "identity:create_mapping": "rule:cloud_admin"

    # Get a federated mapping.
    # GET  /v3/OS-FEDERATION/mappings/{mapping_id}
    # HEAD  /v3/OS-FEDERATION/mappings/{mapping_id}
    # Intended scope(s): system
    #"identity:get_mapping": "role:reader and system_scope:all"
    "identity:get_mapping": "rule:cloud_reader"

    # List federated mappings.
    # GET  /v3/OS-FEDERATION/mappings
    # HEAD  /v3/OS-FEDERATION/mappings
    # Intended scope(s): system
    #"identity:list_mappings": "role:reader and system_scope:all"
    "identity:list_mappings": "rule:cloud_reader"

    # Delete a federated mapping.
    # DELETE  /v3/OS-FEDERATION/mappings/{mapping_id}
    # Intended scope(s): system
    #"identity:delete_mapping": "role:admin and system_scope:all"
    "identity:delete_mapping": "rule:cloud_admin"

    # Update a federated mapping.
    # PATCH  /v3/OS-FEDERATION/mappings/{mapping_id}
    # Intended scope(s): system
    #"identity:update_mapping": "role:admin and system_scope:all"
    "identity:update_mapping": "rule:cloud_admin"

    # Show policy details.
    # GET  /v3/policies/{policy_id}
    # Intended scope(s): system
    #"identity:get_policy": "role:reader and system_scope:all"
    "identity:get_policy": "rule:cloud_reader"

    # List policies.
    # GET  /v3/policies
    # Intended scope(s): system
    #"identity:list_policies": "role:reader and system_scope:all"
    "identity:list_policies": "rule:cloud_reader"

    # Create policy.
    # POST  /v3/policies
    # Intended scope(s): system
    #"identity:create_policy": "role:admin and system_scope:all"
    "identity:create_policy": "rule:cloud_admin"

    # Update policy.
    # PATCH  /v3/policies/{policy_id}
    # Intended scope(s): system
    #"identity:update_policy": "role:admin and system_scope:all"
    "identity:update_policy": "rule:cloud_admin"

    # Delete policy.
    # DELETE  /v3/policies/{policy_id}
    # Intended scope(s): system
    #"identity:delete_policy": "role:admin and system_scope:all"
    "identity:delete_policy": "rule:cloud_admin"

    # Associate a policy to a specific endpoint.
    # PUT  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:create_policy_association_for_endpoint": "role:admin and system_scope:all"
    "identity:create_policy_association_for_endpoint": "rule:cloud_admin"

    # Check policy association for endpoint.
    # GET  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/endpoints/{endpoint_id}
    # HEAD  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:check_policy_association_for_endpoint": "role:reader and system_scope:all"
    "identity:check_policy_association_for_endpoint": "rule:cloud_reader"

    # Delete policy association for endpoint.
    # DELETE  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:delete_policy_association_for_endpoint": "role:admin and system_scope:all"
    "identity:delete_policy_association_for_endpoint": "rule:cloud_admin"

    # Associate a policy to a specific service.
    # PUT  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}
    # Intended scope(s): system
    #"identity:create_policy_association_for_service": "role:admin and system_scope:all"
    "identity:create_policy_association_for_service": "rule:cloud_admin"

    # Check policy association for service.
    # GET  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}
    # HEAD  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}
    # Intended scope(s): system
    #"identity:check_policy_association_for_service": "role:reader and system_scope:all"
    "identity:check_policy_association_for_service": "rule:cloud_reader"

    # Delete policy association for service.
    # DELETE  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}
    # Intended scope(s): system
    #"identity:delete_policy_association_for_service": "role:admin and system_scope:all"
    "identity:delete_policy_association_for_service": "rule:cloud_admin"

    # Associate a policy to a specific region and service combination.
    # PUT  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}/regions/{region_id}
    # Intended scope(s): system
    #"identity:create_policy_association_for_region_and_service": "role:admin and system_scope:all"
    "identity:create_policy_association_for_region_and_service": "rule:cloud_admin"

    # Check policy association for region and service.
    # GET  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}/regions/{region_id}
    # HEAD  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}/regions/{region_id}
    # Intended scope(s): system
    #"identity:check_policy_association_for_region_and_service": "role:reader and system_scope:all"
    "identity:check_policy_association_for_region_and_service": "rule:cloud_reader"

    # Delete policy association for region and service.
    # DELETE  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/services/{service_id}/regions/{region_id}
    # Intended scope(s): system
    #"identity:delete_policy_association_for_region_and_service": "role:admin and system_scope:all"
    "identity:delete_policy_association_for_region_and_service": "rule:cloud_admin"

    # Get policy for endpoint.
    # GET  /v3/endpoints/{endpoint_id}/OS-ENDPOINT-POLICY/policy
    # HEAD  /v3/endpoints/{endpoint_id}/OS-ENDPOINT-POLICY/policy
    # Intended scope(s): system
    #"identity:get_policy_for_endpoint": "role:reader and system_scope:all"
    "identity:get_policy_for_endpoint": "rule:cloud_reader"

    # List endpoints for policy.
    # GET  /v3/policies/{policy_id}/OS-ENDPOINT-POLICY/endpoints
    # Intended scope(s): system
    #"identity:list_endpoints_for_policy": "role:reader and system_scope:all"
    "identity:list_endpoints_for_policy": "rule:cloud_reader"

    # Show project details.
    # GET  /v3/projects/{project_id}
    # Intended scope(s): system, domain, project
    #"identity:get_project": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.project.domain_id)s) or project_id:%(target.project.id)s"
    "identity:get_project": "rule:cloud_reader or
      (role:reader and domain_id:%(target.project.domain_id)s) or
      project_id:%(target.project.id)s or
      role:role_viewer"

    # List projects.
    # GET  /v3/projects
    # Intended scope(s): system, domain
    #"identity:list_projects": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.domain_id)s)"
    "identity:list_projects": "rule:cloud_reader or
      (role:reader and domain_id:%(target.domain_id)s)"

    # List projects for user.
    # GET  /v3/users/{user_id}/projects
    # Intended scope(s): system, domain, project
    #"identity:list_user_projects": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.user.domain_id)s) or user_id:%(target.user.id)s"
    "identity:list_user_projects": "rule:cloud_reader or
      (role:reader and domain_id:%(target.user.domain_id)s) or
      user_id:%(target.user.id)s"

    # Create project.
    # POST  /v3/projects
    # Intended scope(s): system, domain
    #"identity:create_project": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s)"
    "identity:create_project": "rule:cloud_admin or (role:admin and domain_id:%(target.project.domain_id)s)"

    # Update project.
    # PATCH  /v3/projects/{project_id}
    # Intended scope(s): system, domain
    #"identity:update_project": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s)"
    "identity:update_project": "rule:cloud_admin or (role:admin and domain_id:%(target.project.domain_id)s)"

    # Delete project.
    # DELETE  /v3/projects/{project_id}
    # Intended scope(s): system, domain
    #"identity:delete_project": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s)"
    "identity:delete_project": "rule:cloud_admin"

    # List tags for a project.
    # GET  /v3/projects/{project_id}/tags
    # HEAD  /v3/projects/{project_id}/tags
    # Intended scope(s): system, domain, project
    #"identity:list_project_tags": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.project.domain_id)s) or project_id:%(target.project.id)s"
    "identity:list_project_tags": "rule:cloud_reader or (role:reader and domain_id:%(target.project.domain_id)s) or project_id:%(target.project.id)s"

    # Check if project contains a tag.
    # GET  /v3/projects/{project_id}/tags/{value}
    # HEAD  /v3/projects/{project_id}/tags/{value}
    # Intended scope(s): system, domain, project
    #"identity:get_project_tag": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.project.domain_id)s) or project_id:%(target.project.id)s"
    "identity:get_project_tag": "rule:cloud_reader or (role:reader and domain_id:%(target.project.domain_id)s) or project_id:%(target.project.id)s"

    # Replace all tags on a project with the new set of tags.
    # PUT  /v3/projects/{project_id}/tags
    # Intended scope(s): system, domain, project
    #"identity:update_project_tags": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s) or (role:admin and project_id:%(target.project.id)s)"
    "identity:update_project_tags": "rule:cloud_admin or rule:service_role"

    # Add a single tag to a project.
    # PUT  /v3/projects/{project_id}/tags/{value}
    # Intended scope(s): system, domain, project
    #"identity:create_project_tag": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s) or (role:admin and project_id:%(target.project.id)s)"
    "identity:create_project_tag": "rule:cloud_admin or rule:service_role"

    # Remove all tags from a project.
    # DELETE  /v3/projects/{project_id}/tags
    # Intended scope(s): system, domain, project
    #"identity:delete_project_tags": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s) or (role:admin and project_id:%(target.project.id)s)"
    "identity:delete_project_tags": "rule:cloud_admin or rule:service_role"

    # Delete a specified tag from project.
    # DELETE  /v3/projects/{project_id}/tags/{value}
    # Intended scope(s): system, domain, project
    #"identity:delete_project_tag": "(role:admin and system_scope:all) or (role:admin and domain_id:%(target.project.domain_id)s) or (role:admin and project_id:%(target.project.id)s)"
    "identity:delete_project_tag": "rule:cloud_admin or rule:service_role"

    # List projects allowed to access an endpoint.
    # GET  /v3/OS-EP-FILTER/endpoints/{endpoint_id}/projects
    # Intended scope(s): system
    #"identity:list_projects_for_endpoint": "role:reader and system_scope:all"
    "identity:list_projects_for_endpoint": "rule:cloud_reader"

    # Allow project to access an endpoint.
    # PUT  /v3/OS-EP-FILTER/projects/{project_id}/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:add_endpoint_to_project": "role:admin and system_scope:all"
    "identity:add_endpoint_to_project": "rule:cloud_admin"

    # Check if a project is allowed to access an endpoint.
    # GET  /v3/OS-EP-FILTER/projects/{project_id}/endpoints/{endpoint_id}
    # HEAD  /v3/OS-EP-FILTER/projects/{project_id}/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:check_endpoint_in_project": "role:reader and system_scope:all"
    "identity:check_endpoint_in_project": "rule:cloud_reader"

    # List the endpoints a project is allowed to access.
    # GET  /v3/OS-EP-FILTER/projects/{project_id}/endpoints
    # Intended scope(s): system
    #"identity:list_endpoints_for_project": "role:reader and system_scope:all"
    "identity:list_endpoints_for_project": "rule:cloud_reader"

    # Remove access to an endpoint from a project that has previously been
    # given explicit access.
    # DELETE  /v3/OS-EP-FILTER/projects/{project_id}/endpoints/{endpoint_id}
    # Intended scope(s): system
    #"identity:remove_endpoint_from_project": "role:admin and system_scope:all"
    "identity:remove_endpoint_from_project": "rule:cloud_admin"

    # Create federated protocol.
    # PUT  /v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}
    # Intended scope(s): system
    #"identity:create_protocol": "role:admin and system_scope:all"
    "identity:create_protocol": "rule:cloud_admin"

    # Update federated protocol.
    # PATCH  /v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}
    # Intended scope(s): system
    #"identity:update_protocol": "role:admin and system_scope:all"
    "identity:update_protocol": "rule:cloud_admin"

    # Get federated protocol.
    # GET  /v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}
    # Intended scope(s): system
    #"identity:get_protocol": "role:reader and system_scope:all"
    "identity:get_protocol": "rule:cloud_reader"

    # List federated protocols.
    # GET  /v3/OS-FEDERATION/identity_providers/{idp_id}/protocols
    # Intended scope(s): system
    #"identity:list_protocols": "role:reader and system_scope:all"
    "identity:list_protocols": "rule:cloud_reader"

    # Delete federated protocol.
    # DELETE  /v3/OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}
    # Intended scope(s): system
    #"identity:delete_protocol": "role:admin and system_scope:all"
    "identity:delete_protocol": "rule:cloud_admin"

    # Show region details.
    # GET  /v3/regions/{region_id}
    # HEAD  /v3/regions/{region_id}
    # Intended scope(s): system, domain, project
    #"identity:get_region": ""

    # List regions.
    # GET  /v3/regions
    # HEAD  /v3/regions
    # Intended scope(s): system, domain, project
    #"identity:list_regions": ""

    # Create region.
    # POST  /v3/regions
    # PUT  /v3/regions/{region_id}
    # Intended scope(s): system
    #"identity:create_region": "role:admin and system_scope:all"
    "identity:create_region": "rule:cloud_admin"

    # Update region.
    # PATCH  /v3/regions/{region_id}
    # Intended scope(s): system
    #"identity:update_region": "role:admin and system_scope:all"
    "identity:update_region": "rule:cloud_admin"

    # Delete region.
    # DELETE  /v3/regions/{region_id}
    # Intended scope(s): system
    #"identity:delete_region": "role:admin and system_scope:all"
    "identity:delete_region": "rule:cloud_admin"

    # Show registered limit details.
    # GET  /v3/registered_limits/{registered_limit_id}
    # HEAD  /v3/registered_limits/{registered_limit_id}
    # Intended scope(s): system, domain, project
    #"identity:get_registered_limit": ""

    # List registered limits.
    # GET  /v3/registered_limits
    # HEAD  /v3/registered_limits
    # Intended scope(s): system, domain, project
    #"identity:list_registered_limits": ""

    # Create registered limits.
    # POST  /v3/registered_limits
    # Intended scope(s): system
    #"identity:create_registered_limits": "role:admin and system_scope:all"
    "identity:create_registered_limits": "rule:cloud_admin"

    # Update registered limit.
    # PATCH  /v3/registered_limits/{registered_limit_id}
    # Intended scope(s): system
    #"identity:update_registered_limit": "role:admin and system_scope:all"
    "identity:update_registered_limit": "rule:cloud_admin"

    # Delete registered limit.
    # DELETE  /v3/registered_limits/{registered_limit_id}
    # Intended scope(s): system
    #"identity:delete_registered_limit": "role:admin and system_scope:all"
    "identity:delete_registered_limit": "rule:cloud_admin"

    # List revocation events.
    # GET  /v3/OS-REVOKE/events
    # Intended scope(s): system
    #"identity:list_revoke_events": "rule:service_or_admin"

    # Show role details.
    # GET  /v3/roles/{role_id}
    # HEAD  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:get_role": "role:reader and system_scope:all"
    "identity:get_role": "rule:cloud_reader or
      role:admin or
      role:role_admin or
      role:role_viewer"

    # List roles.
    # GET  /v3/roles
    # HEAD  /v3/roles
    # Intended scope(s): system
    #"identity:list_roles": "role:reader and system_scope:all"
    "identity:list_roles": "rule:cloud_reader or
      role:admin or
      role:role_admin or
      role:role_viewer"

    # Create role.
    # POST  /v3/roles
    # Intended scope(s): system
    #"identity:create_role": "role:admin and system_scope:all"
    "identity:create_role": "rule:cloud_admin"

    # PATCH  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:update_role": "role:admin and system_scope:all"
    "identity:update_role": "rule:cloud_admin"

    # Delete role.
    # DELETE  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:delete_role": "role:admin and system_scope:all"
    "identity:delete_role": "rule:cloud_admin"

    # Show domain role.
    # GET  /v3/roles/{role_id}
    # HEAD  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:get_domain_role": "role:reader and system_scope:all"
    "identity:get_domain_role": "rule:cloud_reader"

    # List domain roles.
    # GET  /v3/roles?domain_id={domain_id}
    # HEAD  /v3/roles?domain_id={domain_id}
    # Intended scope(s): system
    #"identity:list_domain_roles": "role:reader and system_scope:all"
    "identity:list_domain_roles": "rule:cloud_reader"

    # Create domain role.
    # POST  /v3/roles
    # Intended scope(s): system
    #"identity:create_domain_role": "role:admin and system_scope:all"
    "identity:create_domain_role": "rule:cloud_admin"

    # Update domain role.
    # PATCH  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:update_domain_role": "role:admin and system_scope:all"
    "identity:update_domain_role": "rule:cloud_admin"

    # Delete domain role.
    # DELETE  /v3/roles/{role_id}
    # Intended scope(s): system
    #"identity:delete_domain_role": "role:admin and system_scope:all"
    "identity:delete_domain_role": "rule:cloud_admin"

    # List role assignments.
    # GET  /v3/role_assignments
    # HEAD  /v3/role_assignments
    # Intended scope(s): system, domain
    #"identity:list_role_assignments": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.domain_id)s)"
    "identity:list_role_assignments": "rule:cloud_reader or
      (role:reader and domain_id:%(target.domain_id)s) or
      (role:reader and domain_id:%(scope.domain.id)s) or
      ((role:reader or role:role_viewer) and project_id:%(scope.project.id)s)"

    # List all role assignments for a given tree of hierarchical projects.
    # GET  /v3/role_assignments?include_subtree
    # HEAD  /v3/role_assignments?include_subtree
    # Intended scope(s): system, domain, project
    #"identity:list_role_assignments_for_tree": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.project.domain_id)s) or (role:admin and project_id:%(target.project.id)s)"
    "identity:list_role_assignments_for_tree": "rule:cloud_reader or
      (role:reader and domain_id:%(target.project.domain_id)s) or
      ((role:reader or role:role_viewer) and project_id:%(target.project.id)s)"

    # Show service details.
    # GET  /v3/services/{service_id}
    # Intended scope(s): system
    #"identity:get_service": "role:reader and system_scope:all"
    "identity:get_service": "rule:cloud_reader or
      rule:service_or_admin"

    # List services.
    # GET  /v3/services
    # Intended scope(s): system
    #"identity:list_services": "role:reader and system_scope:all"
    "identity:list_services": "rule:cloud_reader or
      rule:service_or_admin"

    # Create service.
    # POST  /v3/services
    # Intended scope(s): system
    #"identity:create_service": "role:admin and system_scope:all"
    "identity:create_service": "rule:cloud_admin"

    # Update service.
    # PATCH  /v3/services/{service_id}
    # Intended scope(s): system
    #"identity:update_service": "role:admin and system_scope:all"
    "identity:update_service": "rule:cloud_admin"

    # Delete service.
    # DELETE  /v3/services/{service_id}
    # Intended scope(s): system
    #"identity:delete_service": "role:admin and system_scope:all"
    "identity:delete_service": "rule:cloud_admin"

    # Create federated service provider.
    # PUT  /v3/OS-FEDERATION/service_providers/{service_provider_id}
    # Intended scope(s): system
    #"identity:create_service_provider": "role:admin and system_scope:all"
    "identity:create_service_provider": "rule:cloud_admin"

    # List federated service providers.
    # GET  /v3/OS-FEDERATION/service_providers
    # HEAD  /v3/OS-FEDERATION/service_providers
    # Intended scope(s): system
    #"identity:list_service_providers": "role:reader and system_scope:all"
    "identity:list_service_providers": "rule:cloud_reader"

    # Get federated service provider.
    # GET  /v3/OS-FEDERATION/service_providers/{service_provider_id}
    # HEAD  /v3/OS-FEDERATION/service_providers/{service_provider_id}
    # Intended scope(s): system
    #"identity:get_service_provider": "role:reader and system_scope:all"
    "identity:get_service_provider": "rule:cloud_reader"

    # Update federated service provider.
    # PATCH  /v3/OS-FEDERATION/service_providers/{service_provider_id}
    # Intended scope(s): system
    #"identity:update_service_provider": "role:admin and system_scope:all"
    "identity:update_service_provider": "rule:cloud_admin"

    # Delete federated service provider.
    # DELETE  /v3/OS-FEDERATION/service_providers/{service_provider_id}
    # Intended scope(s): system
    #"identity:delete_service_provider": "role:admin and system_scope:all"
    "identity:delete_service_provider": "rule:cloud_admin"

    # List revoked PKI tokens.
    # GET  /v3/auth/tokens/OS-PKI/revoked
    # Intended scope(s): system, project
    #"identity:revocation_list": "rule:service_or_admin"

    # Check a token.
    # HEAD  /v3/auth/tokens
    # Intended scope(s): system, domain, project
    #"identity:check_token": "(role:reader and system_scope:all) or rule:token_subject"
    "identity:check_token": "rule:cloud_reader or rule:token_subject"

    # Validate a token.
    # GET  /v3/auth/tokens
    # Intended scope(s): system, domain, project
    #"identity:validate_token": "(role:reader and system_scope:all) or rule:service_role or rule:token_subject"
    "identity:validate_token": "rule:cloud_reader or rule:service_role or rule:token_subject"

    # Revoke a token.
    # DELETE  /v3/auth/tokens
    # Intended scope(s): system, domain, project
    #"identity:revoke_token": "(role:admin and system_scope:all) or rule:token_subject"
    "identity:revoke_token": "rule:cloud_admin or rule:token_subject"

    # Create trust.
    # POST  /v3/OS-TRUST/trusts
    # Intended scope(s): project
    #"identity:create_trust": "user_id:%(trust.trustor_user_id)s"

    # List trusts.
    # GET  /v3/OS-TRUST/trusts
    # HEAD  /v3/OS-TRUST/trusts
    # Intended scope(s): system
    #"identity:list_trusts": "role:reader and system_scope:all"
    "identity:list_trusts": "rule:cloud_reader"

    # List trusts for trustor.
    # GET  /v3/OS-TRUST/trusts?trustor_user_id={trustor_user_id}
    # HEAD  /v3/OS-TRUST/trusts?trustor_user_id={trustor_user_id}
    # Intended scope(s): system, project
    #"identity:list_trusts_for_trustor": "role:reader and system_scope:all or user_id:%(target.trust.trustor_user_id)s"
    "identity:list_trusts_for_trustor": "rule:cloud_reader or user_id:%(target.trust.trustor_user_id)s"

    # List trusts for trustee.
    # GET  /v3/OS-TRUST/trusts?trustee_user_id={trustee_user_id}
    # HEAD  /v3/OS-TRUST/trusts?trustee_user_id={trustee_user_id}
    # Intended scope(s): system, project
    #"identity:list_trusts_for_trustee": "role:reader and system_scope:all or user_id:%(target.trust.trustee_user_id)s"
    "identity:list_trusts_for_trustee": "rule:cloud_reader or user_id:%(target.trust.trustee_user_id)s"

    # List roles delegated by a trust.
    # GET  /v3/OS-TRUST/trusts/{trust_id}/roles
    # HEAD  /v3/OS-TRUST/trusts/{trust_id}/roles
    # Intended scope(s): system, project
    #"identity:list_roles_for_trust": "role:reader and system_scope:all or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"
    "identity:list_roles_for_trust": "rule:cloud_reader or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"

    # Check if trust delegates a particular role.
    # GET  /v3/OS-TRUST/trusts/{trust_id}/roles/{role_id}
    # HEAD  /v3/OS-TRUST/trusts/{trust_id}/roles/{role_id}
    # Intended scope(s): system, project
    #"identity:get_role_for_trust": "role:reader and system_scope:all or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"
    "identity:get_role_for_trust": "rule:cloud_reader or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"

    # Revoke trust.
    # DELETE  /v3/OS-TRUST/trusts/{trust_id}
    # Intended scope(s): system, project
    #"identity:delete_trust": "role:admin and system_scope:all or user_id:%(target.trust.trustor_user_id)s"
    "identity:delete_trust": "rule:cloud_admin or user_id:%(target.trust.trustor_user_id)s"

    # Get trust.
    # GET  /v3/OS-TRUST/trusts/{trust_id}
    # HEAD  /v3/OS-TRUST/trusts/{trust_id}
    # Intended scope(s): system, project
    #"identity:get_trust": "role:reader and system_scope:all or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"
    "identity:get_trust": "rule:cloud_reader or user_id:%(target.trust.trustor_user_id)s or user_id:%(target.trust.trustee_user_id)s"

    # Show user details.
    # GET  /v3/users/{user_id}
    # HEAD  /v3/users/{user_id}
    # Intended scope(s): system, domain, project
    #"identity:get_user": "(role:reader and system_scope:all) or (role:reader and token.domain.id:%(target.user.domain_id)s) or user_id:%(target.user.id)s"
    "identity:get_user": "rule:cloud_reader or
      (role:reader and token.domain.id:%(target.user.domain_id)s) or
      user_id:%(target.user.id)s or
      role:role_viewer"

    # List users.
    # GET  /v3/users
    # HEAD  /v3/users
    # Intended scope(s): system, domain
    #"identity:list_users": "(role:reader and system_scope:all) or (role:reader and domain_id:%(target.domain_id)s)"
    "identity:list_users": "rule:cloud_reader or
      (role:reader and domain_id:%(target.domain_id)s)"

    # List all projects a user has access to via role assignments.
    # GET   /v3/auth/projects
    #"identity:list_projects_for_user": ""

    # List all domains a user has access to via role assignments.
    # GET  /v3/auth/domains
    #"identity:list_domains_for_user": ""

    # Create a user.
    # POST  /v3/users
    # Intended scope(s): system, domain
    #"identity:create_user": "(role:admin and system_scope:all) or (role:admin and token.domain.id:%(target.user.domain_id)s)"
    "identity:create_user": "rule:cloud_admin or (role:admin and token.domain.id:%(target.user.domain_id)s)"

    # Update a user, including administrative password resets.
    # PATCH  /v3/users/{user_id}
    # Intended scope(s): system, domain
    #"identity:update_user": "(role:admin and system_scope:all) or (role:admin and token.domain.id:%(target.user.domain_id)s)"
    "identity:update_user": "rule:cloud_admin or (role:admin and token.domain.id:%(target.user.domain_id)s)"

    # Delete a user.
    # DELETE  /v3/users/{user_id}
    # Intended scope(s): system, domain
    #"identity:delete_user": "(role:admin and system_scope:all) or (role:admin and token.domain.id:%(target.user.domain_id)s)"
    "identity:delete_user": "rule:cloud_admin"

  sso_callback_template.html: |
    # Copyright 2017 The Openstack-Helm Authors.
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    <!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml">
      <head>
        <title>Keystone WebSSO redirect</title>
      </head>
      <body>
         <form id="sso" name="sso" action="$host" method="post">
           Please wait...
           <br/>
           <input type="hidden" name="token" id="token" value="$token"/>
           <noscript>
             <input type="submit" name="submit_no_javascript" id="submit_no_javascript"
                value="If your JavaScript is disabled, please click to continue"/>
           </noscript>
         </form>
         <script type="text/javascript">
           window.onload = function() {
             document.forms['sso'].submit();
           }
         </script>
      </body>
    </html>

  wsgi-keystone.conf: |
    # Copyright 2017 The Openstack-Helm Authors.
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

    Listen 0.0.0.0:5000

    ErrorLog /dev/stdout

    LogFormat "%{%Y-%m-%d %T}t.%{msec_frac}t %{pid}P INFO apache \"%{X-Openstack-Request-ID}i\" %h %l %u \"%r\" %>s %b %{ms}T \"%{Referer}i\" \"%{User-Agent}i\"" combined
    LogFormat "%{%Y-%m-%d %T}t.%{msec_frac}t %{pid}P INFO apache \"%{X-Openstack-Request-ID}i\" %{X-Forwarded-For}i %l %u \"%r\" %>s %b %{ms}T \"%{Referer}i\" \"%{User-Agent}i\"" proxy

    SetEnvIf X-Forwarded-For "^.*\..*\..*\..*" forwarded
    CustomLog /dev/stdout combined env=!forwarded
    CustomLog /dev/stdout proxy env=forwarded

    <VirtualHost *:5000>
        ServerName identity-3.qa-de-1.cloud.sap
        WSGIDaemonProcess keystone-public processes=8 threads=1 user=keystone group=keystone display-name=%{GROUP}
        WSGIProcessGroup keystone-public
        WSGIScriptAlias / /var/www/cgi-bin/keystone/keystone-wsgi-public
        WSGIApplicationGroup %{GLOBAL}
        WSGIPassAuthorization On
        LimitRequestBody 114688
        <IfVersion >= 2.4>
          ErrorLogFormat "%{cu}t %M"
        </IfVersion>
        ErrorLog /dev/stdout

        SetEnvIf X-Forwarded-For "^.*\..*\..*\..*" forwarded
        CustomLog /dev/stdout combined env=!forwarded
        CustomLog /dev/stdout proxy env=forwarded

        KeepAliveTimeout 61
    </VirtualHost>

    Alias /identity /var/www/cgi-bin/keystone/keystone-wsgi-public
    <Location /identity>
        SetHandler wsgi-script
        Options +ExecCGI

        WSGIProcessGroup keystone-public
        WSGIApplicationGroup %{GLOBAL}
        WSGIPassAuthorization On
    </Location>

  watcher.yaml: |
    path_keywords:
      - application_credentials
      - credentials
      - domains
      - ec2tokens
      - endpoints
      - groups
      - implies
      - inherited_to_projects
      - limits
      - policies
      - projects
      - regions
      - registered_limits
      - role_assignments
      - role_inferences
      - roles
      - s3tokens
      - services
      - tags
      - tokens
      - users

    # never replace these
    keyword_exclusions:
      - config
      - OS-PKI
      - model


    regex_path_mapping:
      - '\S+/domains/config/[0-9a-zA-Z_]+/default$': 'domains/config/group/default'
      - '\S+/domains/config/[0-9a-zA-Z_]+/[0-9a-zA-Z_]+/default$': 'domains/config/group/option/default'
      - '\S+/domains/\S+/config/[0-9a-zA-Z_]+/[0-9a-zA-Z_]+$': 'domains/domain/config/group/option'
      - '\S+/domains/\S+/config/[0-9a-zA-Z_]+$': 'domains/domain/config/group'

    custom_actions:
      auth:
        - tokens:
            - OS-PKI:
                - revoked:
                    - method: GET
                      action_type: read/list

  statsd-exporter.yaml: |
    defaults:
      timer_type: histogram
      buckets: [.025, .1, .25, 1, 2.5]
      match_type: glob
      glob_disable_ordering: false
      ttl: 0 # metrics do not expire
  access_rules.json: |
    {
    }
---
# Source: keystone/charts/mariadb-galera/templates/storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: keystone-cinder
parameters:
  type: vmware
provisioner: cinder.csi.openstack.org
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
---
# Source: keystone/charts/mariadb-galera/templates/storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: keystone-nfs
parameters:
  pathPattern: "${.PVC.namespace}-${.PVC.name}"
  onDelete: delete
  archiveOnDelete: "true"
provisioner: cluster.local/nfs-subdir-external-provisioner
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
---
# Source: keystone/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: keystone-runtime
rules:
- apiGroups:
  - openstack.stable.sap.cc
  resources:
  - openstackseeds
  verbs:
  - "*"
- apiGroups:
  - "*"
  resources:
  - services
  - endpoints
  - configmaps
  - secrets
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  - extensions
  resources:
  - jobs
  - cronjobs
  verbs:
  - get
  - list
  - watch
---
# Source: keystone/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: keystone
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: keystone-runtime
subjects:
  - kind: ServiceAccount
    name: keystone
    namespace: monsoon3
---
# Source: keystone/charts/mariadb-galera/templates/roles.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: monsoon3
  name: keystone-configmap-updater
rules:
- apiGroups: [""]
  # at the HTTP level, the name of the resource for accessing ConfigMap objects is "configmaps"
  resources: ["configmaps"]
  resourceNames: ["keystone-galerastatus"]
  verbs: ["patch"]
---
# Source: keystone/charts/mariadb-galera/templates/rolebindings.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: keystone-configmap-updater
  namespace: monsoon3
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: keystone-configmap-updater
subjects:
  - kind: ServiceAccount
    name: keystone
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-0
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    statefulset.kubernetes.io/pod-name: keystone-mariadb-g-0
  ports:
    - name: galera
      port: 4567
      targetPort: 4567
      protocol: TCP
    - name: ist
      port: 4568
      targetPort: 4568
      protocol: TCP
    - name: sst
      port: 4444
      targetPort: 4444
      protocol: TCP
  sessionAffinity: "None"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-1
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    statefulset.kubernetes.io/pod-name: keystone-mariadb-g-1
  ports:
    - name: galera
      port: 4567
      targetPort: 4567
      protocol: TCP
    - name: ist
      port: 4568
      targetPort: 4568
      protocol: TCP
    - name: sst
      port: 4444
      targetPort: 4444
      protocol: TCP
  sessionAffinity: "None"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-2
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    statefulset.kubernetes.io/pod-name: keystone-mariadb-g-2
  ports:
    - name: galera
      port: 4567
      targetPort: 4567
      protocol: TCP
    - name: ist
      port: 4568
      targetPort: 4568
      protocol: TCP
    - name: sst
      port: 4444
      targetPort: 4444
      protocol: TCP
  sessionAffinity: "None"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-backend
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    component: "database"
  ports:
    - name: galera
      port: 4567
      targetPort: 4567
      protocol: TCP
    - name: ist
      port: 4568
      targetPort: 4568
      protocol: TCP
    - name: sst
      port: 4444
      targetPort: 4444
      protocol: TCP
  sessionAffinity: "None"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-frontend
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  selector:
    component: "database"
  ports:
    - name: mysql
      port: 3306
      targetPort: 3306
      protocol: TCP
  sessionAffinity: "ClientIP"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 28800
---
# Source: keystone/charts/mariadb-galera/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-frontend-direct
  annotations:
  labels:
    app: keystone
spec:
  type: ClusterIP
  selector:
    component: "database"
  ports:
    - name: mysql
      port: 3306
      targetPort: 3306
      protocol: TCP
  sessionAffinity: "ClientIP"
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 28800
---
# Source: keystone/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: keystone-memcached
  labels:
    app: keystone-memcached
    chart: "memcached-0.1.2"
    release: "keystone"
    heritage: "Helm"
    component: memcached
spec:
  ports:
  - name: memcache
    port: 11211
    targetPort: memcache
  selector:
    app: keystone-memcached
---
# Source: keystone/templates/service-api.yaml
apiVersion: v1
kind: Service
metadata:
  name: keystone
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    system: openstack
    component: keystone
    type: api
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9102"
    prometheus.io/targets: "openstack"
spec:
  selector:
    name: keystone-api
  type: ClusterIP
  ports:
    - name: public
      protocol: "TCP"
      port: 5000
      targetPort: 5000
---
# Source: keystone/templates/daemonset-keep-image-pulled.yaml
# Because Keppel depends on Keystone and the other way around the Docker images
# for Keystone should be pre-pulled to able to start in case keppel is down.
# This daemonset (through its existence) keeps required images permanently
# pulled on all nodes.

kind: DaemonSet
apiVersion: apps/v1

metadata:
  name: keystone-keep-image-pulled

spec:
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 5
  selector:
    matchLabels:
      app: keystone-keep-image-pulled
  template:
    metadata:
      labels:
        app: keystone-keep-image-pulled
        alert-tier: os
        alert-service: keystone
    spec:
      containers:
        - name: keystone
          image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
          imagePullPolicy: IfNotPresent
          command: [ '/bin/sleep', 'inf' ]
          resources:
            requests:
              cpu: "1m"
              memory: "20Mi"
            limits:
              cpu: "1m"
              memory: "20Mi"
        - name: check
          image: keppel.eu-de-1.cloud.sap/ccloud/kube-python:1.0.1
          imagePullPolicy: IfNotPresent
          command: [ '/bin/sleep', '9999999999d' ]
          resources:
            requests:
              cpu: "1m"
              memory: "20Mi"
            limits:
              cpu: "1m"
              memory: "20Mi"
      terminationGracePeriodSeconds: 1
---
# Source: keystone/charts/memcached/templates/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: keystone-memcached
  labels:
    app: keystone-memcached
    chart: "memcached-0.1.2"
    release: "keystone"
    heritage: "Helm"
spec:
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate

    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3

  selector:
    matchLabels:
      app: keystone-memcached
  template:
    metadata:
      labels:
        app: keystone-memcached
        component: memcached
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - preference:
              matchExpressions:
              - key: failure-domain.beta.kubernetes.io/zone
                operator: In
                values:
                - qa-de-1a
            weight: 1
          - weight: 1
            preference:
              matchExpressions:
              - key: cloud.sap/maintenance-state
                operator: In
                values:
                - operational
          - weight: 1
            preference:
              matchExpressions:
              - key: cloud.sap/deployment-state
                operator: NotIn
                values:
                - reinstalling
      containers:
      - name: memcached
        image: "keppel.eu-de-1.cloud.sap/ccloud-dockerhub-mirror/library/memcached:1.6.20-alpine"
        imagePullPolicy: "IfNotPresent"
        command:
        - memcached
        - -m 2048
        - -c 16384
        ports:
        - name: memcache
          containerPort: 11211
        livenessProbe:
          tcpSocket:
            port: memcache
          initialDelaySeconds: 30
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: memcache
          initialDelaySeconds: 5
          timeoutSeconds: 1
        resources:
          limits:
            cpu: "1000m"
            memory: "2560Mi"
          requests:
            cpu: "500m"
            memory: "2560Mi"
      priorityClassName: "openstack-service-critical"
---
# Source: keystone/templates/deployment-api.yaml
kind: Deployment
apiVersion: apps/v1

metadata:
  name: keystone-api
  labels:
    app: keystone-keystone
    chart: keystone-0.4.666
    release: keystone
    heritage: Helm
    system: openstack
    component: keystone
    type: api
spec:
  replicas: 4
  minReadySeconds: 5
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate

    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1

  selector:
    matchLabels:
      name: keystone-api
  template:
    metadata:
      labels:
        name: keystone-api
        system: openstack
        component: keystone
        type: api
        alert-tier: os
        alert-service: keystone
        app: keystone
      annotations:
        chart-version: 0.4.666
        configmap-etc-hash: fb8a092b2d4db01c94feb6a4bfc26a5c61f95fe2828bfcdebd4a9eb717888ad1
        configmap-bin-hash: 239336edfe82f03e07cfc66817b05b1cb58b4a7eb876e3141a1b3a60b348bdc1
    spec:
      serviceAccountName: keystone
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                      - keystone
                  - key: "component"
                    operator: In
                    values:
                      - keystone
              topologyKey: "topology.kubernetes.io/zone"
          - weight: 2
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: "app"
                    operator: In
                    values:
                      - keystone
                  - key: "component"
                    operator: In
                    values:
                      - keystone
              topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 30

      initContainers:
      - name: kubernetes-entrypoint
        #image: quay.io/stackanetes/kubernetes-entrypoint:v0.3.1
        image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
        imagePullPolicy: "IfNotPresent"
        command:
          - kubernetes-entrypoint
        env:
        - name: NAMESPACE
          value: monsoon3
        - name: DEPENDENCY_JOBS
          value: keystone-job-migration,keystone-job-bootstrap
        - name: DEPENDENCY_SERVICE
          value: "keystone-mariadb,keystone-memcached"
        - name: COMMAND
          value: "true"
      containers:
        - name: keystone-api
          image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
          imagePullPolicy: "IfNotPresent"
          command:
            - /scripts/keystone-api.sh
            - start
          env:
            - name: STATSD_HOST
              value: "127.0.0.1"
            - name: STATSD_PORT
              value: "9125"
            - name: STATSD_PREFIX
              value: "openstack"
            - name: PYTHONWARNINGS
              value: "ignore:Unverified HTTPS request"
          ports:
            - name: public
              containerPort: 5000
          lifecycle:
            preStop:
              exec:
                command:
                  - /scripts/keystone-api.sh
                  - stop
          readinessProbe:
            exec:
              command:
              - bash
              - -c
              - "set -e; curl --fail 127.0.0.1:5000/healthcheck; nc -zvw3 keystone-mariadb 3306"
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 20
          livenessProbe:
            httpGet:
              path: /healthcheck
              port: 5000
            initialDelaySeconds: 50
            periodSeconds: 20
            timeoutSeconds: 20
          volumeMounts:
            - name: etc-keystone
              mountPath: /etc/keystone
            - name: wsgi-keystone
              mountPath: /var/www/cgi-bin/keystone
            - name: keystone-etc
              mountPath: /etc/keystone/keystone.conf
              subPath: keystone.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/policy.yaml
              subPath: policy.yaml
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/sso_callback_template.html
              subPath: sso_callback_template.html
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/watcher.yaml
              subPath: watcher.yaml
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/apache2/conf-enabled/wsgi-keystone.conf
              subPath: wsgi-keystone.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/apache2/mods-available/mpm_event.conf
              subPath: mpm_event.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/access_rules.json
              subPath: access_rules.json
              readOnly: true
            - name: fernet
              mountPath: /fernet-keys
              readOnly: true
            - name: credential-keys
              mountPath: /credential-keys
              readOnly: true
            - name: keystone-bin
              mountPath: /scripts
              readOnly: true
          resources:
            limits:
              cpu: 2000m
              memory: 3Gi
            requests:
              cpu: 1500m
              memory: 2Gi
        - name: keystone-statsd
          image: "keppel.eu-de-1.cloud.sap/ccloud-dockerhub-mirror/prom/statsd-exporter:v0.20.1"
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/statsd_exporter
            - --statsd.mapping-config=/etc/statsd/statsd-exporter.yaml
          volumeMounts:
            - name: keystone-etc
              mountPath: /etc/statsd/statsd-exporter.yaml
              subPath: statsd-exporter.yaml
              readOnly: true
          ports:
            - name: statsd
              containerPort: 9125
              protocol: UDP
            - name: metrics
              containerPort: 9102
          resources:
            limits:
              cpu: 300m
              memory: 150Mi
            requests:
              cpu: 150m
              memory: 100Mi
      volumes:
        - name: etc-keystone
          emptyDir: {}
        - name: wsgi-keystone
          emptyDir: {}
        - name: keystone-etc
          configMap:
            name: keystone-etc
            defaultMode: 0444
        - name: keystone-bin
          configMap:
            name: keystone-bin
            defaultMode: 0555
        - name: fernet
          secret:
            secretName: keystone-fernet
            defaultMode: 0555
        - name: credential-keys
          secret:
            secretName: keystone-credential-keys
            defaultMode: 0555
---
# Source: keystone/templates/deployment-cron.yaml
kind: Deployment
apiVersion: apps/v1

metadata:
  name: keystone-cron
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    system: openstack
    component: keystone
    type: operations
spec:
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: Recreate
  selector:
    matchLabels:
      name: keystone-cron
  template:
    metadata:
      labels:
        name: keystone-cron
        system: openstack
        component: keystone
        type: operations
        alert-tier: os
        alert-service: keystone
      annotations:
        chart-version: 0.4.666
        configmap-etc-hash: fb8a092b2d4db01c94feb6a4bfc26a5c61f95fe2828bfcdebd4a9eb717888ad1
        configmap-bin-hash: 239336edfe82f03e07cfc66817b05b1cb58b4a7eb876e3141a1b3a60b348bdc1
    spec:
      serviceAccountName: keystone

      initContainers:
      - name: kubernetes-entrypoint
        #image: quay.io/stackanetes/kubernetes-entrypoint:v0.3.1
        image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
        imagePullPolicy: "IfNotPresent"
        command:
          - kubernetes-entrypoint
        env:
        - name: NAMESPACE
          value: monsoon3
        - name: DEPENDENCY_JOBS
          value: keystone-job-migration,keystone-job-bootstrap
        - name: DEPENDENCY_SERVICE
          value: "keystone-mariadb,keystone-memcached"
        - name: COMMAND
          value: "true"
      containers:
        - name: keystone-cron
          image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
          imagePullPolicy: "IfNotPresent"
          command:
            - bash
            - /scripts/cron
          env:
            - name: PYTHONWARNINGS
              value: "ignore:Unverified HTTPS request"
          volumeMounts:
            - name: keystone-etc
              mountPath: /etc/keystone/policy.yaml
              subPath: policy.yaml
              readOnly: true
            - mountPath: /etc/keystone/keystone.conf
              subPath: keystone.conf
              name: keystone-etc
            - mountPath: /etc/keystone/logging.conf
              subPath: logging.conf
              name: keystone-etc
            - mountPath: /scripts
              name: keystone-bin
            - name: fernet
              mountPath: /fernet-keys
              readOnly: true
            - name: credential-keys
              mountPath: /credential-keys
              readOnly: true
          resources:
            limits:
              cpu: 1000m
              memory: 3Gi
            requests:
              cpu: 500m
              memory: 2Gi
      volumes:
        - name: keystone-etc
          configMap:
            name: keystone-etc
        - name: keystone-bin
          configMap:
            name: keystone-bin
        - name: fernet
          secret:
            secretName: keystone-fernet
            defaultMode: 0755
        - name: credential-keys
          secret:
            secretName: keystone-credential-keys
            defaultMode: 0555
---
# Source: keystone/charts/mariadb-galera/templates/statefulset-mariadb.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g
  labels:
    app: keystone
    component: "database"
    release: keystone
spec:
  replicas: 3
  serviceName: keystone
  selector:
    matchLabels:
      component: "database"
  revisionHistoryLimit: 3
  podManagementPolicy: "Parallel"
  updateStrategy:
    type: "RollingUpdate"
  template:
    metadata:
      labels:
        app: keystone
        component: "database"
        release: keystone
      annotations:
        checksum/my.cnf: fd878d9d2701128edfc24ff7f1e6b29241d460cf39a86cfe3b1eebf6618023ff
        checksum/configmap: aa862a723e82714e94604315c1ab3e8786d1aff4386483799bc4bcb943954597
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: "app"
                      operator: In
                      values:
                        - "keystone"
                    - key: "component"
                      operator: In
                      values:
                        - "database"
                topologyKey: "topology.kubernetes.io/zone"
            - weight: 2
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: "app"
                      operator: In
                      values:
                        - "keystone"
                    - key: "component"
                      operator: In
                      values:
                        - "database"
                topologyKey: "kubernetes.io/hostname"
      serviceAccount: keystone
      automountServiceAccountToken: true
      securityContext:
        runAsUser:  101
        runAsGroup: 101
        fsGroup:  101
      initContainers:
      - name: sysctl-tcp-keepalive
        image: "keppel.eu-de-1.cloud.sap/ccloud/mariadb-galera-ubuntu:22.04-20231010194415"
        imagePullPolicy: "IfNotPresent"
        command:
        - sh
        - -c
        - 'sysctl -w net.ipv4.tcp_keepalive_time=60 net.ipv4.tcp_keepalive_intvl=60 net.ipv4.tcp_keepalive_probes=5'
        securityContext:
          privileged: true
          runAsUser: 0
      - name: increase-map-count
        image: "keppel.eu-de-1.cloud.sap/ccloud/mariadb-galera-ubuntu:22.04-20231010194415"
        imagePullPolicy: "IfNotPresent"
        command:
        - sh
        - -c
        - 'echo 262144 > /proc/sys/vm/max_map_count'
        securityContext:
          privileged: true
          runAsUser: 0
      containers:
      - name: db
        image: "keppel.eu-de-1.cloud.sap/ccloud/mariadb-galera:10.5.22-20231010194415"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser:  101
          runAsGroup: 101
          capabilities:
            add:
              - IPC_LOCK
        # disabled because not whitelisted
        # sysctls:
        # - name: net.ipv4.tcp_keepalive_time
        #   value: "60"
        # - name: net.ipv4.tcp_keepalive_intvl
        #   value: "60"
        # - name: net.ipv4.tcp_keepalive_probes
        #   value: "5"
        env:
        - name: MYSQL_PORT
          value: "3306"
        - name: GALERA_PORT
          value: "4567"
        - name: PC_WEIGHT_0
          value: "1"
        - name: PC_WEIGHT_1
          value: "1"
        - name: PC_WEIGHT_2
          value: "1"
        - name: PC_RECOVERY
          value: "false"
        - name: MARIADB_CLUSTER_NAME
          value: "keystone"
        - name: MARIADB_DATADIR
          value: "/opt/mariadb/data"
        - name: MARIADB_LOGDIR
          value: "/opt/mariadb/log"
        - name: MARIADB_MONITORING_CONNECTION_LIMIT
          value: "6"
        - name: MARIADB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: keystone-mariadb-root
              key: password
        - name: MARIADB_ROOT_USERNAME
          valueFrom:
            secretKeyRef:
              name: keystone-mariadb-root
              key: username
        resources:
          requests:
            cpu: 2
          limits:
            memory: "1024Mi"
        ports:
          - containerPort: 4567
            name: galera
            protocol: TCP
          - containerPort: 4568
            name: ist
            protocol: TCP
          - containerPort: 4444
            name: sst
            protocol: TCP
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - '/opt/mariadb/bin/startup.sh'
          initialDelaySeconds: 15
          periodSeconds: 10
          failureThreshold: 12
          timeoutSeconds: 20
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - '/opt/mariadb/bin/liveness.sh'
          initialDelaySeconds: 15
          periodSeconds: 30
          failureThreshold: 4
          timeoutSeconds: 20
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - '/opt/mariadb/bin/readiness.sh'
          initialDelaySeconds: 30
          periodSeconds: 20
          successThreshold: 1
          failureThreshold: 3
          timeoutSeconds: 10
        lifecycle:
          preStop:
            exec:
              command:
                - sh
                - -c
                - '/opt/mariadb/bin/pre-stop-hook.sh'
          postStart:
            exec:
              command:
                - sh
                - -c
                - '/opt/mariadb/bin/post-start-hook.sh'
        volumeMounts:
          - name: keystone-data-mariadb
            mountPath: /opt/mariadb/data
          - name: keystone-log-marialog
            mountPath: /opt/mariadb/log
          - name: keystone-mariadb-my-cnf
            mountPath: /opt/mariadb/etc/conf.d/tpl
            readOnly: true
          - name: keystone-galerastatus
            mountPath: /opt/mariadb/etc/galerastatus
            readOnly: false
          - name: keystone-mariadb-entrypoint-sh
            mountPath: /opt/mariadb/bin/entrypoint-galera.sh
            subPath: entrypoint-galera.sh
            readOnly: true
          - name: keystone-mariadb-probes-sh
            mountPath: /opt/mariadb/bin/startup.sh
            subPath: startup.sh
            readOnly: true
          - name: keystone-mariadb-probes-sh
            mountPath: /opt/mariadb/bin/liveness.sh
            subPath: liveness.sh
            readOnly: true
          - name: keystone-mariadb-probes-sh
            mountPath: /opt/mariadb/bin/readiness.sh
            subPath: readiness.sh
            readOnly: true
          - name: keystone-mariadb-hooks-sh
            mountPath: /opt/mariadb/bin/pre-stop-hook.sh
            subPath: pre-stop-hook.sh
            readOnly: true
          - name: keystone-mariadb-hooks-sh
            mountPath: /opt/mariadb/bin/post-start-hook.sh
            subPath: post-start-hook.sh
            readOnly: true
          - name: keystone-mariadb-common-functions-extended-sh
            mountPath: /opt/mariadb/bin/common-functions-extended.sh
            subPath: common-functions-extended.sh
            readOnly: true
      terminationGracePeriodSeconds: 600
      volumes:
        - name: keystone-mariadb-my-cnf
          configMap:
            name: keystone-mariadb-my-cnf
            defaultMode: 0444
        - name: keystone-galerastatus
          configMap:
            name: keystone-galerastatus
            defaultMode: 0750
        - name: keystone-mariadb-entrypoint-sh
          configMap:
            name: keystone-mariadb-entrypoint-sh
            defaultMode: 0755
        - name: keystone-mariadb-probes-sh
          configMap:
            name: keystone-mariadb-probes-sh
            defaultMode: 0755
        - name: keystone-mariadb-hooks-sh
          configMap:
            name: keystone-mariadb-hooks-sh
            defaultMode: 0755
        - name: keystone-mariadb-common-functions-extended-sh
          configMap:
            name: keystone-mariadb-common-functions-extended-sh
            defaultMode: 0755
        - name: keystone-monitoring-entrypoint-sh
          configMap:
            name: keystone-monitoring-entrypoint-sh
            defaultMode: 0755
        - name: keystone-monitoring-probes-sh
          configMap:
            name: keystone-monitoring-probes-sh
            defaultMode: 0755
        - name: keystone-monitoring-common-functions-extended-sh
          configMap:
            name: keystone-monitoring-common-functions-extended-sh
            defaultMode: 0755
  volumeClaimTemplates:
  - metadata:
      name: keystone-data-mariadb
    spec:
      accessModes: [ReadWriteOnce]
      resources:
        requests:
          storage: 10Gi
  - metadata:
      name: keystone-log-marialog
    spec:
      accessModes: [ReadWriteOnce]
      resources:
        requests:
          storage: 30Gi
---
# Source: keystone/charts/mariadb-galera/templates/job-mariadb-config.yaml
apiVersion: batch/v1
kind: Job
metadata:
  namespace: monsoon3
  name: keystone-mariadb-g-cfg-icpczwxa
  labels:
    app: keystone
    release: keystone
spec:
  backoffLimit: 12
  activeDeadlineSeconds: 600
  ttlSecondsAfterFinished: 7200
  template:
    metadata:
      labels:
        app: keystone
        release: keystone
      annotations:
        checksum/configmap: 314b5da481c7bf4045a39c1febef8c565f9c16f89a26cd1c7384a745c07e8382
    spec:
      restartPolicy: "OnFailure"
      serviceAccount: keystone
      securityContext:
        fsGroup:  101
      containers:
      - name: cfg
        image: "keppel.eu-de-1.cloud.sap/ccloud/mariadb-galera:10.5.22-20231010194415"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser:  101
          runAsGroup: 101
        command:
          - "sh"
          - "-c"
          - "/opt/mariadb/bin/entrypoint-job-config.sh"
        env:
        - name: MYSQL_PORT
          value: "3306"
        - name: MARIADB_MONITORING_CONNECTION_LIMIT
          value: "6"
        - name: MARIADB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: keystone-mariadb-root
              key: password
        - name: MARIADB_ROOT_USERNAME
          valueFrom:
            secretKeyRef:
              name: keystone-mariadb-root
              key: username
        resources:
          requests:
            cpu: 0.5
          limits:
            memory: "48Mi"
        volumeMounts:
        - name: keystone-mariadb-config-job-entrypoint-sh
          mountPath: /opt/mariadb/bin/entrypoint-job-config.sh
          subPath: entrypoint-job-config.sh
          readOnly: true
        - name: keystone-mariadb-common-functions-extended-sh
          mountPath: /opt/mariadb/bin/common-functions-extended.sh
          subPath: common-functions-extended.sh
          readOnly: true
      volumes:
      - name: keystone-mariadb-config-job-entrypoint-sh
        configMap:
          name: keystone-mariadb-config-job-entrypoint-sh
          defaultMode: 0750
      - name: keystone-mariadb-common-functions-extended-sh
        configMap:
          name: keystone-mariadb-common-functions-extended-sh
          defaultMode: 0755
---
# Source: keystone/templates/job-bootstrap.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: keystone-job-bootstrap
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    system: openstack
    component: keystone
    type: job
    # hooks are not annotated as belonging to the Helm release, so we cannot rely on owner-info injection
    ccloud/support-group: identity
    ccloud/service: keystone
spec:
  template:
    metadata:
      labels:
        name: keystone-job-bootstrap
        system: openstack
        component: keystone
        type: job
      annotations:
        chart-version: 0.4.666
        configmap-bin-hash: 239336edfe82f03e07cfc66817b05b1cb58b4a7eb876e3141a1b3a60b348bdc1
        configmap-etc-hash: fb8a092b2d4db01c94feb6a4bfc26a5c61f95fe2828bfcdebd4a9eb717888ad1
        # only run once on initial install
        "helm.sh/hook": post-install
    spec:
      serviceAccountName: keystone
      restartPolicy: OnFailure
      containers:
        - name: keystone-bootstrap
          image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
          imagePullPolicy: "IfNotPresent"
          command:
            - kubernetes-entrypoint
          env:
            - name: COMMAND
              value: "bash /scripts/bootstrap"
            - name: NAMESPACE
              value: monsoon3
            - name: DEPENDENCY_SERVICE
              value: "keystone-mariadb"
            - name: DEPENDENCY_JOBS
              value: keystone-job-migration
          volumeMounts:
            - name: etc-keystone
              mountPath: /etc/keystone
            - name: keystone-etc
              mountPath: /etc/keystone/keystone.conf
              subPath: keystone.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/policy.yaml
              subPath: policy.yaml
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: fernet
              mountPath: /fernet-keys
              readOnly: true
            - name: credential-keys
              mountPath: /credential-keys
              readOnly: true
            - name: keystone-bin
              mountPath: /scripts
              readOnly: true
      volumes:
        - name: etc-keystone
          emptyDir: {}
        - name: keystone-etc
          configMap:
            name: keystone-etc
            defaultMode: 0444
        - name: keystone-bin
          configMap:
            name: keystone-bin
            defaultMode: 0555
        - name: fernet
          secret:
            secretName: keystone-fernet
            defaultMode: 0555
        - name: credential-keys
          secret:
            secretName: keystone-credential-keys
            defaultMode: 0555
---
# Source: keystone/templates/job-migration.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: keystone-job-migration
  labels:
    app: keystone-keystone
    chart: "keystone-0.4.666"
    release: "keystone"
    heritage: "Helm"
    system: openstack
    component: keystone
    type: job
    # hooks are not annotated as belonging to the Helm release, so we cannot rely on owner-info injection
    ccloud/support-group: identity
    ccloud/service: keystone
spec:
  template:
    metadata:
      labels:
        name: keystone-job-migration
        system: openstack
        component: keystone
        type: job
        alert-tier: os
        alert-service: keystone
      annotations:
        chart-version: 0.4.666
        configmap-bin-hash: 239336edfe82f03e07cfc66817b05b1cb58b4a7eb876e3141a1b3a60b348bdc1
        configmap-etc-hash: fb8a092b2d4db01c94feb6a4bfc26a5c61f95fe2828bfcdebd4a9eb717888ad1
        # only run once
        "helm.sh/hook": post-install, post-upgrade
    spec:
      serviceAccountName: keystone
      restartPolicy: OnFailure
      containers:
        - name: keystone-migration
          image: keppel.eu-de-1.cloud.sap/ccloud/loci-keystone:xena-20230915074356
          imagePullPolicy: "IfNotPresent"
          command:
            - kubernetes-entrypoint
          env:
            - name: COMMAND
              value: "bash /scripts/db-sync"
            - name: NAMESPACE
              value: monsoon3
            - name: DEPENDENCY_SERVICE
              value: "keystone-mariadb"
          volumeMounts:
            - name: etc-keystone
              mountPath: /etc/keystone
            - name: keystone-etc
              mountPath: /etc/keystone/keystone.conf
              subPath: keystone.conf
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/policy.yaml
              subPath: policy.yaml
              readOnly: true
            - name: keystone-etc
              mountPath: /etc/keystone/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: fernet
              mountPath: /fernet-keys
              readOnly: true
            - name: keystone-bin
              mountPath: /scripts
              readOnly: true
            - name: credential-keys
              mountPath: /credential-keys
              readOnly: true
      volumes:
        - name: etc-keystone
          emptyDir: {}
        - name: keystone-etc
          configMap:
            name: keystone-etc
            defaultMode: 0444
        - name: keystone-bin
          configMap:
            name: keystone-bin
            defaultMode: 0555
        - name: fernet
          secret:
            secretName: keystone-fernet
            defaultMode: 0555
        - name: credential-keys
          secret:
            secretName: keystone-credential-keys
            defaultMode: 0555
---
# Source: keystone/templates/ingress-api.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: keystone
  labels:
    chart: "keystone-0.4.666"
    release: "keystone"
    component: keystone
    type: api
  annotations:
    # clear the trusted key header from external requests
    ingress.kubernetes.io/configuration-snippet: |
      proxy_set_header X-Trusted-Key        "";
    ingress.kubernetes.io/auth-tls-secret: monsoon3/keystone-x509-ca
    ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: "true"
    ingress.kubernetes.io/auth-tls-verify-client: "optional"
    ingress.kubernetes.io/auth-tls-verify-depth: "3"
spec:
  tls:

  rules:
    - host: identity-3.qa-de-1.cloud.sap
      http:
        paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: "keystone"
              port:
                number: 5000
---
# Source: keystone/charts/mariadb-galera/templates/secrets.yaml
apiVersion: v1
type:
kind: List
metadata:
  name: keystone-secrets
  namespace: monsoon3
items:
- apiVersion: v1
  kind: Secret
  type: Opaque
  metadata:
    namespace: monsoon3
    name: keystone-mariadb-root
  data:
    password: ZHVtbXlwYXNzLURC

