curator:
  configMaps:
    config_yml: |-
      ---
      client:
        hosts:
          - elasticsearch-master
          - elasticsearch-data
        port: 9200
    # Delete indices older than 3 months
    action_file_yml: |-
      ---
      actions:
        1:
          action: delete_indices
          description: "Clean up ES by deleting old indices"
          options:
            timeout_override:
            continue_if_exception: False
            disable_action: False
            ignore_empty_list: True
          filters:
          - filtertype: age
            source: name
            direction: older
            timestring: '%Y.%m.%d'
            unit: months
            unit_count: 3
            field:
            stats_result:
            epoch:
            exclude: False

# master node configs
elasticsearch:
  enabled: true
  image: "docker.elastic.co/elasticsearch/elasticsearch"

  roles:
    master: "true"
    ingest: "false"
    data: "false"
    
  esJavaOpts: "-Xmx4G -Xms4G"
  esConfig:
    elasticsearch.yml: |
      indices.query.bool.max_clause_count: 8192
      search.max_buckets: 100000

  volumeClaimTemplate:
    accessModes: [ "ReadWriteMany" ]
    resources:
      requests:
        storage: 100G

  resources:
    requests:
      memory: "4G"
    limits:
      memory: "6G"

elasticsearch-data:
  nodeGroup: data
  masterService: elasticsearch-master
  roles:
    master: "false"
    ingest: "true"
    data: "true"
  replicas: 2
  esJavaOpts: "-Xmx4G -Xms4G"
  esConfig:
    elasticsearch.yml: |
      indices.query.bool.max_clause_count: 8192
      search.max_buckets: 100000
  volumeClaimTemplate:
    accessModes: [ "ReadWriteMany" ]
    resources:
      requests:
        storage: 100G
  resources:
    requests:
      memory: "4G"
    limits:
      memory: "6G"

elasticsearchExporter:
  name: elastiflow
  enabled: true
  image: 
    repo: justwatch/elasticsearch_exporter
    tag: 1.1.0
  es:
    uri: http://elasticsearch-master:9200
  listen_port: 9102
  targets: prometheus-openstack
  
logstash:
  image: "robcowart/elastiflow-logstash-oss"
  imageTag: "4.0.0-beta"
  logstashJavaOpts: "-Xmx4G -Xms4G"

  persistence:
    enabled: false

  resources:
    requests:
      cpu: 500m
      memory: 4G
    limits:
      cpu: 4000m
      memory: 6G

  extraEnvs:
    - name: ELASTIFLOW_ES_HOST
      value: "elasticsearch-master:9200"
  service:
    type: NodePort
    ports:
      - name: netflow-udp
        port: 2055
        targetPort: 2055
        nodePort: 30055
        protocol: UDP
      - name: sflow-udp
        port: 6343
        targetPort: 6343
        nodePort: 30343
        protocol: UDP
      - name: ipfix-udp
        port: 4739
        targetPort: 4739
        nodePort: 30739
        protocol: UDP
      - name: ipfix-tcp
        port: 4739
        targetPort: 4739
        nodePort: 30740
        protocol: TCP

  readinessProbe:
    # use ipfix-tcp port instead of http API to better check elastiflow specific status
    httpGet: null
    tcpSocket:
      port: 4739
    initialDelaySeconds: 300
    periodSeconds: 30
    failureThreshold: 20
    successThreshold: 1

  livenessProbe:
    httpGet: null
    tcpSocket:
      port: 4739
    initialDelaySeconds: 600
    periodSeconds: 20
    failureThreshold: 5
    successThreshold: 1

logstashExporter:
  name: elastiflow
  enabled: true
  image: 
    repo: bonniernews/logstash_exporter
    tag: v0.1.2
  ls:
    uri: http://elastiflow-logstash:9600
  listen_port: 9198
  targets: prometheus-openstack

kibana:
  image: "docker.elastic.co/kibana/kibana"
  elasticsearchHosts: "http://elasticsearch-master:9200"

# Deploy Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which the alerts should be assigned to.
  prometheus: openstack

queryExporter:
  name: elastiflow
  enabled: true
  image:
    repo: braedon/prometheus-es-exporter
    tag: 0.9.0
  es:
    uri: "http://elasticsearch-master:9200"
  listen_port: 9206
  targets: prometheus-openstack
  config:
    exporter.cfg: |
      [DEFAULT]
      QueryIntervalSecs = 15
      QueryTimeoutSecs = 10
      QueryIndices = _all
      QueryOnError = drop
      QueryOnMissing = drop

      [query_all]
      QueryJson = {"size": 0, "query": {"match_all": {}}}