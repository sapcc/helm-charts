# vim: set ft=yaml:

groups:
- name: openstack-limes.alerts
  rules:

  # This alert is used for detecting unusually high API load before it becomes
  # a problem. We don't care about the collector; it self-regulates by slowing
  # down when its connection pool is exhausted.
  - alert: OpenstackLimesDBConnectionPoolNearlyFull
    expr: avg_over_time(go_sql_stats_connections_in_use{db_name="limes",kubernetes_pod_name!~"limes-collect-.*"}[1h]) > 8
    for: 5m
    labels:
      context: dbconnpool
      dashboard: limes-overview
      service: limes
      severity: info
      tier: os
      meta: 'DB connection pool nearly full on {{ $labels.kubernetes_pod_name }}'
    annotations:
      summary: 'DB connection pool nearly full on {{ $labels.kubernetes_pod_name }}'
      description: |
        The DB connection pool on pod {{ $labels.kubernetes_pod_name }} is filling up. It can
        go up to 16 connections, but during regular operations we should not go
        over 3-5 connections to retain some budget for request spikes. Going
        high on connections for a long time indicates that the pod might be
        starved for CPU time, so try checking the CPU throttling metrics.

  - alert: OpenstackLimesHttpErrors
    expr: sum(increase(http_requests_total{kubernetes_namespace="limes",code=~"5.*"}[1h])) by (kubernetes_name) > 0
    for: 5m
    labels:
      context: api
      dashboard: limes-overview
      service: limes
      severity: info
      tier: os
    annotations:
      description: "{{ $labels.kubernetes_name }} is producing HTTP responses with 5xx status codes."
      summary: Server errors on {{ $labels.kubernetes_name }}

  - alert: OpenstackLimesNotScraping
    expr: absent(rate(limes_successful_scrapes[30m]) > 0)
    for: 5m
    labels:
      context: failedscrapes
      dashboard: limes-overview
      service: limes
      severity: warning
      tier: os
    annotations:
      description: There have been no successful scrapes in the last hour,
        so limes-collect-ccloud is probably dead.
      summary: Limes is not scraping

  - alert: OpenstackLimesFailedCapacityScrapes
    expr: sum(increase(limes_failed_capacity_scrapes[5m])) BY (capacitor) > 0
    for: 1h
    labels:
      context: failedcapacityscrapes
      dashboard: limes-overview
      service: limes
      severity: warning
      tier: os
    annotations:
      description: Limes cannot scrape capapcity from {{ title $labels.capacitor }}
        for more than an hour.
        The `kubectl logs` for limes-collect-ccloud contain additional info.
      summary: Limes cannot scrape capacity {{ title $labels.capacitor }}

  - alert: OpenstackLimesMissingCapacity
    # This ignores baremetal capacity ("compute/instances_<flavorname>")
    # since many of these are zero legitimately (we do not have all BM server
    # types in all regions).
    #
    # The check for non-zero domain quota skips resources that only report
    # usage, not quota nor capacity (at the moment, those are
    # "compute/{cores,ram}_{bigvm,regular}").
    expr: global:limes_consolidated_cluster_capacity{full_resource!~"compute/instances_.*"} == 0 and on (full_resource) global:limes_consolidated_domain_quota{full_resource!~"compute/instances_*"} > 0
    for: 1h
    labels:
      context: failedcapacityscrapes
      dashboard: limes-overview
      service: limes
      severity: info
      meta: 'no capacity for {{ $labels.full_resource }}'
      tier: os
    annotations:
      description: Limes reports no capacity for {{ $labels.full_resource }}.
        This usually means that the backend service reported weirdly-shaped data
        to Limes' capacity scanner.
        The `kubectl logs` for limes-collect-ccloud may contain additional info.
      summary: Limes reports zero capacity for {{ $labels.full_resource }}

  - alert: OpenstackLimesFailedScrapes
    expr: sum(increase(limes_failed_scrapes[5m])) BY (service, service_name, region) > 0
    for: 1h
    labels:
      context: failedscrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: info
      tier: os
      playbook: docs/support/playbook/limes/failed_scrapes.html
    annotations:
      description: Limes cannot scrape data from {{ title $labels.service_name }}
        for more than an hour. Please check if {{ title $labels.service_name }} is working.
        Error messages can be found in <https://dashboard.{{ $labels.region }}.cloud.sap/ccadmin/cloud_admin/cc-tools/limes#/scrape-errors|the Limes Errors view in Elektra>.
      summary: Limes cannot scrape {{ title $labels.service_name }}

  - alert: OpenstackLimesFailingScrapes
    expr: max(limes_failing_scrapes_gauge) BY (service_name, region) > 0
    for: 1h
    labels:
      context: failedscrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: warning
      tier: os
      playbook: docs/support/playbook/limes/failed_scrapes.html
    annotations:
      description: Limes cannot scrape data for projects from {{ title $labels.service_name }}
        for more than an hour. Please check if {{ title $labels.service_name }} is working.
        Error messages can be found in <https://dashboard.{{ $labels.region }}.cloud.sap/ccadmin/cloud_admin/cc-tools/limes#/scrape-errors|the Limes Errors view in Elektra>.
      summary: Limes cannot scrape {{ title $labels.service_name }}

  - alert: OpenstackLimesSuspendedScrapes
    # this has [15m] instead of [5m] because suspensions last for 10 minutes,
    # therefore the limes_suspended_scrapes counter only increments that often
    expr: sum(increase(limes_suspended_scrapes[15m])) BY (service, service_name) > 0
    for: 1h
    labels:
      context: failedscrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: warning
      tier: os
    annotations:
      description: Limes has suspended scraping from {{ title $labels.service_name }}
        for more than an hour. Please check if the internal endpoint for
        {{ title $labels.service_name }} is correctly entered in the Keystone catalog.
        The `kubectl logs` for limes-collect-ccloud contain additional info.
      summary: Limes cannot find {{ title $labels.service_name }} endpoint

  - alert: OpenstackLimesFailedRateScrapes
    expr: sum(increase(limes_failed_rate_scrapes[5m])) BY (service, service_name, region) > 0
    for: 1h
    labels:
      context: failedratescrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: info
      tier: os
      playbook: docs/support/playbook/limes/failed_scrapes.html
    annotations:
      description: Limes cannot scrape rate data from {{ title $labels.service_name }}
        for more than an hour. Please check if {{ title $labels.service_name }} is working.
        Error messages can be found in <https://dashboard.{{ $labels.region }}.cloud.sap/ccadmin/cloud_admin/cc-tools/limes#/rate-scrape-errors|the Limes Errors view in Elektra>.
      summary: Limes cannot scrape {{ title $labels.service_name }}

  - alert: OpenstackLimesFailingRateScrapes
    expr: max(limes_failing_rate_scrapes_gauge) BY (service_name, region) > 0
    for: 1h
    labels:
      context: failedscrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: warning
      tier: os
      playbook: docs/support/playbook/limes/failed_scrapes.html
    annotations:
      description: Limes cannot scrape rate data for projects from {{ title $labels.service_name }}
        for more than an hour. Please check if {{ title $labels.service_name }} is working.
        Error messages can be found in <https://dashboard.{{ $labels.region }}.cloud.sap/ccadmin/cloud_admin/cc-tools/limes#/scrape-errors|the Limes Errors view in Elektra>.
      summary: Limes cannot scrape {{ title $labels.service_name }}

  - alert: OpenstackLimesSuspendedRateScrapes
    # this has [15m] instead of [5m] because suspensions last for 10 minutes,
    # therefore the limes_suspended_rate_scrapes counter only increments that often
    expr: sum(increase(limes_suspended_rate_scrapes[15m])) BY (service, service_name) > 0
    for: 1h
    labels:
      context: failedratescrapes
      dashboard: limes-overview
      service: '{{ $labels.service_name }}'
      severity: warning
      tier: os
    annotations:
      description: Limes has suspended rate scraping from {{ title $labels.service_name }}
        for more than an hour. Please check if the internal endpoint for
        {{ title $labels.service_name }} is correctly entered in the Keystone catalog.
        The `kubectl logs` for limes-collect-ccloud contain additional info.
      summary: Limes cannot find {{ title $labels.service_name }} endpoint

  - alert: OpenstackLimesMissingSwiftMetrics
    expr: (limes_project_usage{service="object-store",resource="capacity"} > 0) unless on(project_id) (limes_plugin_metrics_ok{service="object-store"} == 1)
    for: 5m
    labels:
      context: swiftmetrics
      dashboard: limes-overview
      service: limes
      severity: warning
      tier: os
      meta: "project {{ $labels.project_id }}"
    annotations:
      description: The project {{ $labels.domain }}/{{ $labels.project }} (UUID {{ $labels.project_id }})
        has Swift containers, but Limes does not submit Swift usage metrics to Maia.
        Check the `kubectl logs` for limes-collect-ccloud for additional info.
      summary: Limes cannot submit Swift usage metrics

  - alert: OpenstackLimesFailedDomainDiscoveries
    expr: sum(increase(limes_failed_domain_discoveries[5m])) > 0
    for: 30m
    labels:
      context: faileddiscoveries
      dashboard: limes-overview
      service: limes
      severity: warning
      tier: os
    annotations:
      description: Limes cannot discover domains.
        Please check if "openstack domain list" is working.
      summary: Limes cannot discover domains.

  - alert: OpenstackLimesFailedProjectDiscoveries
    expr: sum(increase(limes_failed_project_discoveries[5m])) BY (domain) > 0
    for: 30m
    labels:
      context: faileddiscoveries
      dashboard: limes-overview
      service: limes
      severity: warning
      tier: os
    annotations:
      description: Limes cannot discover projects in domain {{ $labels.domain }}.
        Please check if "openstack project list --domain {{ $labels.domain }}" is working.
      summary: Limes cannot discover projects.

  - alert: OpenstackLimesAuditEventPublishFailing
    # Usually, you would check increase() here, but audit events *can* be quite
    # rare, so we alert if there are any failed audit events at all. To clear this alert,
    # delete the respective
    expr: max by (pod) (limes_failed_auditevent_publish > 0)
    for: 1h
    labels:
      context: auditeventpublish
      dashboard: limes-overview
      service: limes
      severity: info
      tier: os
      meta: '{{ $labels.pod }}'
    annotations:
      summary: "{{ $labels.pod }} cannot publish audit events"
      description: "Audit events from {{ $labels.pod }} could not be published to the RabbitMQ server. Check the pod log for details. Once the underlying issue was addressed, delete the offending pod to clear this alert."

  - alert: OpenstackLimesPodSchedulingFailedInsufficientCPU
    expr: sum(rate(kube_pod_failed_scheduling_cpu_total{pod_name=~"limes-.+"}[30m])) by (pod_name) > 0
    for: 15m
    labels:
      severity: warning
      tier: os
      service: limes
      context: cpu
      dashboard: limes-overview
      meta: "{{ $labels.pod_name }}"
      no_alert_on_absence: "true" # the underlying metric is only generated when scheduling fails
    annotations:
      summary: Scheduling failed due to insufficient cpu
      description: The pod {{ $labels.pod_name }} failed to be scheduled. Insuffient CPU!

  - alert: OpenstackLimesIncompleteProjectResourceData
    expr: max by (service, resource) (limes_project_resources_by_type_count) != on () group_left max(limes_project_count)
    # Do not trigger too fast! When a new resource is added, it takes one full scrape cycle to create all resource records.
    for: 60m
    labels:
      severity: info
      tier: os
      service: limes
      context: data-completeness
      meta: "Incomplete project resource data for {{$labels.service}}/{{$labels.resource}}"
    annotations:
      summary: Incomplete project resource data in Limes DB
      description: Some or all projects are missing an entry in the "project_resources" table for resource
        {{$labels.service}}/{{$labels.resource}}. Until this is resolved, PUT requests on the API may fail. Check the
        log for limes-collect; its consistency check should create any missing entries. If this alert only appears for
        baremetal flavor resources, try restarting all nova-api pods, then afterwards restart all limes-api and
        limes-collect pods.
