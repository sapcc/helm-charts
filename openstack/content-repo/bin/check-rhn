#!/bin/ash
# shellcheck shell=ash

RELEASE="$1"
if [ -z "${RELEASE}" ]; then
  echo "$0: missing release" >&2
  exit 1
fi
CHECK_URL="$2"
if [ -z "${CHECK_URL}" ]; then
  echo "$0: missing check url" >&2
  exit 1
fi

# extract just the domain from the URL
CHECK_DOMAIN="${CHECK_URL#https://}"
CHECK_DOMAIN="${CHECK_DOMAIN%%/*}"

ENTITLEMENT_PREFIX=rhel
# Check for release specific entitlements
if [ -r "/secret-check/${RELEASE}-entitlement.pem" ]; then
  ENTITLEMENT_PREFIX=${RELEASE}
fi

get_date() {
  date "+%Y/%m/%d %H:%M:%S"
}

echo "$(get_date) Starting RedHat CDN entitlement check for ${RELEASE}"
while true; do
  # This looks stupid, but we have seen problems in prod where `curl` times out
  # on the DNS resolution because cdn.redhat.com goes through a billion CNAMEs.
  # This step warms up the DNS cache to make it more likely that curl succeeds.
  nslookup "${CHECK_DOMAIN}" &>/dev/null

  SUCCESS=0
  ERR_FILE=$(mktemp)
  STATUS=$(curl --head --silent --show-error --write-out '%{http_code}' --output /dev/null \
    --cacert "/secret-check/${ENTITLEMENT_PREFIX}-ca.pem" \
    --cert "/secret-check/${ENTITLEMENT_PREFIX}-entitlement.pem" \
    --key "/secret-check/${ENTITLEMENT_PREFIX}-entitlement-key.pem" \
    "${CHECK_URL}" 2> "$ERR_FILE")
  EXIT_CODE=$?
  if [ $EXIT_CODE -ne 0 ]; then
    echo "$(get_date) RHN entitlement check failed: $(cat "$ERR_FILE")"
  elif [ "${STATUS}" -eq 200 ]; then
    SUCCESS=1
    echo "$(get_date) RHN entitlement check succeeded"
  elif [ "${STATUS}" -eq 403 ]; then
    echo "$(get_date) RHN entitlement check for ${RELEASE}: ${STATUS} - Forbidden. Entitlement might need to be renewed"
  else
    echo "$(get_date) RHN entitlement check for ${RELEASE}: ${STATUS}"
  fi

  rm -f "$ERR_FILE"

  echo "repo.${RELEASE}.check.success:${SUCCESS}|g" | nc -w 1 -u "${STATSD_HOSTNAME}" 9125
  echo "repo.${RELEASE}.check.httpcode:${STATUS}|g" | nc -w 1 -u "${STATSD_HOSTNAME}" 9125

  sleep "${CHECK_INTERVAL}"
done
