# Default values for designate.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value
#
debug: "True"

global_setup: false
tempest_enabled: false
nanny_enabled: false

sentry:
  enabled: true

global:
  db_region: ""
  dbUser: "designate"
  designate_api_endpoint_protocol_admin: http
  designate_api_endpoint_protocol_internal: http
  designate_api_endpoint_protocol_public: https
  designate_public_api: ""
  designate_api_port_internal: '9001'
  designate_api_port_admin: '9001'
  designate_api_port_public: '443'
  designate_metrics_port: '9102'
  designate_mdns_port_public: '5354'
  designate_mdns_service_ip:
  designate_mdns_akamai_ip:
  designate_service_user: designate
  domain_seeds:
    skip_hcm_domain: false
  linkerd_requested: false
  
pod:
  replicas:
    api: 3
    central: 3
    mdns: 2
    poolmanager: 1
    producer: 4
    worker: 3
    sink: 1
  lifecycle:
    upgrades:
      deployments:
        revision_history: 5
        pod_replacement_strategy: RollingUpdate
        rolling_update:
          max_unavailable: 0
          max_surge: 1

# image_version_designate:  DEFINED-IN-REGION-CHART
imageVersionTempest: "latest"

bind_pools:
  - name: default
    nameservers: []
    options: {}

rndc_keys:
- name: DEFINED-IN-REGION-CHART
  algorithm: DEFINED-IN-REGION-CHART
  secret: DEFINED-IN-REGION-CHART

db_name: designate
pool_id: 794ccc2c-d751-44fe-b57f-8894c9f5c842
scheduler_filters: attribute, pool_id_attribute, in_doubt_default_pool, fallback
sink_enabled: False

quota_api_export_size: 100000

worker_enabled: True
worker_notify: True
worker_poll_timeout: '20'
worker_poll_retry_interval: '15'
worker_poll_max_retries: '100'
worker_threshold_percentage: '100'
worker_all_tcp: True

percona_cluster:
  enabled: false
  db_name: designate
  db_user: designate
  alerts:
    support_group: network-api

proxysql:
  connect_retries_delay: 1000
  mode: null
  max_connections_per_proc: 15

mariadb:
  enabled: true
  name: designate
  initdb_secret: designate-initdb
  persistence_claim:
    name: db-designate-pvclaim
  alerts:
    support_group: network-api
  backup:
    enabled: false
  databases:
  - designate
  users:
    designate:
      name: designate
      grants:
      - "ALL PRIVILEGES on designate.*"
  backup_v2:
    verification:
      enabled: false
      run_after_inc_backups: 12
    enabled: true
    databases:
      - designate
    verify_tables:
      - designate.zones
      - designate.quotas
    oauth:
      client_id: "designate"

mysql_metrics:
  enabled: true
  db_name: designate
  db_user: designate
  customMetrics:
    - name: openstack_designate_zones
      help: "zones grouped by status and project"
      labels:
        - "zone_name"
        - "status"
        - "project_id"
      values:
        - "count_gauge"
      query:  |
              SELECT
                name AS zone_name,
                status,
                tenant_id AS project_id,
                COUNT(*) AS count_gauge
              FROM zones
              GROUP BY
                name,
                status,
                tenant_id

    - name: openstack_designate_zones_stuck_pending
      help: "zones that stuck in pending state at least for 10 mins"
      labels:
        - "zone_name"
        - "project_id"
      values:
        - "count_gauge"
      query:  |
              SELECT
                name AS zone_name,
                tenant_id AS project_id,
                updated_at,
                COUNT(*) AS count_gauge
              FROM zones
              WHERE status='PENDING' AND (updated_at < DATE_SUB(now(), INTERVAL 10 MINUTE))
              GROUP BY
                name,
                tenant_id,
                updated_at
              UNION SELECT 'none' AS zone_name, 'none' AS project_id, 'none' AS updated_at, 0 AS count_gauge;

    - name: openstack_designate_zones_stuck_max_duration
      help: "max duration for zones that stuck in non active state"
      labels:
        - "zone_name"
        - "project_id"
        - "status"
      values:
        - "max_duration_gauge"
      query:  |
              SELECT
                name AS zone_name,
                tenant_id AS project_id,
                status,
                MAX(NOW() - updated_at) AS max_duration_gauge
              FROM zones
              WHERE deleted=False AND status in ('DELETING','CREATING','PENDING') AND (updated_at < DATE_SUB(now(), INTERVAL 10 MINUTE))
              GROUP BY
                name,
                tenant_id,
                status
              UNION SELECT 'none' AS zone_name, 'none' AS project_id, 'none' AS status, 0 AS max_duration_gauge;

    - name: openstack_designate_records
      help: "records count grouped by status"
      labels:
        - "status"
        - "zone_id"
      values:
        - "count_gauge"
      query:  |
              SELECT
                zone_id,
                status,
                count(id) AS count_gauge
              FROM records
              GROUP BY
                zone_id,
                status

cors:
  enabled: false

logging:
  formatters:
    context:
      class: oslo_log.formatters.ContextFormatter
    default:
      format: "%(message)s"
  handlers:
    stdout:
      class: StreamHandler
      args: "(sys.stdout,)"
      formatter: context
    "null":
      class: logging.NullHandler
      args: "()"
      formatter: default
    sentry:
      class: raven.handlers.logging.SentryHandler
      level: ERROR
      args: "()"
  loggers:
    root:
      handlers: stdout, sentry
      level: WARNING
    designate:
      handlers: stdout, sentry
      level: DEBUG
    amqp:
      handlers: stdout, sentry
      level: WARNING
    amqplib:
      handlers: stdout, sentry
      level: WARNING
    boto:
      handlers: stdout, sentry
      level: WARNING
    eventlet.wsgi.server:
      handlers: stdout, sentry
      level: INFO
    sqlalchemy:
      handlers: stdout, sentry
      level: WARNING
    auditmiddleware:
      handlers: stdout, sentry
      level: INFO

audit:
  enabled: true
  # do by default not attach the request payloads of create/update calls to the event
  record_payloads: true
  metrics_enabled: true
  # how many messages to buffer before dumping to log (when rabbit is down or too slow)
  mem_queue_size: 1000
  central_service:
    user: rabbitmq
    password: null

memcached:
  alerts:
    support_group: network-api

rabbitmq:
  enabled: true
  use_alternate_registry: true
  ports:
    public: 5672
    management: 15672
  name: designate
  users:
    default:
      user: openstack
      password: welcome
    admin:
      user: admin
      password: secret
  alerts:
    support_group: network-api
  metrics:
    enabled: true
    sidecar:
      enabled: false 
    enableDetailedMetrics: true
    enablePerObjectMetrics: true

rabbitmq_cluster:
  enabled: false
  use_alternate_registry: true
  name: designate
  users:
    default:
      user: openstack

rabbitmq_notifications:
  use_alternate_registry: true
  name: designate
  users:
    default:
      user: rabbitmq
      password: DEFINED-IN-SECRETS
    admin:
      user: admin
      password: DEFINED-IN-SECRETS

resources:
  api:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "2048Mi"
      cpu: "2000m"
  central:
    requests:
      cpu: "250m"
      memory: "256Mi"
    limits:
      cpu: "5000m"
      memory: "8192Mi"
  mdns:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "4096Mi"
      cpu: "5000m"
  worker:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "2048Mi"
      cpu: "2000m"

# openstack-watcher-middleware
watcher:
  enabled: true

rbac:
  enabled: true

metrics:
  prometheus: openstack

# Deploy Designate Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which the alerts should be assigned to.
  # Keys = directory names in alerts/ and aggregations/
  prometheus:
    openstack: openstack
    kubernetes: kubernetes
  support_group: network-api

osprofiler:
  enabled: false

coordinationBackend: "file"

owner-info:
  support-group: network-api
  service: designate
  maintainers:
    - David Hoeller
    - Benjamin Tinney
  helm-chart-url: https://github.com/sapcc/helm-charts/tree/master/openstack/designate

utils:
  trust_bundle:
    enabled: true
    
vpa:
  # https://github.com/sapcc/vpa_butler
  # The maximum available capacity is split evenly across containers specified in the Deployment, StatefulSet or DaemonSet to derive the upper recommendation bound. This does not work out for pods with a single resource-hungry container with several sidecar containers
  # Annotate the Deployment, StatefulSet or DaemonSet with vpa-butler.cloud.sap/main-container=$MAIN_CONTAINER. That will distribute 75% of the maximum available capacity to the main container and the rest evenly across all others
  set_main_container: true
