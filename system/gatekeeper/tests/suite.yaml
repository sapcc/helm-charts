kind: Suite
apiVersion: test.gatekeeper.sh/v1alpha1
metadata:
  name: gatekeeper-tests
tests:

################################################################################
# library tests

- name: libtest-add-support-labels
  template: rendered-chart/gatekeeper/templates/constrainttemplate-libtest-add-support-labels.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-libtest-add-support-labels.yaml
  cases:
  - name: support-labels-on-pod-filled
    object: fixtures/libtest-add-support-labels/pod-filled.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: test for from_k8s_object\(\)$'
  - name: support-labels-on-pod-missing
    object: fixtures/libtest-add-support-labels/pod-missing.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: test for from_k8s_object\(\)$'
  - name: support-labels-on-helm-release-filled
    object: fixtures/libtest-add-support-labels/helm-release-filled.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: test for from_helm_release\(\)$'
  - name: support-labels-on-helm-release-missing
    object: fixtures/libtest-add-support-labels/helm-release-missing.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: test for from_helm_release\(\)$'

- name: libtest-traversal
  template: rendered-chart/gatekeeper/templates/constrainttemplate-libtest-traversal.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-libtest-traversal.yaml
  cases:
  - name: traversal-for-cronjob
    object: fixtures/libtest-traversal/cronjob.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in cronjob" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-daemonset
    object: fixtures/libtest-traversal/daemonset.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in daemonset" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-deployment
    object: fixtures/libtest-traversal/deployment.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in deployment" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-job
    object: fixtures/libtest-traversal/job.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in job" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-job-in-cronjob
    object: fixtures/libtest-traversal/job-in-cronjob.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-pod
    object: fixtures/libtest-traversal/pod.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "individual pod" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-pod-minimal
    object: fixtures/libtest-traversal/pod-minimal.yaml # special case: tests empty `initContainers`
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "minimal pod" and containers "alpine"$'
  - name: traversal-for-pod-in-daemonset
    object: fixtures/libtest-traversal/pod-in-daemonset.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-pod-in-job
    object: fixtures/libtest-traversal/pod-in-job.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-pod-in-replicaset
    object: fixtures/libtest-traversal/pod-in-replicaset.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-pod-in-statefulset
    object: fixtures/libtest-traversal/pod-in-statefulset.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-pod-in-unknown-owner
    object: fixtures/libtest-traversal/pod-in-unknown-owner.yaml # special case: tests `ownerReferences` pointing to unexpected owner
    assertions:
    - violations: 1
      # because we do not know this owner, we have to report violations on this level
      message: '^found a relevant pod with marker "pod in unknown owner" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-replicaset
    object: fixtures/libtest-traversal/replicaset.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in replicaset" and containers "alpine", "init-busybox", "ubuntu"$'
  - name: traversal-for-replicaset-in-deployment
    object: fixtures/libtest-traversal/replicaset-in-deployment.yaml
    assertions:
    - violations: 1
      message: '^no relevant pod found$' # suppressed because of owner reference
  - name: traversal-for-statefulset
    object: fixtures/libtest-traversal/statefulset.yaml
    assertions:
    - violations: 1
      message: '^found a relevant pod with marker "pod in statefulset" and containers "alpine", "init-busybox", "ubuntu"$'

################################################################################
# policy tests

- name: deprecated-api-version-k8s1.16
  template: rendered-chart/gatekeeper/templates/constrainttemplate-deprecated-api-version.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-deprecated-api-version-k8s1.16.yaml
  cases:
  - name: helm-release-deprecated-api-version
    object: fixtures/deprecated-api-version/helm-release-deprecated-1.16.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: Deployment dummy declared with deprecated API version: extensions/v1beta1 \(will break in k8s v1.16\)$'
  - name: helm-release-clean
    object: fixtures/deprecated-api-version/helm-release-clean.out.yaml
    assertions:
    - violations: no

- name: deprecated-api-version-k8s1.22
  template: rendered-chart/gatekeeper/templates/constrainttemplate-deprecated-api-version.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-deprecated-api-version-k8s1.22.yaml
  cases:
  - name: helm-release-deprecated-api-version-1.22
    object: fixtures/deprecated-api-version/helm-release-deprecated-1.22.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: CustomResourceDefinition dummy declared with deprecated API version: apiextensions.k8s.io/v1beta1 \(will break in k8s v1.22\)$'
  - name: helm-release-clean
    object: fixtures/deprecated-api-version/helm-release-clean.out.yaml
    assertions:
    - violations: no

- name: deprecated-api-version-k8s1.25
  template: rendered-chart/gatekeeper/templates/constrainttemplate-deprecated-api-version.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-deprecated-api-version-k8s1.25.yaml
  cases:
  - name: helm-release-deprecated-api-version-1.25
    object: fixtures/deprecated-api-version/helm-release-deprecated-1.25.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: CronJob dummy declared with deprecated API version: batch/v1beta1 \(will break in k8s v1.25\)$'
  - name: helm-release-clean
    object: fixtures/deprecated-api-version/helm-release-clean.out.yaml
    assertions:
    - violations: no

- name: deprecated-api-version-k8s1.26
  template: rendered-chart/gatekeeper/templates/constrainttemplate-deprecated-api-version.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-deprecated-api-version-k8s1.26.yaml
  cases:
  - name: helm-release-deprecated-api-version-1.26
    object: fixtures/deprecated-api-version/helm-release-deprecated-1.26.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: FlowSchema dummy declared with deprecated API version: flowcontrol.apiserver.k8s.io/v1beta1 \(will break in k8s v1.26\)$'
  - name: helm-release-clean
    object: fixtures/deprecated-api-version/helm-release-clean.out.yaml
    assertions:
    - violations: no

- name: forbidden-clusterwide-objects
  template: rendered-chart/gatekeeper/templates/constrainttemplate-forbidden-clusterwide-objects.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-forbidden-clusterwide-objects.yaml
  cases:
  - name: gatekeeper-tugger
    object: fixtures/forbidden-clusterwide-objects/gatekeeper-tugger.yaml
    assertions:
    - violations: no
  - name: gatekeeper-validating-webhook-configuration
    object: fixtures/forbidden-clusterwide-objects/gatekeeper-validating-webhook-configuration.yaml
    assertions:
    - violations: no
  - name: cert-manager-mutating-webhook
    object: fixtures/forbidden-clusterwide-objects/cert-manager-mutating-webhook.yaml
    assertions:
    # TODO: repair this
    - violations: 1
      message: '^support-group=foo-group,service=dummy: webhook "webhook.cert-manager.io" does not match our allowlist$'
  - name: cert-manager-validating-webhook
    object: fixtures/forbidden-clusterwide-objects/cert-manager-validating-webhook.yaml
    assertions:
    # TODO: repair this
    - violations: 1
      message: '^support-group=foo-group,service=dummy: webhook "webhook.cert-manager.io" does not match our allowlist$'
  - name: seeder.cloud.sap
    object: fixtures/forbidden-clusterwide-objects/seeder.cloud.sap.yaml
    assertions:
    # TODO: repair this
    - violations: 1
      message: '^support-group=foo-group,service=dummy: webhook "validate-networks.spec.openstack.networks.seeder.cloud.sap" does not match our allowlist$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: webhook "validate-domains.spec.openstack.domains.seeder.cloud.sap" does not match our allowlist$'

- name: high-cpu-requests
  template: rendered-chart/gatekeeper/templates/constrainttemplate-high-cpu-requests.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-high-cpu-requests.yaml
  cases:
  - name: pod-failure
    object: fixtures/high-cpu-requests/pod-failure.yaml
    assertions:
    - violations: 1
      message: "^support-group=foo-group,service=dummy: requests 6.064 CPU in total$"
  - name: pod-close-violation
    object: fixtures/high-cpu-requests/pod-close-violation.yaml
    assertions:
    - violations: no
  - name: pod-only-one-limit
    object: fixtures/high-cpu-requests/pod-only-one-limit.yaml
    assertions:
    - violations: no
  - name: pod-no-limits
    object: fixtures/high-cpu-requests/pod-no-limits.yaml
    assertions:
    - violations: no

- name: images-from-correct-registry
  template: rendered-chart/gatekeeper/templates/constrainttemplate-images-from-correct-registry.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-images-from-correct-registry.yaml
  cases:
  - name: pod-one-image-wrong
    object: fixtures/images-from-correct-registry/pod-one-image-wrong.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "dummy-small" uses incorrect regional registry for image: alpine:3$'
  - name: pod-pass
    object: fixtures/images-from-correct-registry/pod-pass.yaml
    assertions:
    - violations: no

- name: images-from-non-keppel
  template: rendered-chart/gatekeeper/templates/constrainttemplate-images-from-non-keppel.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-images-from-non-keppel.yaml
  cases:
  - name: pod-failure
    object: fixtures/images-from-non-keppel/pod-failure.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "dummy" uses an image that is not from a Keppel registry: alpine:3$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "dummy" uses an image that is not from a Keppel registry: alpine:3$'
  - name: pod-one-of-two
    object: fixtures/images-from-non-keppel/pod-one-of-two.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "dummy" uses an image that is not from a Keppel registry: alpine:3$'
  - name: pod-pass
    object: fixtures/images-from-non-keppel/pod-pass.yaml
    assertions:
    - violations: no
  # The test suite for this policy is a bit more expansive to check the logic in traversal.find_pod().
  - name: pod-owned
    object: fixtures/images-from-non-keppel/pod-owned.yaml
    assertions:
    - violations: no
  - name: deployment-mixed
    object: fixtures/images-from-non-keppel/deployment-mixed.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "container-bad" uses an image that is not from a Keppel registry: alpine:3$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "starter-bad" uses an image that is not from a Keppel registry: alpine:3$'

- name: ingress-annotations-insecure-snippets
  template: rendered-chart/gatekeeper/templates/constrainttemplate-ingress-annotations.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-ingress-annotations-insecure-snippets.yaml
  cases:
  - name: networking-disabled-snippet
    object: fixtures/ingress-annotations/networking-disabled-snippet.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: has disabled annotation: "ingress.kubernetes.io/configuration-snippet" \(disabled due to CVE-2021-25742\)$'
  - name: networking-pass
    object: fixtures/ingress-annotations/networking-pass.yaml
    assertions:
    - violations: no

- name: ingress-annotations-wrong-prefix
  template: rendered-chart/gatekeeper/templates/constrainttemplate-ingress-annotations.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-ingress-annotations-wrong-prefix.yaml
  cases:
  - name: networking-disabled-snippet
    object: fixtures/ingress-annotations/networking-wrong-prefix.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: has disabled annotation: "nginx.ingress.kubernetes.io/proxy-request-buffering" \(use the prefix "ingress.kubernetes.io/" instead\)$'
  - name: networking-pass
    object: fixtures/ingress-annotations/networking-pass.yaml
    assertions:
    - violations: no

- name: outdated-image-bases
  template: rendered-chart/gatekeeper/templates/constrainttemplate-outdated-image-bases.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-outdated-image-bases.yaml
  cases:
  - name: pod-old
    object: fixtures/outdated-image-bases/pod-old.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:old for container "dummy" uses a very old base image \(oldest layer is 417 days old\)$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:old for container "starter" uses a very old base image \(oldest layer is 417 days old\)$'
  - name: pod-new
    object: fixtures/outdated-image-bases/pod-new.yaml
    assertions:
    - violations: no

- name: owner-info-on-helm-releases
  template: rendered-chart/gatekeeper/templates/constrainttemplate-owner-info-on-helm-releases.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-owner-info-on-helm-releases.yaml
  cases:
  - name: configmap-no-owner
    object: fixtures/owner-info-on-helm-releases/configmap-no-owner.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: could not find ConfigMap: owner-of-almost-empty-chart$'
  - name: configmap-no-owner-pending-upgrade
    object: fixtures/owner-info-on-helm-releases/configmap-no-owner-pending-upgrade.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: could not find ConfigMap: owner-of-almost-empty-chart$'
  - name: configmap-no-owner-superseded
    object: fixtures/owner-info-on-helm-releases/configmap-no-owner-superseded.out.yaml
    assertions:
    - violations: no
  - name: configmap-outdated-chart
    object: fixtures/owner-info-on-helm-releases/configmap-outdated-chart.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: Chart uses outdated owner-info version "0.1.2". Please update to at least "0.2.0".$'
  - name: pod-owner-info
    object: fixtures/owner-info-on-helm-releases/configmap-pass.out.yaml
    assertions:
    - violations: no

- name: pci-forbidden-images
  template: rendered-chart/gatekeeper/templates/constrainttemplate-pci-forbidden-images.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-pci-forbidden-images.yaml
  cases:
  - name: pod-forbidden-image
    object: fixtures/pci-forbidden-images/pod-with-forbidden-image.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: container "dummy" uses forbidden image: bogus-pattern-for-testing:3$'
  - name: pod-pass
    object: fixtures/pci-forbidden-images/pod-pass.yaml
    assertions:
    - violations: no

- name: pod-labels
  template: rendered-chart/gatekeeper/templates/constrainttemplate-pod-labels.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-pod-labels.yaml
  cases:
  - name: pod-invalid-labels
    object: fixtures/pod-labels/pod-invalid-labels.yaml
    assertions:
    - violations: 1
      message: '^support-group=gatekeeper,service=containers: pod has an unacceptable label value: ccloud/support-group="gatekeeper"$'
  - name: pod-no-labels
    object: fixtures/pod-labels/pod-no-labels.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: pod does not have the required label: ccloud/support-group$'
  - name: pod-labels
    object: fixtures/pod-labels/pod-labels.yaml
    assertions:
    - violations: no

- name: pod-security
  template: rendered-chart/gatekeeper/templates/constrainttemplate-pod-security.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-pod-security.yaml
  cases:
  - name: pod-security-accept-audit-logs-auditbeat
    object: fixtures/pod-security/audit-logs-auditbeat.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-kube-proxy-ng
    object: fixtures/pod-security/kube-proxy-ng.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-kubernikus-apiserver
    object: fixtures/pod-security/kubernikus-apiserver.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-neutron-network-agent
    object: fixtures/pod-security/neutron-network-agent.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-node-exporter
    object: fixtures/pod-security/node-exporter.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-swift-drive-autopilot
    object: fixtures/pod-security/swift-drive-autopilot.yaml
    assertions:
    - violations: no
  - name: pod-security-accept-swift-servers
    object: fixtures/pod-security/swift-servers.yaml
    assertions:
    - violations: no
  - name: pod-security-reject-security-nightmare
    object: fixtures/pod-security/invalid.yaml
    assertions:
    - violations: 1
      message: '^support-group=none,service=none: pod is not allowed to set spec.hostNetwork = true$'
    - violations: 1
      message: '^support-group=none,service=none: pod is not allowed to set spec.hostPID = true$'
    - violations: 1
      message: '^support-group=none,service=none: pod is not allowed to set spec.containers\["mallory"].securityContext.allowPrivilegeEscalation = true$'
    - violations: 1
      message: '^support-group=none,service=none: pod is not allowed to set spec.containers\["mallory"].securityContext.privileged = true$'
    - violations: 1
      message: '^support-group=none,service=none: pod is not allowed to set spec.containers\["mallory"].securityContext.capabilities.add = \["CAP_SYS_ADMIN"]$'
    - violations: 1
      message: '^support-group=none,service=none: container \"mallory\" in this pod is not allowed to mount hostPath volumes with path \"/\" \(readonly = false\)$'

- name: prometheus-scrape-annotations
  template: rendered-chart/gatekeeper/templates/constrainttemplate-prometheus-scrape-annotations.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-prometheus-scrape-annotations.yaml
  cases:
  - name: pod-missing-target
    object: fixtures/prometheus-scrape-annotations/pod-missing-target.yaml
    inventory:
    - fixtures/prometheus-scrape-annotations/inventory.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: has prometheus.io/scrape annotation, but prometheus.io/targets annotation is missing or does not have a valid value \(got: \[""\], valid: \["openstack"\]\)$'
  - name: pod-pass
    object: fixtures/prometheus-scrape-annotations/pod-pass.yaml
    inventory:
    - fixtures/prometheus-scrape-annotations/inventory.yaml
    assertions:
    - violations: no

- name: prometheusrule-alert-labels
  template: rendered-chart/gatekeeper/templates/constrainttemplate-prometheusrule-alert-labels.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-prometheusrule-alert-labels.yaml
  cases:
  - name: prometheus-rule-no-label
    object: fixtures/prometheusrule-alert-labels/prometheus-rule-no-label.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have a valid value for labels.severity \("critical", "warning" or "info"\)$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have labels.tier$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have labels.support_group$'
  - name: prometheus-rule-only-severity
    object: fixtures/prometheusrule-alert-labels/prometheus-rule-only-severity.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have a valid value for labels.playbook \(required for critical alerts\)$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have labels.tier$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have labels.support_group$'
  - name: prometheus-rule-only-severity-tier
    object: fixtures/prometheusrule-alert-labels/prometheus-rule-only-severity-tier.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: rule DummyBackupWentMissing in group backup.alerts does not have a valid value for labels.playbook \(required for critical alerts\)$'
  - name: prometheus-rule-pass
    object: fixtures/prometheusrule-alert-labels/prometheus-rule-pass.yaml
    assertions:
    - violations: no

- name: region-value-mismatch
  template: rendered-chart/gatekeeper/templates/constrainttemplate-region-value-mismatch.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-region-value-mismatch.yaml
  cases:
  - name: helm-release-region-mismatch
    object: fixtures/region-value-mismatch/helm-release-region-mismatch.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: .Values.global.region does not match the deployed region: expected qa-de-1, but found "qa-de-9"$'
  - name: helm-release-no-region
    object: fixtures/region-value-mismatch/helm-release-no-region.out.yaml
    assertions:
    - violations: no
  - name: helm-release-invalid-region
    object: fixtures/region-value-mismatch/helm-release-invalid-region.out.yaml
    assertions:
    - violations: no
  - name: helm-release-pass
    object: fixtures/region-value-mismatch/helm-release-pass.out.yaml
    assertions:
    - violations: no

- name: region-value-missing
  template: rendered-chart/gatekeeper/templates/constrainttemplate-region-value-missing.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-region-value-missing.yaml
  cases:
  - name: helm-release-no-region
    object: fixtures/region-value-missing/helm-release-no-region.out.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: missing or invalid .Values.global.region value$'
  - name: helm-release-pass
    object: fixtures/region-value-missing/helm-release-pass.out.yaml
    assertions:
    - violations: no

- name: resource-limits
  template: rendered-chart/gatekeeper/templates/constrainttemplate-resource-limits.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-resource-limits.yaml
  cases:
  - name: pod-complete-failure
    object: fixtures/resource-limits/pod-complete-failure.yaml
    assertions:
    - violations: 1
      message: "^support-group=foo-group,service=dummy: cpu and memory limits not set on some or all containers$"
  - name: pod-some-failure
    object: fixtures/resource-limits/pod-some-failure.yaml
    assertions:
    - violations: 1
      message: "^support-group=foo-group,service=dummy: cpu and memory limits not set on some or all containers$"
  - name: pod-pass
    object: fixtures/resource-limits/pod-pass.yaml
    assertions:
    - violations: no

- name: vulnerable-images
  template: rendered-chart/gatekeeper/templates/constrainttemplate-vulnerable-images.yaml
  constraint: rendered-chart/gatekeeper-config/templates/constraint-vulnerable-images.yaml
  cases:
  - name: pod-vulnerable
    object: fixtures/vulnerable-images/pod-vulnerable.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:low for container "dummylow" has vulnerability status "Low"$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:medium for container "dummymedium" has vulnerability status "Medium"$'
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:high for container "starter" has vulnerability status "High"$'
  - name: pod-unclear
    object: fixtures/vulnerable-images/pod-unclear.yaml
    assertions:
    - violations: 1
      message: '^support-group=foo-group,service=dummy: image keppel.example.com/vulnerability:unclear for container "dummy" has vulnerability status "Unclear"$'
  - name: pod-clean
    object: fixtures/vulnerable-images/pod-clean.yaml
    assertions:
    - violations: no
