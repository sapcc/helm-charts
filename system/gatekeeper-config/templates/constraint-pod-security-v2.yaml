{{/* This check is disabled entirely in the lab clusters to avoid needlessly obstructing the development of changes to the core components. */}}
{{/* In the QA cluster, this check is in audit-only mode. Service owners can set up new deployments there and then ask for an extension of the allowlist based on that template. */}}
{{- if ne .Values.cluster_layer "labs" }}

apiVersion: constraints.gatekeeper.sh/v1beta1
kind: GkPodSecurityV2
metadata:
  name: podsecurityv2
  annotations:
    {{- include "sources" (tuple "pod-security-v2" "pod-security-v2") | indent 4 }}
    {{- include "docstring" (tuple $ "GkPodSecurityV2") | indent 4 }}
  labels:
    severity: 'debug'
spec:
  enforcementAction: dryrun
  match: {{ include "match_pods_and_pod_owners" . | indent 4 }}
  parameters:
    allowlist:
      ### unit tests
      {{- if eq .Values.cluster_type "test" }}
      - matchNamespace: foo
        matchRepository: test-app/unprivileged
        mayUseCapabilities: [ FOO ]
      - matchNamespace: foo
        matchRepository: test-app/highly-privileged
        mayUseHostNetwork: true
        mayUseHostPID: true
        mayUsePrivilegeEscalation: true
        mayBePrivileged: true
        mayUseCapabilities: [ FOO, SYS_ADMIN ]
        mayReadHostPathVolumes: [ / ]
        mayWriteHostPathVolumes: [ / ]
      {{- end }}
      ### archer
      - matchNamespace: monsoon3
        matchRepository: ccloud/archer
        # TODO: why?
        mayBePrivileged: true
      ### audit-logs-auditbeat
      - matchNamespace: audit-logs
        matchRepository: ccloud-elastic-mirror/beats/auditbeat-oss
        # The "auditbeat" container needs to break out into the host to read
        # and also configure the kernel audit log.
        mayUseHostPID: true
        mayUseCapabilities: [ AUDIT_CONTROL, AUDIT_READ, AUDIT_WRITE ]
        mayReadHostPathVolumes: [ /bin, /sbin, /usr/bin, /usr/sbin, /etc, /run/containerd ]
        mayWriteHostPathVolumes: [ /var/lib/auditbeat-data ]
      {{- if eq .Values.cluster_type "cloudshell" "concourse" "internet" "scaleout" }}
      - matchNamespace: audit-logs
        matchRepository: ccloud-dockerhub-mirror/library/alpine
        # The init container "enable-pamd-tty" needs to break out into the host
        # to setup audit logging for PAM-based authentication (this is only
        # necessary in clusters where the worker nodes are provisioned by
        # OpenStack instead of Terraform).
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ / ]
      {{- end }}
      ### automation-jobs
      {{- if eq .Values.cluster_type "scaleout" }}
      - matchNamespace: awx
        matchRepository: keppel.global.cloud.sap/ccloud/servicemesh/proxy-init
        # TODO: why?
        mayBePrivileged: true
        mayUsePrivilegeEscalation: true
        mayUseCapabilities: [ NET_ADMIN, NET_RAW ]
      {{- end }}
      ### calico
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: cni-nanny
        matchRepository: ccloud-ghcr-io-mirror/sapcc/cni-nanny
        # TODO: why?
        mayUseHostNetwork: true
      - matchNamespace: calico-apiserver
        matchRepository: ccloud-dockerhub-mirror/calico/apiserver
        # TODO: why?
        mayUseHostNetwork: true
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/calico/kube-controllers
        # TODO: why?
        mayUseHostNetwork: true
      {{- end }}
      {{- if eq .Values.cluster_type "baremetal" "cloudshell" }}
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/calico/node
        # TODO: why?
        mayUseHostNetwork: true
        mayBePrivileged: true
        mayReadHostPathVolumes: [ /var/log/calico/cni, /proc ]
        mayWriteHostPathVolumes: [ /etc/cni/net.d, /run/xtables.lock, /sys/fs/, /sys/fs/bpf, /var/lib/calico, /var/run/calico, /var/run/nodeagent ]
      - matchNamespace: kube-system
        matchRepository: ccloud-ghcr-io-mirror/sapcc/bird_exporter
        # TODO: why?
        mayReadHostPathVolumes:
        - /var/run/calico
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/calico/cni
        # Many kube-system components need broad network access (e.g. coredns,
        # CNI, ingress-nginx)
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /etc/cni/net.d, /opt/cni/bin ]
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/calico/typha
        # TODO: why?
        mayUseHostNetwork: true
      {{- end }}
      ### cinder-volume-backup
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: monsoon3
        matchRepository: ccloud/loci-cinder
        # TODO: why?
        mayUseCapabilities: [ CHOWN, DAC_OVERRIDE, DAC_READ_SEARCH, FOWNER, NET_ADMIN, SYS_ADMIN ]
      {{- end }}
      ### cloudprober
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace:  infra-monitoring
        matchRepository: ccloud-dockerhub-mirror/cloudprober/cloudprober
        # The cloudprober pods need to send pings.
        mayUseCapabilities: [ NET_RAW ]
      {{- end }}
      ### concourse
      {{- if eq .Values.cluster_type "concourse" }}
      - matchNamespace: concourse
        matchRepository: ccloud-dockerhub-mirror/haproxytech/kubernetes-ingress
        # TODO: Why does Concourse need its own ingress? And why does it need
        # CAP_NET_BIND_SERVICE instead of being exposed via a k8s Service?
        mayUseCapabilities: [ NET_BIND_SERVICE ]
      - matchNamespace: concourse
        matchRepository: ccloud-dockerhub-mirror/concourse/concourse
        # Concourse worker pods need to access their work directory on the host FS.
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /concourse-work-dir ]
      {{- end }}
      ### coredns
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/coredns/coredns
        # Many kube-system components need broad network access (e.g. coredns,
        # CNI, ingress-nginx)
        mayUseCapabilities: [ NET_BIND_SERVICE ]
      ### csi-cinder-nodeplugin
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/provider-os/cinder-csi-plugin
        # TODO: why?
        mayUseHostNetwork: true
        mayUsePrivilegeEscalation: true
        mayBePrivileged: true
        mayUseCapabilities: [ SYS_ADMIN ]
        mayWriteHostPathVolumes: [ /var/lib/kubelet, /var/lib/kubelet/plugins/cinder.csi.openstack.org ]
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/sig-storage/livenessprobe
        # TODO: why?
        mayUseHostNetwork: true
        mayUsePrivilegeEscalation: true
        mayBePrivileged: true
        mayUseCapabilities: [ SYS_ADMIN ]
        mayWriteHostPathVolumes: [ /var/lib/kubelet/plugins/cinder.csi.openstack.org ]
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/sig-storage/csi-node-driver-registrar
        # TODO: why?
        mayUseHostNetwork: true
        mayUseCapabilities: [ SYS_ADMIN ]
        mayUsePrivilegeEscalation: true
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /var/lib/kubelet/plugins/cinder.csi.openstack.org, /var/lib/kubelet/plugins_registry/ ]
      ### falco
      {{- if eq .Values.cluster_type "baremetal" "concourse" "scaleout" }}
      - matchNamespace: kube-monitoring
        matchRepository: ccloud-dockerhub-mirror/falcosecurity/falco
        # TODO: why?
        mayBePrivileged: true
        mayReadHostPathVolumes: [ /boot, /usr, /etc, /proc ]
        mayWriteHostPathVolumes: [ /lib/modules, /run/containerd, /run/crio, /var/run ]
      {{- end }}
      ### flannel
      {{- if eq .Values.cluster_type "concourse" "internet" "postfix" "scaleout" }}
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/flannel/flannel
        # TODO: why?
        mayUseHostNetwork: true
        mayUseCapabilities: [ NET_ADMIN, NET_RAW ]
        mayWriteHostPathVolumes: [ /run/flannel, /run/xtables.lock, /etc/cni/net.d ]
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/flannel/flannel-cni-plugin
        # Many kube-system components need broad network access (e.g. coredns,
        # CNI, ingress-nginx)
        mayUseHostNetwork: true
        mayUseCapabilities: [ NET_ADMIN, NET_RAW ]
        mayWriteHostPathVolumes: [ /opt/cni/bin ]
      {{- end }}
      ### flatcar-linux-update-agent
      - matchNamespace: maintenance-controller
        matchRepository: ccloud/flatcar-linux-update-operator
        # TODO: why?
        mayWriteHostPathVolumes: [ /etc/flatcar, /etc/os-release, /usr/share/flatcar, /var/run/dbus ]
      ### fluent
      - matchNamespace: audit-logs
        matchRepository: ccloud/elk-fluent
        # Most Fluent pods (except -systemd) need to read container logs.
        # All Fluent pods need to access log files on the host.
        mayReadHostPathVolumes: [ /var/lib/docker/containers ]
        mayWriteHostPathVolumes: [ /var/log ]
      ### fluent-prometheus
      {{- if eq .Values.cluster_type "baremetal" "scaleout" }}
      - matchNamespace: logs
        matchRepository: ccloud/elk-fluent
        mayReadHostPathVolumes: [ /var/lib/docker/containers ]
        mayWriteHostPathVolumes: [ /var/log ]
      {{- end }}
      ### ingress-nginx-controller
      {{- if eq .Values.cluster_type "postfix" }}
      - matchNamespace: ingress-nginx
        matchRepository: ingress-nginx/controller
        # TODO: why?
        mayUsePrivilegeEscalation: true
        mayUseCapabilities: [ NET_BIND_SERVICE ]
      {{- end }}
      ### ironic-inspector
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: monsoon3
        matchRepository: ccloud/loci-ironic
        # TODO: why?
        mayUseCapabilities: [ NET_ADMIN ]
      {{- end }}
      ### kube-cni
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: kube-system
        matchRepository: ccloud/cni-plugins
        # Many kube-system components need broad network access (e.g. coredns,
        # CNI, ingress-nginx)
        mayUseHostNetwork: true
        mayWriteHostPathVolumes: [ /opt/cni/bin ]
      - matchNamespace: kube-system
        matchRepository: ccloud/multus-cni
        # Many kube-system components need broad network access (e.g. coredns,
        # CNI, ingress-nginx)
        mayUseHostNetwork: true
        mayWriteHostPathVolumes: [ /opt/cni/bin ]
      {{- end }}
      ### kube-proxy
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/kube-proxy
        # Many kube-system components need broad node-level access (e.g.
        # kube-proxy, MTU discovery, wormhole to k8s central).
        mayUseHostNetwork: true
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /run/xtables.lock ]
      ### kube-system-ingress-nginx-controller
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/ingress-nginx/controller
        # TODO: why?
        mayUseCapabilities: [ NET_BIND_SERVICE ]
      ### kube-system-ldap-named-user
      {{- if eq .Values.cluster_type "cloudshell" "concourse" "internet" "scaleout" }}
      - matchNamespace: kube-system
        matchRepository: ccloud-dockerhub-mirror/library/alpine
        # TODO: why?
        mayBePrivileged: true
        mayUseHostPID: true
        mayWriteHostPathVolumes: [ / ]
      {{- end }}
      ### linkerd
      - matchNamespace: linkerd
        matchRepository: ccloud/servicemesh/proxy-init
        # TODO: why?
        mayUsePrivilegeEscalation: true
        mayBePrivileged: true
        mayUseCapabilities: [ NET_ADMIN, NET_RAW ]
      ### logs-collector
      - matchNamespace: logs
        matchRepository: ccloud/opentelemetry-collector-contrib
        # Most Otel pods need to access log files on the host.
        mayReadHostPathVolumes: [ /var/log ]
      ### neutron
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: monsoon3
        matchRepository: ccloud-dockerhub-mirror/library/alpine
        # The init container mounts the entire host FS to load kernel modules.
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ / ]
      - matchNamespace: monsoon3
        matchRepository: ccloud/loci-neutron
        # The agent containers need to reach into most customer networks.
        mayBePrivileged: true
        mayUseCapabilities: [ DAC_OVERRIDE, DAC_READ_SEARCH, NET_ADMIN, SYS_ADMIN, SYS_PTRACE ]
        mayWriteHostPathVolumes: [ /dev/log ]
      {{- end }}
      ### nodecidr-controller
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: kube-system
        matchRepository: ccloud-ghcr-io-mirror/sapcc/ccloud-nodecidr-controller
        # TODO: why?
        mayUseHostNetwork: true
      {{- end }}
      ### node-exporter
      - matchNamespace: kube-monitoring
        matchRepository: ccloud-dockerhub-mirror/prom/node-exporter
        # node-exporter needs node-level access to collect node metrics
        mayUseHostNetwork: true
        mayUseHostPID: true
        # the node exporter needs to inspect the host filesystem to collect metrics
        mayReadHostPathVolumes: [ /, /proc, /sys, /var/run/dbus/system_bus_socket ]
      ### node-problem-detector
      - matchNamespace: kube-system
        matchRepository: ccloud-registry-k8s-io-mirror/node-problem-detector/node-problem-detector
        mayUseHostNetwork: true
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /etc/localtime, /proc, /var/log/ ]
      ### ns-exporter
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: ns-exporter
        matchRepository: ccloud/ns-exporter
        # The ns-exporter needs to reach into all network namespaces.
        mayBePrivileged: true
        mayUseHostPID: true
      {{- end }}
      ### oomkill-exporter
      {{- if eq .Values.cluster_type "baremetal" "concourse" "scaleout" }}
      - matchNamespace: kube-monitoring
        matchRepository: ccloud/kubernetes-oomkill-exporter
        # The oomkill-exporter needs to talk to container runtimes and read the kernel log.
        mayBePrivileged: true
        mayReadHostPathVolumes: [ /dev/kmsg ]
        mayWriteHostPathVolumes: [ /run/containerd/containerd.sock, /var/run/docker.sock ]
      {{- end }}
      ### opensearch-hermes
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: hermes
        matchRepository: ccloud-dockerhub-mirror/opensearchproject/opensearch
        # Elastic and OpenSearch need to use sysctl to increase `vm.max_map_count`:
        # <https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html>
        mayBePrivileged: true
      {{- end }}
      ### opensearch-logs-client
      {{- if eq .Values.cluster_type "scaleout" }}
      - matchNamespace: opensearch-logs
        matchRepository: ccloud-dockerhub-mirror/library/busybox
        # Elastic and OpenSearch need to use sysctl to increase `vm.max_map_count`:
        # <https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html>
        mayBePrivileged: true
      {{- end }}
      ### pmtud
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: kube-system
        matchRepository: ccloud/iptables
        # TODO: why?
        mayUseHostNetwork: true
        mayBePrivileged: true
      - matchNamespace: kube-system
        matchRepository: ccloud-ghcr-io-mirror/sapcc/go-pmtud
        # TODO: why?
        mayUseHostNetwork: true
        mayBePrivileged: true
      {{- end }}
      ### postfixin
      {{- if eq .Values.cluster_type "postfix" }}
      - matchNamespace: postfixin
        matchRepository: genady/postfix-exporter
        # TODO: why?
        mayReadHostPathVolumes: [ /var/log/pods/ ]
      - matchNamespace: postfixin-bounce
        matchRepository: genady/postfix-exporter
        # TODO: why?
        mayReadHostPathVolumes: [ /var/log/pods/ ]
      {{- end }}
      ### postfixout
      {{- if eq .Values.cluster_type "postfix" }}
      - matchNamespace: postfixout
        matchRepository: istio/proxyv2
        # TODO: why?
        mayUseCapabilities: [ NET_ADMIN, NET_RAW ]
      - matchNamespace: postfixout
        matchRepository: genady/postfix-exporter
        # TODO: why?
        mayReadHostPathVolumes: [ /var/log/pods/ ]
      {{- end }}
      ### px
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: px
        matchRepository: ccloud/px
        # Bird needs to be able to send and receive BGP announcements.
        mayBePrivileged: true
        mayUseCapabilities: [ NET_ADMIN ]
      {{- end }}
      ### sporebox
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: default
        matchRepository: ccloud/sporebox
        # Sporebox is used to jump into the namespaces of network agents.
        mayUseHostNetwork: true
        mayUseHostPID: true
        mayBePrivileged: true
      {{- end }}
      ### swift
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: swift
        matchRepository: ccloud/swift
        # Swift storage components inspect the network interfaces to establish
        # their identity within the Swift ring
        mayUseHostNetwork: true
        # Swift storage components need to be able to mount/unmount disks at
        # runtime
        mayBePrivileged: true
        # All swift components need to access the storage disks (as well as state
        # shared with the drive autopilot)
        mayWriteHostPathVolumes: [ /run/swift-storage/state, /srv/node, /var/cache/swift ]
      - matchNamespace: swift
        matchRepository: ccloud/swift-drive-autopilot
        # Swift-drive-autopilot needs far-reaching access to the host FS to
        # find/format/encrypt/decrypt/mount/unmount disks and watch the
        # kernel log for errors
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ / ]
      - matchNamespace: swift
        matchRepository: ccloud-dockerhub-mirror/prom/statsd-exporter
        # TODO: why?
        mayUseHostNetwork: true
      {{- end }}
      ### sysctl
      {{- if eq .Values.cluster_type "baremetal" }}
      - matchNamespace: kube-system
        matchRepository: ccloud/sysctl
        # TODO: why?
        mayUseHostNetwork: true
        mayBePrivileged: true
      {{- end }}
      ### tailscale
      {{- if eq .Values.cluster_type "scaleout" "internet" }}
      - matchNamespace: tailscale
        matchRepository: ccloud/tailcontrol
        # TODO: Why does Tailscale need to be privileged? Is CAP_NET_ADMIN not enough?
        mayBePrivileged: true
        # Tailscale needs CAP_NET_ADMIN to establish its VPN network interface.
        mayUseCapabilities: [ NET_ADMIN ]
      {{- end }}
      ### toolbox-init
      - matchNamespace: kube-system
        matchRepository: ccloud/toolbox-docker
        # TODO: why?
        mayBePrivileged: true
        mayWriteHostPathVolumes: [ /etc/sudoers.d/, /opt/bin/, /root, /var/lib, /var/run/docker.sock ]
      - matchNamespace: kube-system
        matchRepository: ccloud/toolbox-sleep
        # TODO: why?
        mayBePrivileged: true
      ### workstation
      # scaleout
      - matchNamespace: workstation
        matchRepository: ccloud-dockerhub-mirror/library/docker
        # A Workstation deployment contains a "docker-carrier" container where
        # a Docker daemon is running. dockerd needs privileged access to the
        # kernel to run, even when localized into a container.
        mayBePrivileged: true
      ### wormhole
      - matchNamespace: kube-system
        matchRepository: ccloud/kubernikus
        # Many kube-system components need broad node-level access (e.g.
        # kube-proxy, MTU discovery, wormhole to k8s central).
        mayUseHostNetwork: true
        mayBePrivileged: true
        mayReadHostPathVolumes: [ /var/lib/kubelet ]
{{- end }}
