{{- if .Values.objectstore.multiInstance.enabled }}
apiVersion: ceph.rook.io/v1
kind: CephObjectRealm
metadata:
  name: {{ .Values.objectstore.name }}
  namespace: {{ .Release.Namespace }}
---
apiVersion: ceph.rook.io/v1
kind: CephObjectZoneGroup
metadata:
  name: {{ .Values.objectstore.name }}
  namespace: {{ .Release.Namespace }}
spec:
  realm: {{ .Values.objectstore.name }}
---
apiVersion: ceph.rook.io/v1
kind: CephObjectZone
metadata:
  name: {{ .Values.objectstore.name }}
  namespace: {{ .Release.Namespace }}
spec:
  zoneGroup: {{ .Values.objectstore.name }}
  metadataPool: {{ toYaml .Values.objectstore.metadataPool | nindent 4 }}
  dataPool: {{ toYaml .Values.objectstore.dataPool | nindent 4 }}
{{- range $instance := .Values.objectstore.multiInstance.extraInstances }}
---
apiVersion: ceph.rook.io/v1
kind: CephObjectStore
metadata:
  name: {{ $instance.name }}
  namespace: {{ $.Release.Namespace }}
spec:
  zone:
    name: {{ $.Values.objectstore.name }} 
  hosting:
{{- if gt (len $instance.gateway.dnsNames) 0 }}
    advertiseEndpoint:
      dnsName: {{ $instance.gateway.dnsNames | first }}
      port: 443
      useTls: true
    dnsNames: {{ toYaml $instance.gateway.dnsNames | nindent 8 }}
{{- end }}
  gateway:
    instances: {{ $instance.gateway.instances | default $.Values.objectstore.gateway.instances }}
    {{- if or $instance.gateway.port $.Values.objectstore.gateway.port }}
    port: {{ $instance.gateway.port | default $.Values.objectstore.gateway.port }}
    {{- end }}
    {{- if or $instance.gateway.securePort $.Values.objectstore.gateway.securePort }}
    securePort: {{ $instance.gateway.securePort | default $.Values.objectstore.gateway.securePort }}
    {{- end }}
    placement:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.metal.cloud.sap/role
                  operator: In
                  values:
                    - {{ $.Values.osd.nodeRole }}
      # since the CephCluster's network provider is "host", we need to isolate 80/443 port listeners from each other
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - rook-ceph-rgw
          topologyKey: kubernetes.io/hostname
    priorityClassName: system-cluster-critical
    sslCertificateRef: {{ $instance.gateway.sslCertificateRef | default $.Values.objectstore.gateway.sslCertificateRef }}
    resources: {{ toYaml ( $instance.gateway.resources | default $.Values.objectstore.gateway.resources) | nindent 6 }}
  preservePoolsOnDelete: true
{{- if and $.Values.objectstore.keystone.enabled }}
{{- with $.Values.objectstore.keystone }}
  auth:
    keystone:
      acceptedRoles:
{{- range $_, $role := .accepted_roles }}
        - {{ $role }}
{{- end }}
      implicitTenants: {{ .implicit_tenants | quote }}
      serviceUserSecretName: ceph-keystone-secret
      tokenCacheSize: {{ .token_cache_size }}
      url: {{ .url }}
  protocols:
{{- if $instance.enabledAPIs }}
    enableAPIs: {{ toYaml $instance.enabledAPIs | nindent 6 }}
{{- end }}
    s3:
      authUseKeystone: true
    swift:
      accountInUrl: {{ .swift_account_in_url }}
      versioningEnabled: {{ .swift_versioning_enabled }}
{{- end }}
{{- end }}
{{- end }}
{{- end }}
