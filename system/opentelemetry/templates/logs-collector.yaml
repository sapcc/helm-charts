{{- if .Values.logsCollector.enabled }}
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: logs
  labels:
  {{- include "plugin.labels" . | nindent 4 }} 
  {{- if .Values.customLabels }}
  {{ toYaml .Values.customLabels | nindent 4 }}
  {{- end }}
spec:
  mode: daemonset
  tolerations:
  - operator: Exists
  env:
    - name: NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: KUBE_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: cluster
      value: "{{ .Values.cluster }}"
    - name: region
      value: "{{ .Values.region }}"
  envFrom:
    - secretRef:
         name: otel-basic-auth
{{- if .Values.podMonitor.enabled }}
  ports:
    - name: prometheus
      port: 9999
{{- end }}
  image: {{ index .Values "manager" "collectorImage" "repository" }}:{{ index .Values "manager" "collectorImage" "tag" }}
  volumeMounts:
  - mountPath: /var/log
    name: varlog
    readOnly: true
  volumes:
  - name: varlog
    hostPath:
      path: /var/log
  config:
    receivers:
      journald:
        directory: /var/log/journal
        operators:
          - id: journal-label
            type: add
            field: attributes["log.type"]
            value: "journald"

      k8s_events:
        auth_type: serviceAccount

      filelog/containerd:
        include_file_path: true
        include: [ /var/log/pods/*/*/*.log ]
        operators:
          - id: container-parser
            type: container
          - id: parser-containerd
            type: add
            field: resource["container.runtime"]
            value: "containerd"
          - id: container-label
            type: add
            field: attributes["log.type"]
            value: "containerd"

      filelog/files:
        include: [ /var/log/libvirt/qemu/*.log, /var/log/openvswitch/*.log ]
        include_file_path: true
        start_at: beginning
        multiline:
          line_start_pattern: ^\d{4}-\d{2}-\d{2}
        operators:
          - type: regex_parser
            regex: (?P<logtime>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3})
          - type: time_parser
            parse_from: attributes.logtime
            layout: '%Y-%m-%dT%H:%M:%S.%L'
            layout_type: strptime
          - id: file-label
            type: add
            field: attributes["log.type"]
            value: "files"

{{- if .Values.podMonitor.enabled }}
      prometheus/internal:
        config:
          scrape_configs:
            - job_name: 'internal'
              scrape_interval: 5s
              static_configs:
                - targets: ['127.0.0.1:8888']
{{- end }}

    processors:
      batch:
        send_batch_max_size: 500
        timeout: 5s
        send_batch_size : 10

{{- if .Values.podMonitor.enabled }}
      attributes/prometheus:
        actions:
          - action: insert
            key: k8s_node_name
            value: ${KUBE_NODE_NAME}
          - action: insert
            key: k8s_cluster_name
            value: ${cluster}
          - action: insert
            key: region
            value: ${region}
          - action: delete
            key: service_instance_id
          - action: delete
            key: pod
{{- end }}

      attributes/cluster:
        actions:
          - action: insert
            key: k8s.cluster.name
            value: ${cluster}
          - action: insert
            key: region
            value: ${region}
          - action: insert
            key: k8s.node.name
            value: ${KUBE_NODE_NAME}

      attributes/k8sevents:
        actions:
          - action: insert
            key: k8s.node.name
            value: ${KUBE_NODE_NAME}
          - key: k8s.namespace.name
            from_attribute: k8s.namespace.name
            action: insert
          - action: insert
            key: k8s.cluster.name
            value: ${cluster}
          - action: insert
            key: region
            value: ${region}
          - action: insert
            key: log.type
            value: "k8sevents"

      transform/journal:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - merge_maps(cache, body, "upsert") where IsMatch(body, "^\\{")
              - set(attributes["message"], cache["MESSAGE"])
              - set(attributes["code_file"], cache["CODE_FILE"])
              - set(attributes["code_func"], cache["CODE_FUNC"])
              - set(attributes["code_line"], cache["CODE_LINE"])
              - set(attributes["incovation_id"], cache["INVOCATION_ID"])
              - set(attributes["message_id"], cache["MESSAGE_ID"])
              - set(attributes["priority"], cache["PRIORITY"])
              - set(attributes["syslog_facility"], cache["SYSLOG_FACILITY"])
              - set(attributes["syslog_identifier"], cache["SYSLOG_IDENTIFIER"])
              - set(attributes["tid"], cache["TID"])
              - set(attributes["unit"], cache["UNIT"])
              - set(attributes["boot_id"], cache["_BOOT_ID"])
              - set(attributes["cao_effective"], cache["_CAP_EFFECTIVE"])
              - set(attributes["cmdline"], cache["_CMDLINE"])
              - set(attributes["exe"], cache["_EXE"])
              - set(attributes["gid"], cache["_GID"])
              - set(attributes["hostname"], cache["_HOSTNAME"])
              - set(attributes["machine_id"], cache["_MACHINE_ID"])
              - set(attributes["pid"], cache["_PID"])
              - set(attributes["runtime_scope"], cache["_RUNTIME_SCOPE"])
              - set(attributes["selinux_context"], cache["_SELINUX_CONTEXT"])
              - set(attributes["source_realtime_timestamp"], cache["_SOURCE_REALTIME_TIMESTAMP"])
              - set(attributes["systemd_cgroup"], cache["_SYSTEMD_CGROUP"])
              - set(attributes["systemd_slice"], cache["_SYSTEMD_SLICE"])
              - set(attributes["systemd_unit"], cache["_SYSTEMD_UNIT"])
              - set(attributes["transport"], cache["_TRANSPORT"])
              - set(attributes["uid"], cache["_UID"])
              - set(attributes["cursor"], cache["__CURSOR"])
              - set(attributes["monotonic_timestamp"], cache["__MONOTONIC_TIMESTAMP"])
              - delete_key(attributes, "cache")

      transform/ingress:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["app.label.name"] == "ingress-nginx"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{IP:client.address} %{NOTSPACE:client.ident} %{NOTSPACE:client.auth} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:request_method} %{NOTSPACE:request_path} %{WORD:network.protocol.name}/%{NOTSPACE:network.protocol.version}\" %{NUMBER:response} %{NUMBER:content_length:int} %{QUOTEDSTRING} \"%{GREEDYDATA:user_agent}\" %{NUMBER:request_length:int} %{BASE10NUM:request_time:float}( \\[%{NOTSPACE:service}\\])? ?(\\[\\])? %{IP:server.address}\\:%{NUMBER:server.port} %{NUMBER:upstream_response_length:int} %{BASE10NUM:upstream_response_time:float} %{NOTSPACE:upstream_status} %{NOTSPACE:request_id}", true),"upsert")
              - set(attributes["network.protocol.name"], ConvertCase(attributes["network.protocol.name"], "lower"))

      transform/ceph_rgw:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["app.label.component"] == "cephobjectstores.ceph.rook.io"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{WORD:debug_level} %{TIMESTAMP_ISO8601:log_timestamp}(%{SPACE})?%{NOTSPACE}(%{SPACE})?%{NOTSPACE}(%{SPACE})?%{WORD}\\:(%{SPACE})?%{WORD}\\:(%{SPACE})?%{IP:client.address}(%{SPACE})?%{NOTSPACE}(%{SPACE})%{PROJECT_ID:project.id}(\\$%{NOTSPACE})?(%{SPACE})?\\[%{HTTPDATE:request.timestamp}\\] \"%{WORD:request.method} \\/(?<bucket>[a-zA-Z0-9._+-]+)?(\\/)?(%{NOTSPACE:request.path})? %{WORD:network.protocol.name}/%{NOTSPACE:network.protocol.version}\" %{NUMBER:response} %{NUMBER:content.length:int} %{NOTSPACE} \"%{GREEDYDATA:user.agent}\" %{NOTSPACE} latency=%{NUMBER:latency:float}", true, ["PROJECT_ID=([A-Za-z0-9-]+)"]),"upsert")
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{WORD:log_level}%{SPACE}%{NOTSPACE}%{SPACE}%{NOTSPACE:process.name}", true),"upsert")
              - set(attributes["network.protocol.name"], ConvertCase(attributes["network.protocol.name"], "lower")) where cache["network.protocol.name"] != nil
              - set(attributes["config.parsed"], "ceph_rgw") where attributes["project.id"] != nil
              - set(attributes["config.parsed"], "ceph_rgw") where attributes["log_level"] != nil

      transform/ceph_osd:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["app.label.component"] == "cephclusters.ceph.rook.io"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{WORD:osd.stats.level}%{SPACE}%{NOTSPACE:osd.stats.files}%{SPACE}%{NUMBER:osd.stats.osd.stats.size:float}%{SPACE}%{WORD}%{SPACE}%{NUMBER:osd.stats.size_unit:float}%{SPACE}%{NUMBER:osd.stats.score:float}%{SPACE}%{NUMBER:osd.stats.read_gb:float}%{SPACE}%{NUMBER:osd.stats.rn_gb:float}%{SPACE}%{NUMBER:osd.stats.rnp1_gb:float}%{SPACE}%{NUMBER:osd.stats.write_gb:float}%{SPACE}%{NUMBER:osd.stats.wnew_gb:float}%{SPACE}%{NUMBER:osd.stats.moved:float}%{SPACE}%{NUMBER:osd.stats.w_amp:float}%{SPACE}%{NUMBER:osd.stats.rd_mb_s:float}%{SPACE}%{NUMBER:osd.stats.wr_mb_s:float}%{SPACE}%{NUMBER:osd.stats.comp_sec:float}%{SPACE}%{NUMBER:osd.stats.comp_merge_cpu_sec:float}%{SPACE}%{NUMBER:osd.stats.cpmp_cnt:float}%{SPACE}%{NUMBER:osd.stats.av_sec:float}%{SPACE}%{NUMBER:osd.stats.keyin:float}%{SPACE}%{NUMBER:osd.stats.keydrop:float}%{SPACE}%{NUMBER:osd.stats.rblob_gb:float}%{SPACE}%{NUMBER:osd.stats.wblol_gb:float}", true),"upsert")
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{GREEDYDATA:osd.wall.type}\\:%{SPACE}%{NUMBER:osd.wall.writes:float}(K|M|G)?%{SPACE}writes,%{SPACE}%{NUMBER:osd.wall.syncs:float}(K|M|G)?%{SPACE}syncs,%{SPACE}%{NUMBER:osd.wall.writes_per_sync:float}%{SPACE}writes per sync, written\\:%{SPACE}%{NUMBER:osd.wall.written_gb:float}%{SPACE}(GB|MB|TB)?,%{SPACE}%{NUMBER:osd.written_mb_sec:float}", true),"upsert")
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{WORD:log_level}%{SPACE}%{NOTSPACE}%{SPACE}%{SPACE}%{NOTSPACE:process.name}", true),"upsert")
              - set(attributes["config.parsed"], "ceph_osd") where attributes["osd.stats.level"] != nil
              - set(attributes["config.parsed"], "ceph_osd") where attributes["log_level"] != nil

      transform/files:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["log.type"] == "files"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{TIMESTAMP_ISO8601:timestamp}%{SPACE}%{GREEDYDATA:log}", true), "upsert")
              - set(attributes["config.parsed"], "files") where attributes["log_level"] != nil

      transform/kvm_openvswitch:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["k8s.daemonset.name"] == "neutron-openvswitch-agent"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{TIMESTAMP_ISO8601:logtime}%{SPACE}%{NUMBER:process.id}%{SPACE}%{WORD:log_level}%{SPACE}%{NOTSPACE:process.name}%{SPACE}\\[%{REQUEST_ID:request.id}%{SPACE}%{REQUEST_ID:request.global_id}", true, ["REQUEST_ID=([A-Za-z0-9-]+)"]), "upsert")
              - set(attributes["config.parsed"], "kvm_openvswitch") where attributes["log_level"] != nil

      transform/kvm_nova_agent:
        error_mode: ignore
        log_statements:
          - context: log
            conditions:
              - resource.attributes["k8s.daemonset.name"] == "nova-hypervisor-agents-compute-kvm"
            statements:
              - merge_maps(attributes, ExtractGrokPatterns(body, "%{TIMESTAMP_ISO8601:logtime}%{SPACE}%{NUMBER:process.id}%{SPACE}%{WORD:log_level}%{SPACE}%{NOTSPACE:process.name}%{SPACE}\\[%{REQUEST_ID:request.id}%{SPACE}%{REQUEST_ID:request.global_id}", true, ["REQUEST_ID=([A-Za-z0-9-]+)"]), "upsert")
              - set(attributes["config.parsed"], "kvm_nova_agent") where attributes["log_level"] != nil

      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.namespace.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.ip
            - k8s.pod.start_time
            - k8s.deployment.name
            - k8s.deployment.uid
            - k8s.node.name
            - k8s.replicaset.name
            - k8s.replicaset.uid
            - k8s.statefulset.name
            - k8s.statefulset.uid
            - k8s.daemonset.name
            - k8s.daemonset.uid
            - k8s.job.name
            - k8s.job.uid
            - k8s.cronjob.name
            - k8s.node.uid
            - k8s.cluster.uid
            - k8s.container.name
            - container.image.name
            - container.image.tag
          labels:
            - tag_name: app.label.ingress-nginx
              key: ingress-nginx
              from: pod
            - tag_name: app.label.support-group
              key: ccloud/support-group
              from: pod
            - tag_name: app.label.app_name
              key: app.kubernetes.io/app_name
              from: pod
            - tag_name: app.label.component
              key: app.kubernetes.io/component
              from: pod
            - tag_name: app.label.name
              key: app.kubernetes.io/name
              from: pod
            - tag_name: app.label.instance
              key: app.kubernetes.io/instance
              from: pod
            - tag_name: app.label.pod-template-hash
              key: app.kubernetes.io/pod-template-hash
              from: pod
            #ceph
            - tag_name: app.label.component
              key: app.kubernetes.io/component
              from: pod
            - tag_name: app.label.created-by
              key: app.kubernetes.io/created-by
              from: pod
            - tag_name: app.label.managed-by
              key: app.kubernetes.io/managed-by
              from: pod
            - tag_name: app.label.part-of
              key: app.kubernetes.io/part-of
              from: pod
            - tag_name: app.label.ceph-osd-id
              key: ceph-osd-id
              from: pod
            - tag_name: app.label.ceph_daemon_id
              key: ceph_daemon_id
              from: pod
            - tag_name: app.label.ceph_daemon_type
              key: ceph_daemon_type
              from: pod
            - tag_name: app.label.device-class
              key: device-class
              from: pod
            - tag_name: app.label.failure-domain
              key: failure-domain
              from: pod
            - tag_name: app.label.osd
              key: osd
              from: pod
            - tag_name: app.label.osd-store
              key: osd-store
              from: pod
            - tag_name: app.label.portable
              key: portable
              from: pod
            - tag_name: app.label.rook_cluster
              key: rook_cluster
              from: pod
            - tag_name: app.label.rook_io.operator-namespace
              key: rook_io/operator-namespace
              from: pod
            - tag_name: app.label.topology-location-host
              key: topology-location-host
              from: pod
            - tag_name: app.label.topology-location-region
              key: topology-location-region
              from: pod
            - tag_name: app.label.topology-location-region
              key: topology-location-region
              from: pod
            - tag_name: app.label.topology-location-root
              key: topology-location-root
              from: pod
            - tag_name: app.label.topology-location-zone
              key: topology-location-zone
              from: pod
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              - from: resource_attribute
                name: k8s.pod.name
          - sources:
              - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 30

    exporters:
      debug:
        verbosity: basic
      opensearch/logs:
        http:
          auth:
            authenticator: basicauth
          endpoint: {{ .Values.openSearchLogs.endpoint }}
        logs_index: ${username}-datastream
        
      prometheus:
        endpoint: 0.0.0.0:9999

    extensions:
      basicauth:
        client_auth:
          username: ${username}
          password: ${password}

    connectors:
      routing:
        default_pipelines: [logs/containerd]
        error_mode: ignore
        table:
          - statement: route() where attributes["container.runtime"] =="containerd"
            pipelines: [logs/containerd]
      count:

    service:
      extensions:
        - basicauth
{{- if .Values.podMonitor.enabled }}
      telemetry:
        metrics:
          address: 127.0.0.1:8888
          level: detailed
{{- end }}
      pipelines:
        logs/containerd:
          receivers: [filelog/containerd]
          processors: [k8sattributes,attributes/cluster,transform/ingress,transform/ceph_rgw,transform/ceph_osd,transform/kvm_openvswitch,transform/kvm_nova_agent,batch]
          exporters: [opensearch/logs,count]
        logs/files:
          receivers: [filelog/files]
          processors: [k8sattributes,attributes/cluster,transform/files,batch]
          exporters: [opensearch/logs,count]
        logs/k8sevents:
          receivers: [k8s_events]
          processors: [attributes/k8sevents,batch]
          exporters: [opensearch/logs,count]
        logs/journald:
          receivers: [journald]
          processors: [attributes/cluster,transform/journal,batch]
          exporters: [opensearch/logs,count]
        metrics:
          receivers: [count]
          exporters: [prometheus/internal]
{{- if .Values.podMonitor.enabled }}
        metrics/prometheus:
          receivers: [prometheus/internal]
          processors: [attributes/prometheus]
          exporters: [prometheus]
{{- end }}
{{- end }}
