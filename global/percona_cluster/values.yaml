---
# values for Percona XtraDB Cluster

## percona image and version
## ref: https://hub.docker.com/r/percona/percona-xtradb-cluster/tags/
image:
  repository: "percona/percona-xtradb-cluster"
  tag: "8.0.42-33.1"
  pullPolicy: IfNotPresent

# Desired number of members (Per region)
replicas: 1
# Desired cluster size (Cross region)
cluster_size: 3

db_name: test
pxc_strict_mode: ENFORCING
allowRootFrom: "%"

root_password: notasecurepassword
db_user: test
dbPassword: test
mysqlAllowEmptyPassword: false
xtraBackupPassword: test

# claim name is used as a prefix for full release name
persistence:
  enabled: true
  accessMode: ReadWriteMany
  claimName: db-global
  size: 100Gi
  # storageClass: "-"

podAnnotations: {}
nodeAffinity: {}
tolerations: []

# name of priorityClass to influence scheduling priority
# priority_class:

resources:
  requests:
    memory: 2048Mi
    cpu: 1000m

metrics:
  enabled: true
  tag: "v0.18.0"
  ## Password for exporter user (replaces auto-generated password)
  monitorPassword: longpassword
  flags:
    - collect.binlog_size
    - collect.info_schema.processlist
    - collect.info_schema.query_response_time
    - collect.info_schema.innodb_tablespaces

alerts:
  prometheus: openstack
  tier: os

prometheus:
  operator:
    ## Setting to true will create Prometheus-Operator specific resources like ServiceMonitors
    enabled: false

    ## Configures alerts for Prometheus to pick up
    prometheusRule:
      enabled: true
      ## Labels to add to alerts
      labels: {}
      ## Namespace which Prometheus is installed in
      # namespace: monitoring
      ## Label Selector for Prometheus to find alert rules
      # selector:
      #   prometheus: kube-prometheus

    ## Configures targets for Prometheus to pick up
    serviceMonitor:
      ## Interval at which Prometheus will scrape metrics exporter
      interval: 10s
      ## Namespace which Prometheus is installed in
      # namespace: monitoring
      ## Label Selector for Prometheus to find ServiceMonitors
      # selector:
      #   prometheus: kube-prometheus

ssl:
  enabled: false
  secret: pxc-ssl-certs
  certificates: {}
#  - name: pxc-ssl-certs
#    ca: |-
#      -----BEGIN CERTIFICATE-----
#      ...
#      -----END CERTIFICATE-----
#    cert: |-
#      -----BEGIN CERTIFICATE-----
#      ...
#      -----END CERTIFICATE-----
#    key: |-
#      -----BEGIN RSA PRIVATE KEY-----
#      ...
#      -----END RSA PRIVATE KEY-----
certificate:
  issuerRef:
    name: "digicert-issuer"
    kind: "ClusterIssuer"
    group: "certmanager.cloud.sap"
  usages:
    - digital signature
    - key encipherment
    - server auth
    - client auth

podDisruptionBudget:
  enabled: false
  # minAvailable: 1
  maxUnavailable: 1

tests:
  enabled: false

# segment to be set different for far locations
gmcast_segment: 1

backup:
  enabled: false
  image: percona/percona-xtrabackup
  image_tag: "8.0.35-34.1"
  schedule: "30 * * * *"
  claimName: backup-pvc
  security_context_ids: 1000
  retentionDays: 7

global:
  region: global
  db_region: eu-de-1
  linkerd_requested: true

# Set 'primary' to true for initiating a bootstrap below:
service:
  primary: false
  headless: false
  regions:
    eu-de-1: "10.46.2.111"
    eu-de-2: "10.46.180.111"
    eu-nl-1: "10.46.78.111"
